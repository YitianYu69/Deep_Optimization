{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e96b8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/yyu496/.conda/envs/lib/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# os.environ[\"TORCH_LOGS\"] = \"output_code\"\n",
    "# os.environ[\"TORCH_LOGS\"] = \"inductor\"\n",
    "# os.environ[\"TORCHINDUCTOR_TRACE\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_VERBOSE\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_DEBUG\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_DUMP\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_COMPILE_THREADS\"] = \"1\"\n",
    "# os.environ[\"TORCH_COMPILE_DEBUG\"] = \"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = (\n",
    "    # \"backend:cudaMallocAsync,\"\n",
    "    \"expandable_segments:True,\"\n",
    "    # \"garbage_collection_threshold:0.6\"\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/hice1/yyu496/kaggle/CW')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch._functorch.aot_autograd import aot_module, make_boxed_func\n",
    "from torch.autograd import grad\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import (\n",
    "    LinearLR,\n",
    "    CosineAnnealingLR,\n",
    "    SequentialLR\n",
    ")\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch._dynamo as dynamo\n",
    "import torch.nn.utils.parametrize as P\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "\n",
    "import ACT6.cpp_extension as cpp_extension\n",
    "\n",
    "from ACT6.controller import Controller\n",
    "import ACT6.cuda_graph_utils as cuda_utils\n",
    "from ACT6.layers import RMSNorm, DOConv2d, DOConv1d, DOLinear\n",
    "from ACT6.fusion.fused_layers import DOBatchNormReLU2d\n",
    "\n",
    "import timm\n",
    "from timm.layers import trunc_normal_\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "import actnn\n",
    "# available choices are [\"L0\", \"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]\n",
    "actnn.set_optimization_level(\"L3\")\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import triton\n",
    "import triton.language as tl    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba78a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ACT6.modules.tensor_act_reshape_utils import (\n",
    "    spatical_aware_act_tensor_reshape,\n",
    "    spatical_aware_act_tensor_reshape_back,\n",
    "    default_act_tensor_reshape,\n",
    "    default_act_tensor_reshape_back)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b0f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(64, 512, 32, 32, device='cuda')\n",
    "Group_Size = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd24e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, N, G, new_H, new_W, ori_shape_new, spatical_padding_eligibility, spatical_reshape_eligibility,channel_mean = spatical_aware_act_tensor_reshape(X, Group_Size=16, act_padding=False, pack_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20b10384",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_X_2 = spatical_aware_act_tensor_reshape_back(X2,ori_shape_new, Group_Size=16, new_H=new_H, new_W=new_W, act_padding=False, spatical_padding_eligibility=spatical_padding_eligibility, spatical_reshape_eligibility=spatical_reshape_eligibility, channel_mean=channel_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a52eae4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_act_tensor_reshape() missing 1 required positional argument: 'pack_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X3, N_old, G_old, original_shape_old \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_act_tensor_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGroup_Size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_padding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: default_act_tensor_reshape() missing 1 required positional argument: 'pack_only'"
     ]
    }
   ],
   "source": [
    "X3, N_old, G_old, original_shape_old = default_act_tensor_reshape(X, Group_Size=16, act_padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67361c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ori_X_3 \u001b[38;5;241m=\u001b[39m default_act_tensor_reshape_back(\u001b[43mX3\u001b[49m, original_shape_old, act_padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X3' is not defined"
     ]
    }
   ],
   "source": [
    "ori_X_3 = default_act_tensor_reshape_back(X3, original_shape_old, act_padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a678d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(8, 512, 32, 32, device='cuda')\n",
    "\n",
    "group_size = 512\n",
    "N = X.size(0)\n",
    "X2 = X.view(N, -1, group_size)\n",
    "G = X2.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b647d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = torch.clamp(X2, -3, 3)\n",
    "\n",
    "min = X2.min()\n",
    "max = X2.max()\n",
    "\n",
    "# mean_X2 = X2.mean()\n",
    "# var_X2 = X2.var()\n",
    "# _X2 = (X2 - mean_X2) / torch.sqrt(X2.var() + 1e-6)\n",
    "# rms_norm = torch.sqrt((X2 ** 2).mean(dim=0, keepdim=True) + 1e-6)\n",
    "# _X2 = X2 / rms_norm\n",
    "# _X2 = F.tanh(X2 / 0.5) * 0.5\n",
    "# _X2 = F.silu(X2)\n",
    "# _X2 = F.gelu(_X2) \n",
    "# _X2 = F.selu(X2)\n",
    "# _X2 = F.softshrink(X2, lambd=0.7)\n",
    "# _X2 = F.rrelu(X2)\n",
    "# _mean_X2 = _X2.mean()\n",
    "# _var_X2 = _X2.var()\n",
    "# _X2 = (_X2 - _mean_X2) / torch.sqrt(_var_X2 + 1e-6)\n",
    "# _X2 = F.gelu(X2)\n",
    "\n",
    "\n",
    "scale = (max - min) / (2**2 - 1)\n",
    "\n",
    "_x2_quantized = (_X2 - min) / scale\n",
    "x2_quantized = (X2 - min) / scale\n",
    "\n",
    "# X2_hat_quantized = (X2_hat - min) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7139c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39cc7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cd99ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2_hat_quantized_checker = X2_hat_quantized.to(torch.int32).view(N, -1, Group_Size // 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b969e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _X2_quantized_checker = _x2_quantized.view(N, -1, Group_Size // 2, 2)\n",
    "# _X2_quantized_checker = _X2_quantized_checker.mean(dim=-1).repeat(1, 1, 1, 2).to(torch.int32)\n",
    "_X2_quantized_checker = _x2_quantized.to(torch.int32).view(N, -1, Group_Size // 2, 2)\n",
    "\n",
    "X2_quantized_checker = x2_quantized.to(torch.int32).view(N, -1, Group_Size // 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d4a33b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1308.6737, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X2_dequantized = (_X2_quantized_checker.to(torch.float32)+ min) * scale\n",
    "X2_dequantized = (X2_quantized_checker.to(torch.float32)+ min) * scale\n",
    "\n",
    "# F.cosine_similarity(_X2_dequantized.view(-1), X2_dequantized.view(-1), dim=0)\n",
    "F.pairwise_distance(_X2_dequantized.view(-1), X2_dequantized.view(-1), p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "062430a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_X2 number of 0: 17771842\n",
      "_X2number of 1: 13424074\n",
      "_X2 number of 2: 2358516\n",
      "_X2 number of 3: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"_X2 number of 0: {torch.sum(_X2_quantized_checker == 0)}\")\n",
    "print(f\"_X2number of 1: {torch.sum(_X2_quantized_checker == 1)}\")\n",
    "print(f\"_X2 number of 2: {torch.sum(_X2_quantized_checker == 2)}\")\n",
    "print(f\"_X2 number of 3: {torch.sum(_X2_quantized_checker == 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82705898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 7474254\n",
      "Not Equal 9302962\n",
      "Ratio: 0.27724987268447876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Equal {torch.sum(_X2_quantized_checker[..., 0] == _X2_quantized_checker[..., 1])}\")\n",
    "print(f\"Not Equal {torch.sum(_X2_quantized_checker[..., 0] != _X2_quantized_checker[..., 1])}\")\n",
    "print(f\"Ratio: {torch.sum(_X2_quantized_checker[..., 0] != _X2_quantized_checker[..., 1]) / _X2_quantized_checker.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35d91c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal 5590171\n",
      "Not Equal 11187045\n",
      "Ratio: 0.3333999216556549\n"
     ]
    }
   ],
   "source": [
    "print(f\"Equal {torch.sum(X2_quantized_checker[..., 0] == X2_quantized_checker[..., 1])}\")\n",
    "print(f\"Not Equal {torch.sum(X2_quantized_checker[..., 0] != X2_quantized_checker[..., 1])}\")\n",
    "print(f\"Ratio: {torch.sum(X2_quantized_checker[..., 0] != X2_quantized_checker[..., 1]) / X2_quantized_checker.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e4a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2 number of 0: 11185916\n",
      "X2 number of 1: 11182192\n",
      "X2 number of 2: 11186324\n",
      "X2 number of 3: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"X2 number of 0: {torch.sum(X2_quantized_checker == 0)}\")\n",
    "print(f\"X2 number of 1: {torch.sum(X2_quantized_checker == 1)}\")\n",
    "print(f\"X2 number of 2: {torch.sum(X2_quantized_checker == 2)}\")\n",
    "print(f\"X2 number of 3: {torch.sum(X2_quantized_checker == 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f58803",
   "metadata": {},
   "outputs": [],
   "source": [
    "_X2_dequantized = (_X2_quantized_checker.to(torch.float32)+ min) * scale\n",
    "X2_dequantized = (X2_quantized_checker.to(torch.float32)+ min) * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "91e905f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5640, device='cuda:0')"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(_X2_dequantized.view(-1), X2_dequantized.view(-1), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4b3d309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1, 0],\n",
       "          [0, 1, 2, 1],\n",
       "          [1, 2, 1, 0],\n",
       "          ...,\n",
       "          [2, 1, 1, 2],\n",
       "          [1, 0, 0, 0],\n",
       "          [0, 2, 1, 2]],\n",
       "\n",
       "         [[0, 1, 2, 2],\n",
       "          [0, 0, 2, 0],\n",
       "          [2, 0, 1, 1],\n",
       "          ...,\n",
       "          [0, 1, 2, 2],\n",
       "          [0, 1, 1, 1],\n",
       "          [0, 0, 2, 1]],\n",
       "\n",
       "         [[1, 2, 1, 2],\n",
       "          [0, 1, 0, 1],\n",
       "          [1, 2, 1, 0],\n",
       "          ...,\n",
       "          [0, 2, 0, 2],\n",
       "          [1, 2, 2, 1],\n",
       "          [0, 0, 2, 0]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2, 2, 1, 0],\n",
       "          [0, 2, 1, 2],\n",
       "          [2, 2, 1, 2],\n",
       "          ...,\n",
       "          [2, 2, 2, 2],\n",
       "          [0, 1, 1, 2],\n",
       "          [0, 2, 1, 0]],\n",
       "\n",
       "         [[0, 1, 0, 0],\n",
       "          [0, 1, 2, 2],\n",
       "          [2, 2, 1, 0],\n",
       "          ...,\n",
       "          [1, 2, 2, 0],\n",
       "          [1, 0, 1, 0],\n",
       "          [0, 0, 1, 0]],\n",
       "\n",
       "         [[1, 2, 1, 1],\n",
       "          [0, 0, 2, 1],\n",
       "          [2, 1, 0, 0],\n",
       "          ...,\n",
       "          [1, 2, 0, 1],\n",
       "          [0, 2, 1, 1],\n",
       "          [1, 2, 0, 1]]],\n",
       "\n",
       "\n",
       "        [[[0, 1, 1, 0],\n",
       "          [1, 1, 0, 0],\n",
       "          [0, 2, 1, 0],\n",
       "          ...,\n",
       "          [0, 1, 1, 0],\n",
       "          [2, 1, 2, 0],\n",
       "          [2, 1, 0, 0]],\n",
       "\n",
       "         [[1, 1, 2, 1],\n",
       "          [0, 0, 2, 0],\n",
       "          [2, 1, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 0, 0],\n",
       "          [0, 0, 1, 0],\n",
       "          [0, 2, 0, 2]],\n",
       "\n",
       "         [[1, 0, 1, 2],\n",
       "          [2, 1, 2, 2],\n",
       "          [0, 2, 2, 0],\n",
       "          ...,\n",
       "          [2, 0, 1, 0],\n",
       "          [2, 1, 0, 0],\n",
       "          [0, 2, 0, 2]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0, 2, 2, 0],\n",
       "          [0, 2, 2, 2],\n",
       "          [0, 1, 2, 2],\n",
       "          ...,\n",
       "          [1, 2, 2, 2],\n",
       "          [1, 0, 2, 0],\n",
       "          [1, 0, 1, 1]],\n",
       "\n",
       "         [[0, 1, 0, 2],\n",
       "          [2, 0, 1, 0],\n",
       "          [1, 1, 2, 0],\n",
       "          ...,\n",
       "          [0, 2, 1, 1],\n",
       "          [2, 2, 0, 1],\n",
       "          [2, 2, 1, 2]],\n",
       "\n",
       "         [[1, 1, 2, 2],\n",
       "          [2, 1, 2, 2],\n",
       "          [1, 0, 1, 0],\n",
       "          ...,\n",
       "          [2, 1, 1, 2],\n",
       "          [1, 0, 1, 2],\n",
       "          [2, 1, 1, 2]]],\n",
       "\n",
       "\n",
       "        [[[1, 1, 1, 0],\n",
       "          [0, 2, 0, 1],\n",
       "          [0, 2, 0, 1],\n",
       "          ...,\n",
       "          [1, 0, 0, 0],\n",
       "          [0, 0, 0, 2],\n",
       "          [1, 1, 2, 1]],\n",
       "\n",
       "         [[1, 0, 1, 1],\n",
       "          [0, 1, 0, 2],\n",
       "          [1, 1, 1, 0],\n",
       "          ...,\n",
       "          [1, 2, 1, 1],\n",
       "          [0, 0, 2, 2],\n",
       "          [2, 0, 2, 2]],\n",
       "\n",
       "         [[1, 0, 2, 0],\n",
       "          [1, 0, 2, 2],\n",
       "          [2, 0, 1, 2],\n",
       "          ...,\n",
       "          [1, 1, 2, 0],\n",
       "          [0, 2, 0, 1],\n",
       "          [2, 2, 0, 2]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2, 0, 2, 1],\n",
       "          [2, 1, 0, 2],\n",
       "          [0, 2, 0, 2],\n",
       "          ...,\n",
       "          [1, 1, 2, 2],\n",
       "          [0, 2, 2, 2],\n",
       "          [2, 0, 1, 0]],\n",
       "\n",
       "         [[2, 2, 0, 0],\n",
       "          [2, 1, 1, 1],\n",
       "          [0, 0, 2, 0],\n",
       "          ...,\n",
       "          [0, 2, 2, 0],\n",
       "          [1, 2, 2, 1],\n",
       "          [1, 2, 2, 2]],\n",
       "\n",
       "         [[0, 1, 2, 2],\n",
       "          [2, 0, 1, 0],\n",
       "          [2, 2, 2, 0],\n",
       "          ...,\n",
       "          [1, 2, 1, 1],\n",
       "          [0, 2, 1, 2],\n",
       "          [2, 2, 0, 0]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0, 1, 1, 2],\n",
       "          [0, 2, 2, 0],\n",
       "          [2, 1, 1, 1],\n",
       "          ...,\n",
       "          [0, 2, 1, 2],\n",
       "          [2, 0, 0, 1],\n",
       "          [1, 1, 2, 0]],\n",
       "\n",
       "         [[2, 0, 1, 1],\n",
       "          [2, 1, 1, 0],\n",
       "          [1, 0, 0, 0],\n",
       "          ...,\n",
       "          [2, 1, 1, 0],\n",
       "          [1, 1, 1, 2],\n",
       "          [2, 2, 0, 1]],\n",
       "\n",
       "         [[0, 2, 1, 0],\n",
       "          [0, 1, 1, 1],\n",
       "          [1, 0, 1, 2],\n",
       "          ...,\n",
       "          [2, 1, 0, 1],\n",
       "          [1, 1, 1, 0],\n",
       "          [2, 0, 0, 2]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2, 0, 0, 2],\n",
       "          [0, 2, 1, 1],\n",
       "          [2, 2, 2, 0],\n",
       "          ...,\n",
       "          [1, 1, 1, 0],\n",
       "          [1, 1, 2, 1],\n",
       "          [2, 2, 0, 0]],\n",
       "\n",
       "         [[1, 0, 2, 1],\n",
       "          [2, 2, 2, 1],\n",
       "          [2, 0, 2, 1],\n",
       "          ...,\n",
       "          [1, 2, 0, 0],\n",
       "          [0, 2, 0, 0],\n",
       "          [2, 2, 0, 0]],\n",
       "\n",
       "         [[2, 0, 0, 0],\n",
       "          [2, 1, 2, 2],\n",
       "          [0, 0, 2, 0],\n",
       "          ...,\n",
       "          [0, 1, 2, 2],\n",
       "          [0, 1, 2, 2],\n",
       "          [2, 1, 1, 0]]],\n",
       "\n",
       "\n",
       "        [[[0, 1, 2, 2],\n",
       "          [2, 0, 2, 2],\n",
       "          [2, 0, 2, 1],\n",
       "          ...,\n",
       "          [2, 1, 2, 1],\n",
       "          [0, 0, 1, 0],\n",
       "          [2, 1, 0, 1]],\n",
       "\n",
       "         [[1, 2, 1, 1],\n",
       "          [1, 1, 1, 0],\n",
       "          [0, 0, 0, 1],\n",
       "          ...,\n",
       "          [1, 0, 1, 2],\n",
       "          [0, 2, 2, 1],\n",
       "          [1, 1, 2, 1]],\n",
       "\n",
       "         [[1, 0, 0, 0],\n",
       "          [0, 0, 0, 2],\n",
       "          [2, 2, 1, 1],\n",
       "          ...,\n",
       "          [0, 1, 2, 0],\n",
       "          [2, 0, 0, 2],\n",
       "          [1, 2, 1, 0]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2, 1, 1, 1],\n",
       "          [0, 2, 0, 0],\n",
       "          [2, 1, 0, 1],\n",
       "          ...,\n",
       "          [0, 2, 0, 1],\n",
       "          [2, 0, 1, 1],\n",
       "          [2, 1, 0, 1]],\n",
       "\n",
       "         [[0, 0, 2, 0],\n",
       "          [1, 0, 2, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          ...,\n",
       "          [2, 1, 1, 1],\n",
       "          [1, 2, 2, 1],\n",
       "          [0, 0, 2, 1]],\n",
       "\n",
       "         [[1, 0, 0, 0],\n",
       "          [2, 0, 2, 2],\n",
       "          [0, 2, 0, 1],\n",
       "          ...,\n",
       "          [1, 1, 0, 0],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 0, 2, 2]]],\n",
       "\n",
       "\n",
       "        [[[2, 2, 2, 0],\n",
       "          [2, 2, 0, 0],\n",
       "          [2, 0, 2, 2],\n",
       "          ...,\n",
       "          [2, 1, 2, 2],\n",
       "          [1, 2, 1, 2],\n",
       "          [1, 1, 1, 0]],\n",
       "\n",
       "         [[2, 0, 0, 1],\n",
       "          [1, 1, 2, 1],\n",
       "          [0, 0, 1, 0],\n",
       "          ...,\n",
       "          [1, 2, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 0]],\n",
       "\n",
       "         [[2, 2, 0, 2],\n",
       "          [2, 0, 1, 1],\n",
       "          [2, 1, 2, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, 0],\n",
       "          [1, 2, 0, 0],\n",
       "          [2, 1, 1, 1]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0, 1, 0, 2],\n",
       "          [1, 2, 0, 2],\n",
       "          [2, 1, 0, 0],\n",
       "          ...,\n",
       "          [1, 0, 1, 0],\n",
       "          [2, 0, 1, 0],\n",
       "          [1, 1, 0, 2]],\n",
       "\n",
       "         [[2, 1, 0, 0],\n",
       "          [2, 0, 2, 1],\n",
       "          [2, 1, 2, 0],\n",
       "          ...,\n",
       "          [1, 2, 0, 0],\n",
       "          [0, 0, 0, 2],\n",
       "          [0, 1, 0, 0]],\n",
       "\n",
       "         [[0, 0, 1, 1],\n",
       "          [1, 1, 0, 1],\n",
       "          [0, 0, 2, 2],\n",
       "          ...,\n",
       "          [2, 2, 1, 0],\n",
       "          [0, 0, 0, 0],\n",
       "          [1, 1, 0, 2]]]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_quantized_int = x2_quantized.to(torch.int32)\n",
    "x2_quantized_int.view(N, G, group_size // 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe3296e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.3432e+00, 1.0879e+00],\n",
       "          [4.8966e-02, 1.5319e+00],\n",
       "          [1.9327e+00, 7.5273e-01],\n",
       "          ...,\n",
       "          [2.4140e+00, 6.5493e-01],\n",
       "          [8.3042e-01, 2.9752e+00],\n",
       "          [1.3666e+00, 1.0859e+00]],\n",
       "\n",
       "         [[1.8584e+00, 9.9521e-01],\n",
       "          [1.6998e-01, 1.5811e+00],\n",
       "          [2.2233e+00, 1.8326e+00],\n",
       "          ...,\n",
       "          [7.9671e-01, 2.5218e+00],\n",
       "          [1.2742e-01, 9.8014e-01],\n",
       "          [1.4920e-02, 1.4914e+00]],\n",
       "\n",
       "         [[2.0787e+00, 7.5452e-01],\n",
       "          [6.1217e-02, 7.4855e-01],\n",
       "          [6.2302e-01, 7.5215e-01],\n",
       "          ...,\n",
       "          [1.1050e-01, 1.4306e-01],\n",
       "          [1.5507e+00, 2.8007e+00],\n",
       "          [7.5011e-01, 1.8909e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.6356e+00, 1.7314e+00],\n",
       "          [1.3093e+00, 2.4303e+00],\n",
       "          [7.4922e-01, 3.1696e-01],\n",
       "          ...,\n",
       "          [7.9777e-01, 2.8208e+00],\n",
       "          [1.0357e+00, 9.8567e-01],\n",
       "          [2.5519e+00, 1.8857e+00]],\n",
       "\n",
       "         [[1.1974e+00, 1.8758e+00],\n",
       "          [8.4026e-01, 2.9049e+00],\n",
       "          [6.7866e-01, 1.3301e+00],\n",
       "          ...,\n",
       "          [6.6559e-01, 1.4714e+00],\n",
       "          [1.2696e+00, 2.6718e+00],\n",
       "          [8.2118e-01, 2.9861e+00]],\n",
       "\n",
       "         [[2.3996e+00, 1.1365e+00],\n",
       "          [3.8032e-01, 2.7337e+00],\n",
       "          [2.4671e+00, 2.6973e+00],\n",
       "          ...,\n",
       "          [1.9734e-01, 2.8885e+00],\n",
       "          [2.8626e+00, 2.8327e+00],\n",
       "          [8.1901e-01, 2.3862e+00]]],\n",
       "\n",
       "\n",
       "        [[[1.9602e+00, 2.4203e-01],\n",
       "          [4.2461e-01, 2.5941e+00],\n",
       "          [1.9410e+00, 2.1302e+00],\n",
       "          ...,\n",
       "          [1.2386e-01, 1.1450e+00],\n",
       "          [2.8944e+00, 1.8814e+00],\n",
       "          [2.9419e+00, 1.3488e+00]],\n",
       "\n",
       "         [[1.0102e+00, 1.3230e+00],\n",
       "          [2.5317e+00, 1.7246e+00],\n",
       "          [2.7016e+00, 2.8922e+00],\n",
       "          ...,\n",
       "          [4.2060e-01, 1.0812e-02],\n",
       "          [5.8662e-01, 2.9656e+00],\n",
       "          [1.7977e+00, 2.7521e+00]],\n",
       "\n",
       "         [[1.3406e+00, 1.7590e+00],\n",
       "          [2.5924e+00, 1.0077e+00],\n",
       "          [2.2744e+00, 1.3232e+00],\n",
       "          ...,\n",
       "          [9.1725e-01, 2.1520e+00],\n",
       "          [2.0443e+00, 2.1283e+00],\n",
       "          [2.0345e+00, 1.7482e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.6397e-01, 5.4904e-02],\n",
       "          [2.3556e+00, 1.0218e+00],\n",
       "          [1.5055e+00, 9.1230e-01],\n",
       "          ...,\n",
       "          [1.7040e+00, 2.1247e+00],\n",
       "          [2.6056e+00, 5.9608e-01],\n",
       "          [2.7504e+00, 7.1449e-03]],\n",
       "\n",
       "         [[1.8112e+00, 2.5024e+00],\n",
       "          [1.9926e-01, 2.2705e+00],\n",
       "          [1.5245e+00, 9.1896e-01],\n",
       "          ...,\n",
       "          [2.9927e+00, 4.0146e-01],\n",
       "          [1.6688e+00, 2.7576e+00],\n",
       "          [1.4889e+00, 2.5655e+00]],\n",
       "\n",
       "         [[1.8833e+00, 2.4540e+00],\n",
       "          [2.3442e+00, 8.4372e-01],\n",
       "          [2.8164e+00, 2.3520e+00],\n",
       "          ...,\n",
       "          [1.8579e+00, 2.5163e+00],\n",
       "          [1.8189e+00, 2.0111e+00],\n",
       "          [1.7063e+00, 2.8589e+00]]],\n",
       "\n",
       "\n",
       "        [[[2.1250e+00, 1.1342e+00],\n",
       "          [5.4353e-01, 9.7198e-01],\n",
       "          [1.9846e+00, 1.8029e-01],\n",
       "          ...,\n",
       "          [1.8593e+00, 2.9993e+00],\n",
       "          [2.7305e+00, 2.6169e+00],\n",
       "          [2.0634e+00, 2.7982e+00]],\n",
       "\n",
       "         [[2.5692e+00, 2.0551e+00],\n",
       "          [1.1423e+00, 1.5046e+00],\n",
       "          [1.8188e+00, 1.5618e+00],\n",
       "          ...,\n",
       "          [6.6064e-01, 4.2709e-01],\n",
       "          [1.6268e+00, 2.2178e+00],\n",
       "          [9.7191e-01, 2.1403e-02]],\n",
       "\n",
       "         [[5.2275e-01, 7.9538e-01],\n",
       "          [2.3196e+00, 2.7089e+00],\n",
       "          [1.4479e+00, 2.8755e+00],\n",
       "          ...,\n",
       "          [1.9857e+00, 6.9132e-01],\n",
       "          [2.2143e+00, 1.3097e+00],\n",
       "          [8.9059e-01, 2.8849e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.8813e+00, 2.7079e+00],\n",
       "          [1.3352e+00, 2.7762e+00],\n",
       "          [1.0564e-01, 1.6809e+00],\n",
       "          ...,\n",
       "          [2.4225e+00, 2.4402e+00],\n",
       "          [2.3131e+00, 4.6841e-01],\n",
       "          [8.6046e-01, 9.0545e-01]],\n",
       "\n",
       "         [[6.9441e-01, 2.4088e+00],\n",
       "          [5.5836e-01, 3.0301e-01],\n",
       "          [2.1957e+00, 1.3748e+00],\n",
       "          ...,\n",
       "          [1.2287e-04, 2.9496e+00],\n",
       "          [2.7764e+00, 2.7405e-02],\n",
       "          [2.1159e+00, 6.9882e-01]],\n",
       "\n",
       "         [[1.3987e+00, 8.4477e-01],\n",
       "          [1.8779e-01, 7.5511e-01],\n",
       "          [2.2438e+00, 1.5708e+00],\n",
       "          ...,\n",
       "          [2.9661e+00, 2.1609e+00],\n",
       "          [7.6765e-01, 1.3908e+00],\n",
       "          [2.2358e+00, 1.2498e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[2.0742e+00, 2.5777e+00],\n",
       "          [1.7048e+00, 2.1111e+00],\n",
       "          [1.2912e+00, 2.8205e+00],\n",
       "          ...,\n",
       "          [1.0626e+00, 9.3752e-01],\n",
       "          [1.4213e+00, 1.5109e+00],\n",
       "          [1.2069e+00, 1.7593e+00]],\n",
       "\n",
       "         [[2.6994e-02, 1.4935e+00],\n",
       "          [2.4545e+00, 2.2077e+00],\n",
       "          [1.4105e+00, 2.6551e+00],\n",
       "          ...,\n",
       "          [1.9130e+00, 1.9559e+00],\n",
       "          [2.9935e+00, 2.7135e+00],\n",
       "          [2.4429e+00, 7.5445e-01]],\n",
       "\n",
       "         [[2.8644e+00, 2.6829e+00],\n",
       "          [8.6024e-01, 7.8549e-01],\n",
       "          [1.6162e+00, 5.7354e-01],\n",
       "          ...,\n",
       "          [2.3699e+00, 2.9236e+00],\n",
       "          [2.0396e+00, 6.4225e-01],\n",
       "          [1.3326e+00, 2.9101e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.5151e+00, 2.6419e+00],\n",
       "          [1.5692e+00, 1.1841e+00],\n",
       "          [4.8349e-01, 3.7663e-01],\n",
       "          ...,\n",
       "          [2.9672e+00, 2.0858e-01],\n",
       "          [2.7275e+00, 2.3443e+00],\n",
       "          [1.1097e+00, 1.0566e+00]],\n",
       "\n",
       "         [[1.4356e+00, 1.0861e+00],\n",
       "          [1.5477e+00, 9.8179e-02],\n",
       "          [1.5335e+00, 9.5087e-01],\n",
       "          ...,\n",
       "          [1.1911e+00, 1.4375e+00],\n",
       "          [2.9850e+00, 1.8531e+00],\n",
       "          [1.4125e+00, 1.0585e-01]],\n",
       "\n",
       "         [[2.5695e+00, 1.8547e+00],\n",
       "          [1.0826e+00, 1.5342e+00],\n",
       "          [9.1587e-01, 1.4136e+00],\n",
       "          ...,\n",
       "          [9.0905e-01, 1.0105e+00],\n",
       "          [2.2356e+00, 1.4574e+00],\n",
       "          [1.2148e+00, 1.3540e+00]]],\n",
       "\n",
       "\n",
       "        [[[2.5736e+00, 2.8667e+00],\n",
       "          [1.9656e+00, 1.3837e+00],\n",
       "          [7.9831e-01, 2.9643e+00],\n",
       "          ...,\n",
       "          [1.5201e+00, 2.1785e+00],\n",
       "          [1.2118e+00, 9.2871e-01],\n",
       "          [1.2151e-01, 2.5056e+00]],\n",
       "\n",
       "         [[3.6317e-01, 3.0437e-01],\n",
       "          [2.7329e+00, 2.3429e-01],\n",
       "          [1.0280e+00, 2.7224e+00],\n",
       "          ...,\n",
       "          [1.4196e+00, 2.9054e+00],\n",
       "          [4.6403e-01, 1.4008e+00],\n",
       "          [1.8767e+00, 1.7220e+00]],\n",
       "\n",
       "         [[1.3234e+00, 8.5956e-01],\n",
       "          [9.8774e-01, 5.2558e-01],\n",
       "          [1.7496e+00, 2.0871e+00],\n",
       "          ...,\n",
       "          [8.8228e-01, 2.7203e+00],\n",
       "          [1.9456e+00, 7.5487e-01],\n",
       "          [2.5431e+00, 1.4465e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.4939e+00, 2.2351e+00],\n",
       "          [1.2912e+00, 2.5340e+00],\n",
       "          [5.4342e-01, 1.7393e+00],\n",
       "          ...,\n",
       "          [2.1282e+00, 1.9519e-01],\n",
       "          [1.1128e+00, 1.0945e+00],\n",
       "          [1.1344e+00, 2.4850e+00]],\n",
       "\n",
       "         [[2.0877e-01, 8.5538e-01],\n",
       "          [2.3365e+00, 1.5711e+00],\n",
       "          [7.7800e-02, 2.9333e+00],\n",
       "          ...,\n",
       "          [2.9080e+00, 2.3645e+00],\n",
       "          [1.7440e+00, 1.1932e+00],\n",
       "          [2.9708e+00, 8.7099e-01]],\n",
       "\n",
       "         [[2.2626e+00, 9.3792e-01],\n",
       "          [1.6117e+00, 8.9474e-01],\n",
       "          [2.9894e+00, 2.8689e+00],\n",
       "          ...,\n",
       "          [1.8201e+00, 2.8410e+00],\n",
       "          [2.9937e-01, 2.3469e+00],\n",
       "          [1.8389e+00, 6.1763e-01]]],\n",
       "\n",
       "\n",
       "        [[[2.6825e+00, 1.2522e+00],\n",
       "          [1.7772e+00, 5.8179e-01],\n",
       "          [9.2812e-01, 2.4292e+00],\n",
       "          ...,\n",
       "          [2.3912e+00, 2.9124e+00],\n",
       "          [5.8027e-01, 7.9023e-01],\n",
       "          [2.5657e+00, 1.3075e+00]],\n",
       "\n",
       "         [[8.1507e-02, 2.8952e-01],\n",
       "          [1.8891e-01, 4.2274e-01],\n",
       "          [4.2278e-01, 1.4607e+00],\n",
       "          ...,\n",
       "          [1.5535e+00, 2.7717e+00],\n",
       "          [7.8371e-01, 4.3419e-01],\n",
       "          [7.7971e-01, 7.0905e-01]],\n",
       "\n",
       "         [[2.8181e+00, 2.7626e+00],\n",
       "          [2.2773e+00, 2.4492e+00],\n",
       "          [9.7188e-01, 4.5940e-01],\n",
       "          ...,\n",
       "          [2.7077e+00, 2.4575e+00],\n",
       "          [1.9785e+00, 6.6618e-01],\n",
       "          [1.6339e+00, 2.9849e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.7076e+00, 2.0672e+00],\n",
       "          [5.8654e-03, 2.4844e+00],\n",
       "          [1.7297e+00, 2.6870e+00],\n",
       "          ...,\n",
       "          [5.0675e-01, 1.4616e+00],\n",
       "          [1.6519e+00, 1.9429e+00],\n",
       "          [1.7019e+00, 2.4380e+00]],\n",
       "\n",
       "         [[5.8109e-01, 2.8000e+00],\n",
       "          [2.5677e+00, 2.8864e+00],\n",
       "          [3.1487e-01, 1.8577e+00],\n",
       "          ...,\n",
       "          [2.2857e+00, 1.1438e+00],\n",
       "          [2.8347e+00, 1.0549e+00],\n",
       "          [6.5656e-01, 1.9133e-01]],\n",
       "\n",
       "         [[2.7113e+00, 2.7359e+00],\n",
       "          [2.1877e+00, 2.7746e+00],\n",
       "          [2.0303e+00, 2.9364e+00],\n",
       "          ...,\n",
       "          [6.7803e-01, 6.8297e-01],\n",
       "          [7.6110e-01, 6.0514e-01],\n",
       "          [2.6570e+00, 2.5662e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_quantized.view(N, G, group_size // 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h4(x):\n",
    "    a,b,c,d = x[...,0],x[...,1],x[...,2],x[...,3]\n",
    "    return torch.stack([\n",
    "        a+b+c+d,\n",
    "        a+b-c-d,\n",
    "        a-b+c-d,\n",
    "        a-b-c+d\n",
    "    ], dim=-1) * 0.5\n",
    "\n",
    "\n",
    "def h4_inv(y):\n",
    "    y0,y1,y2,y3 = y[...,0],y[...,1],y[...,2],y[...,3]\n",
    "    return torch.stack([\n",
    "        y0+y1+y2+y3,\n",
    "        y0+y1-y2-y3,\n",
    "        y0-y1+y2-y3,\n",
    "        y0-y1-y2+y3\n",
    "    ], dim=-1) * 0.5\n",
    "\n",
    "\n",
    "def hadamard_auto(x):\n",
    "    shp = x.shape\n",
    "    B = x.shape[0]\n",
    "\n",
    "    flat = x.reshape(B, -1).contiguous()\n",
    "    F = flat.shape[1]\n",
    "\n",
    "    pad = (-F) % 4\n",
    "\n",
    "    if pad:\n",
    "        flat = torch.cat(\n",
    "            [flat, torch.zeros(B, pad, device=x.device, dtype=x.dtype)],\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "    Fp = flat.shape[1]\n",
    "\n",
    "    g = flat.reshape(B, Fp // 4, 4)\n",
    "    y = h4(g)\n",
    "\n",
    "    # drop padding before reshaping back\n",
    "    y = y.reshape(B, Fp)\n",
    "    if pad:\n",
    "        y = y[:, :-pad]\n",
    "\n",
    "    return y.reshape(shp), pad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hadamard_auto_inv(y, pad):\n",
    "    shp = y.shape\n",
    "    B = y.shape[0]\n",
    "\n",
    "    flat = y.reshape(B, -1).contiguous()\n",
    "    F = flat.shape[1]\n",
    "\n",
    "    if pad:\n",
    "        flat = torch.cat(\n",
    "            [flat, torch.zeros(B, pad, device=y.device, dtype=y.dtype)],\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "    Fp = flat.shape[1]\n",
    "\n",
    "    g = flat.reshape(B, Fp // 4, 4)\n",
    "    x = h4_inv(g)\n",
    "\n",
    "    x = x.reshape(B, Fp)\n",
    "    if pad:\n",
    "        x = x[:, :-pad]\n",
    "\n",
    "    return x.reshape(shp)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0811f3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7684e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(64,32,8,8,device='cuda')\n",
    "\n",
    "y, pad = hadamard_auto(x)\n",
    "xr = hadamard_auto_inv(y,  pad)\n",
    "\n",
    "print((x-xr).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9642a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 8, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7831a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f3f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(8, 512, 32, 32, device='cuda')\n",
    "x2 = x.permute(1, 0, 2, 3).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09324187",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_torch = x2.reshape(512, -1)\n",
    "x2_cupy = cp.from_dlpack(torch.utils.dlpack.to_dlpack(x2_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c71471de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 8192)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_cupy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2db3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_res = cp.dot(x2_cupy, x2_cupy.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7756ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "\n",
    "U, S, _ = cp.linalg.svd(x_res, full_matrices=False)\n",
    "P = U[:, :k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1c1c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rank_x2 = cp.dot(P.T, x2_cupy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf0f45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rank_x2_new = low_rank_x2.reshape(8, 8, 32, 32).transpose(1, 0, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "132f5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rank_x2_new_torch = torch.utils.dlpack.from_dlpack(low_rank_x2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df6ec07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_rank_x2_new_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfefa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, _ = cp.linalg.svd(x2_cupy, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14ba914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = (S**2)\n",
    "ratio = cp.cumsum(energy) / cp.sum(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b597e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = cp.searchsorted(ratio, cp.array(0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e64184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(34)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fca506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, H, W = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e07ee8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 17408 into shape (34, 8, 32, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[43mU\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mcupy/_core/core.pyx:858\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.reshape\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_manipulation.pyx:82\u001b[0m, in \u001b[0;36mcupy._core._routines_manipulation._ndarray_reshape\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_manipulation.pyx:351\u001b[0m, in \u001b[0;36mcupy._core._routines_manipulation._reshape\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/internal.pyx:208\u001b[0m, in \u001b[0;36mcupy._core.internal.infer_unknown_dimension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 17408 into shape (34, 8, 32, 32)"
     ]
    }
   ],
   "source": [
    "new = U[:, :k].reshape(int(k), B, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d0b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lib)",
   "language": "python",
   "name": "lib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
