{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c81cfe9",
   "metadata": {},
   "source": [
    "/storage/ice1/shared/d-pace_community/makerspace-datasets/IMAGE/Imagenet2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e96b8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/yyu496/.conda/envs/lib/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# os.environ[\"TORCH_LOGS\"] = \"output_code\"\n",
    "# os.environ[\"TORCH_LOGS\"] = \"inductor\"\n",
    "# os.environ[\"TORCHINDUCTOR_TRACE\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_VERBOSE\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_DEBUG\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_DUMP\"] = \"1\"\n",
    "# os.environ[\"TORCHINDUCTOR_COMPILE_THREADS\"] = \"1\"\n",
    "# os.environ[\"TORCH_COMPILE_DEBUG\"] = \"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = (\n",
    "    # \"backend:cudaMallocAsync,\"\n",
    "    \"expandable_segments:True,\"\n",
    "    # \"garbage_collection_threshold:0.6\"\n",
    ")\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import collections\n",
    "collections.Iterable = Iterable\n",
    "import webdataset as wds\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/hice1/yyu496/kaggle/CW')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch._functorch.aot_autograd import aot_module, make_boxed_func\n",
    "from torch.autograd import grad\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import (\n",
    "    LinearLR,\n",
    "    CosineAnnealingLR,\n",
    "    SequentialLR\n",
    ")\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch._dynamo as dynamo\n",
    "import torch.nn.utils.parametrize as P\n",
    "from torch.nn.utils.parametrizations import spectral_norm\n",
    "\n",
    "import cpp_extension as cpp_extension\n",
    "\n",
    "from controller import Controller\n",
    "import cuda_graph_utils as cuda_utils\n",
    "from layers import RMSNorm, DOConv2d, DOConv1d, DOLinear\n",
    "from modules.activations.act_layers import DOReLU_Variance, DOSiLU, DOGELU\n",
    "from fusion.fused_layers import DOBatchNormReLU2d\n",
    "from freq_utils import radial_spectrum_2d, wasserstein, kl_div_spectrum\n",
    "from ViT import VisionTransformerFreq, VisionTransformerFreqStrong\n",
    "# from FreqViT import VisionTransformerFreqV2\n",
    "from FreqViT import VisionTransformerFreqV4\n",
    "# from VT_test import VisionTransformerV2, VisionTransformer\n",
    "from VT_test import VisionTransformerV3\n",
    "\n",
    "import timm\n",
    "from timm.layers import trunc_normal_\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import triton\n",
    "\n",
    "import actnn\n",
    "# available choices are [\"L0\", \"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]\n",
    "actnn.set_optimization_level(\"L3\")\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad128bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "warmup_epochs = 10\n",
    "num_epochs = 512\n",
    "# ============= Data ==================\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "transform_train = v2.Compose([\n",
    "    # --- Convert to tensor FIRST (kills PIL early) ---\n",
    "    v2.ToImage(),                          # handles PIL → Tensor safely\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "\n",
    "    # --- Geometry ---\n",
    "    v2.Resize((224, 224), antialias=True),\n",
    "    # v2.Resize((112, 112), antialias=True),\n",
    "    # v2.RandomResizedCrop(224, scale=(0.5, 1.0), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    # --- Color ---\n",
    "    v2.RandomApply([\n",
    "        v2.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.1\n",
    "        )\n",
    "    ], p=0.5),\n",
    "\n",
    "    # --- RandAugment (vectorized, NO PIL) ---\n",
    "    v2.RandAugment(num_ops=5, magnitude=9),\n",
    "\n",
    "    # --- Normalize ---\n",
    "    v2.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "\n",
    "    # --- Random Erasing (tensor-based, fast) ---\n",
    "    v2.RandomErasing(p=0.5, scale=(0.02, 0.33),\n",
    "                     ratio=(0.3, 3.3), value=0),\n",
    "])\n",
    "\n",
    "check_transform = v2.Compose([\n",
    "    v2.ToImage(),                          \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "\n",
    "    v2.Resize((224, 224), antialias=True),\n",
    "    # v2.Resize((112, 112), antialias=True),\n",
    "\n",
    "    v2.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "\n",
    "#/home/hice1/yyu496/scratch/data/cifar10_resized/train\n",
    "# /storage/ice1/shared/d-pace_community/makerspace-datasets/IMAGE/Imagenet2012/train\n",
    "#/storage/ice1/shared/d-pace_community/makerspace-datasets/IMAGE/CIFAR-10-images\n",
    "# check_set = ImageFolder(\n",
    "#     root=\"/home/hice1/yyu496/scratch/data/cifar10_resized/train\",\n",
    "#     transform=check_transform\n",
    "# )\n",
    "check_set = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "        download=True, transform=check_transform)\n",
    "\n",
    "check_loder = DataLoader(\n",
    "    check_set, batch_size=64, shuffle=True,\n",
    "    num_workers=15, pin_memory=True, drop_last=True,\n",
    "    persistent_workers=True, prefetch_factor=3\n",
    ")\n",
    "\n",
    "# download and prepare\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                 download=True, transform=transform_train)\n",
    "# train_dataset = ImageFolder(\n",
    "#     root=\"/home/hice1/yyu496/scratch/data/cifar10_resized/train\",\n",
    "#     transform=transform_train\n",
    "# )\n",
    "\n",
    "# DataLoader with GPU-friendly settings\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=15, pin_memory=True, drop_last=True,\n",
    "                          persistent_workers=True, prefetch_factor=3)\n",
    "\n",
    "TRAIN_PATH = \"/home/hice1/yyu496/scratch/data/cifar10_shards/train/train-{000000..000009}.tar\"\n",
    "VAL_PATH   = \"/home/hice1/yyu496/scratch/data/cifar10_shards/val/val-{000000..000001}.tar\"\n",
    "\n",
    "\n",
    "# trainset = (\n",
    "#     wds.WebDataset(wds.ResampledShards(TRAIN_PATH), empty_check=False)\n",
    "#     .shuffle(256)                          # small buffer is enough for CIFAR\n",
    "#     .decode(\"torch\")\n",
    "#     .to_tuple(\"png\", \"cls\")\n",
    "#     .batched(batch_size, partial=False)    # batch FIRST\n",
    "#     .map(lambda b: (transform_train(b[0]), b[1]))   # transform the whole batch\n",
    "# )\n",
    "\n",
    "# train_loader = (\n",
    "#     wds.WebLoader(\n",
    "#         trainset,\n",
    "#         batch_size=None,                   # already batched\n",
    "#         num_workers=2,                     # CIFAR: 2–4 is plenty\n",
    "#         pin_memory=True,\n",
    "#         persistent_workers=False,          # IMPORTANT for RSS not to accumulate\n",
    "#         prefetch_factor=2,\n",
    "#     )\n",
    "#     .with_epoch(50000 // batch_size)\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "\n",
    "    v2.Resize((224, 224), antialias=True),\n",
    "    # v2.Resize((112, 112), antialias=True),\n",
    "\n",
    "    v2.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# /storage/ice1/shared/d-pace_community/makerspace-datasets/IMAGE/Imagenet2012/val\n",
    "# /storage/ice1/shared/d-pace_community/makerspace-datasets/IMAGE/CIFAR-10-images/test\n",
    "#/home/hice1/yyu496/scratch/data/cifar10_resized/test\n",
    "# === CIFAR-10 validation dataset (train=False) ===\n",
    "val_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform\n",
    ")\n",
    "# val_dataset = ImageFolder(\n",
    "#     root=\"/home/hice1/yyu496/scratch/data/cifar10_resized/test\",\n",
    "#     transform=val_transform\n",
    "# )\n",
    "\n",
    "# === Validation DataLoader ===\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=False,   \n",
    "    num_workers=15,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True, \n",
    "    prefetch_factor=3\n",
    ")\n",
    "# valset = (\n",
    "#     wds.WebDataset(VAL_PATH, shardshuffle=False, empty_check=False)\n",
    "#     .decode(\"torch\")\n",
    "#     .to_tuple(\"png\", \"cls\")\n",
    "#     .batched(128, partial=False)\n",
    "#     .map(lambda b: (val_transform(b[0]), b[1]))\n",
    "# )\n",
    "\n",
    "# val_loader = (\n",
    "#     wds.WebLoader(\n",
    "#         valset,\n",
    "#         batch_size=None,\n",
    "#         num_workers=1,\n",
    "#         pin_memory=True,\n",
    "#         persistent_workers=False,\n",
    "#         prefetch_factor=2,\n",
    "\n",
    "#     )\n",
    "#     .with_epoch(10000 // 128)\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "def mixup_cutmix(x, y, alpha=1.0, p_cutmix=0.5):\n",
    "    if alpha <= 0:\n",
    "        return x, y\n",
    "\n",
    "    lam = torch.distributions.Beta(alpha, alpha).sample().to(x.device)\n",
    "\n",
    "    b = x.size(0)\n",
    "    perm = torch.randperm(b, device=x.device)\n",
    "    x2, y2 = x[perm], y[perm]\n",
    "\n",
    "    H, W = x.shape[-2:]\n",
    "\n",
    "    if torch.rand(()) < p_cutmix:\n",
    "        # ---- CutMix ----\n",
    "        cx = torch.randint(W, (1,), device=x.device)\n",
    "        cy = torch.randint(H, (1,), device=x.device)\n",
    "\n",
    "        w = (W * torch.sqrt(1 - lam)).long()\n",
    "        h = (H * torch.sqrt(1 - lam)).long()\n",
    "\n",
    "        x1 = torch.clamp(cx - w // 2, 0, W)\n",
    "        x2b = torch.clamp(cx + w // 2, 0, W)\n",
    "        y1 = torch.clamp(cy - h // 2, 0, H)\n",
    "        y2b = torch.clamp(cy + h // 2, 0, H)\n",
    "\n",
    "        x[:, :, y1:y2b, x1:x2b] = x2[:, :, y1:y2b, x1:x2b]\n",
    "        lam = 1 - ((x2b-x1)*(y2b-y1) / (W*H))\n",
    "    else:\n",
    "        # ---- Mixup ----\n",
    "        x = lam * x + (1 - lam) * x2\n",
    "\n",
    "    return x, (y, y2, lam)\n",
    "\n",
    "def replace_activation_func(m):\n",
    "    for name, child in m.named_children():\n",
    "        if isinstance(child, nn.ReLU):\n",
    "            setattr(m, name, nn.SiLU(inplace=True))\n",
    "            # setattr(m, name, nn.ReLU6(inplace=True))\n",
    "            # setattr(m, name, nn.LeakyReLU(inplace=True))\n",
    "            # setattr(m, name, nn.GELU())\n",
    "        else:\n",
    "            replace_activation_func(child)\n",
    "\n",
    "\n",
    "def replace_norm(m):\n",
    "    for name, child in m.named_children():\n",
    "        if isinstance(child, nn.LayerNorm):\n",
    "            setattr(m, name, RMSNorm(dims=child.normalized_shape[-1]))\n",
    "        else:\n",
    "            replace_activation_func(child)\n",
    "\n",
    "\n",
    "def disable_act_inplace(m):\n",
    "    for module in m.modules():\n",
    "        if isinstance(module, (nn.ReLU, nn.SiLU, nn.GELU, nn.ReLU6)) and hasattr(module, 'inplace'):\n",
    "            module.inplace = False\n",
    "\n",
    "def set_seed(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "def init_fan_out(m):\n",
    "    if isinstance(m, (nn.Conv2d,)):\n",
    "        nn.init.kaiming_normal_(\n",
    "            m.weight,\n",
    "            mode='fan_out',\n",
    "            nonlinearity='relu'\n",
    "        )\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(\n",
    "            m.weight,\n",
    "            mode='fan_in',\n",
    "            nonlinearity='relu'\n",
    "        )\n",
    "\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "def apply_trunc_init_for_act(module, std=0.02):\n",
    "    \"\"\"\n",
    "    Truncated normal init tuned for ACT stability.\n",
    "    Applies only to ACT-sensitive layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Convs (ACT-fragile entry + transition layers) ----\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        # stem conv or downsample conv benefit most\n",
    "        if module.kernel_size[0] > 1 or module.in_channels < module.out_channels:\n",
    "            trunc_normal_(module.weight, std=std)\n",
    "        else:\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    # ---- Linear layers (ViT / MLP / projections) ----\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        trunc_normal_(module.weight, std=std)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    # ---- BatchNorm / LayerNorm ----\n",
    "    elif isinstance(module, (nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm)):\n",
    "        nn.init.ones_(module.weight)\n",
    "        nn.init.zeros_(module.bias)\n",
    "\n",
    "\n",
    "\n",
    "def init_orthogonal_conv(m, gain=1.0):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.orthogonal_(m.weight, gain=gain)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # nn.init.orthogonal_(m.weight, gain=gain)\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "def init_orthogonal_conv_v2(n, m, gain=1.0):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.orthogonal_(m.weight, gain=gain)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    if n == 'layer2.0.conv1' and isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "        print('True')\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # nn.init.orthogonal_(m.weight, gain=gain)\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1f5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_cache = {}\n",
    "def forward_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        global act_cache\n",
    "        act_cache[name] = output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19dbf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)\n"
     ]
    }
   ],
   "source": [
    "# DIVISION = {\n",
    "#     'pool_kernel_size' : 3\n",
    "# }\n",
    "\n",
    "DIVISION = None\n",
    "\n",
    "config = {\n",
    "    \"default_bits\": 2,\n",
    "    'analyze' : False,\n",
    "    'auto_precision': None,\n",
    "    'DIVISION' : DIVISION,\n",
    "    'AVG_ALAM' : False,\n",
    "    \"AVG_ALAM_BTS\" : 4,\n",
    "    \"group_size\": 256,\n",
    "    'batch_size' : batch_size,\n",
    "    'fp8' : False,\n",
    "    'depth_point_conv' : False,\n",
    "    'rms_norm' : False\n",
    "}\n",
    "\n",
    "# vit_base_patch16_224\n",
    "# efficientnet_b0\n",
    "num_classes = 10\n",
    "# model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "# replace_activation_func(model)\n",
    "# replace_norm(model)\n",
    "# model = VisionTransformer(\n",
    "#     image_size=224,\n",
    "#     patch_size=16,\n",
    "#     in_channels=3,\n",
    "#     num_classes=num_classes,\n",
    "#     embed_dim=384,\n",
    "#     depth=8,\n",
    "#     num_head=6,\n",
    "#     mlp_ratio=4.0,\n",
    "#     attn_p=0.2,\n",
    "#     mlp_p=0.0,\n",
    "#     pos_p=0.0\n",
    "# ).cuda()\n",
    "\n",
    "# model = VisionTransformerV2(\n",
    "#     image_size=224,\n",
    "#     patch_size=16,\n",
    "#     in_channels=3,\n",
    "#     num_classes=num_classes,\n",
    "#     embed_dim=384,\n",
    "#     depth=8,\n",
    "#     num_head=6,\n",
    "#     mlp_ratio=4.0,\n",
    "#     attn_p=0.2,\n",
    "#     mlp_p=0.0,\n",
    "#     pos_p=0.0\n",
    "# ).cuda()\n",
    "\n",
    "model = VisionTransformerV3(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    in_channels=3,\n",
    "    num_classes=num_classes,\n",
    "    embed_dim=384,\n",
    "    depth=8,\n",
    "    num_head=6,\n",
    "    mlp_ratio=4.0,\n",
    "    attn_p=0.2,\n",
    "    mlp_p=0.0,\n",
    "    pos_p=0.0\n",
    ").cuda()\n",
    "\n",
    "# model = VisionTransformerFreq(\n",
    "#         in_channels=3, num_classes=10,\n",
    "#         image_size=224, patch_size=16,\n",
    "#         embed_dim=384, depth=8, num_head=6, mlp_ratio=4.0,\n",
    "#         attn_p=0.2, mlp_p=0.0, pos_p=0.0,\n",
    "#         num_freq_bins=16,\n",
    "#         use_proxy_head=False,\n",
    "#         inject_every_block=False,\n",
    "#         injector_init_scale=1.0,\n",
    "#     ).cuda()\n",
    "\n",
    "# model = VisionTransformerFreqV2(\n",
    "#     in_channels=3,\n",
    "#     num_classes=10,\n",
    "#     image_size=224,\n",
    "#     patch_size=16,\n",
    "#     embed_dim=384,\n",
    "#     depth=12,\n",
    "#     num_head=6,\n",
    "#     freq_bins=16,\n",
    "#     inject_every_block=True,\n",
    "#     injector_scale=0.05,\n",
    "#     use_proxy_head=False,\n",
    "# )\n",
    "# model = VisionTransformerFreqV2(\n",
    "#         in_channels=3,\n",
    "#         num_classes=10,\n",
    "#         image_size=224,\n",
    "#         patch_size=16,\n",
    "#         embed_dim=384,\n",
    "#         depth=12,\n",
    "#         num_head=6,\n",
    "#         num_bands=6,\n",
    "#         inject_patchwise_bias=True,\n",
    "#         anchor_freq_token=True,\n",
    "#     )\n",
    "# model = VisionTransformerFreqStrong(\n",
    "#     in_channels = 3,\n",
    "#     num_classes = 10,\n",
    "#     image_size = 224,\n",
    "#     patch_size = 16,\n",
    "#     embed_dim = 768,\n",
    "#     depth = 12,\n",
    "#     num_head = 12,\n",
    "#     mlp_ratio = 4.0,\n",
    "#     attn_p = 0.0,\n",
    "#     mlp_p = 0.0,\n",
    "#     pos_p = 0.0,\n",
    "#     num_bands = 8,\n",
    "#     retain_scale = 0.5,\n",
    "#     anchor_freq_token = True,\n",
    "#     anchor_weight = 0.04,\n",
    "# )\n",
    "\n",
    "\n",
    "# model = VisionTransformerFreqV3(\n",
    "#         in_channels=3,\n",
    "#         num_classes=10,\n",
    "#         image_size=224,\n",
    "#         patch_size=16,\n",
    "#         embed_dim=384,\n",
    "#         depth=8,\n",
    "#         num_head=6,\n",
    "#         mlp_ratio=4.0,\n",
    "#         attn_p=0.2,\n",
    "#         proxy_channels=8,\n",
    "#         radial_bins=4,\n",
    "#         angular_bins=4,\n",
    "#         alpha=0.10,\n",
    "#         detach_freq_token_update=True,\n",
    "#     )\n",
    "# model = VisionTransformerFreqV4(\n",
    "#         in_channels = 3,\n",
    "#         num_classes = num_classes,\n",
    "#         image_size = 224,\n",
    "#         patch_size = 16,\n",
    "#         embed_dim = 384,\n",
    "#         depth = 8,\n",
    "#         num_head = 6,\n",
    "#         mlp_ratio = 4.0,\n",
    "#         attn_p = 0.0,\n",
    "#         mlp_p = 0.0,\n",
    "#         pos_p = 0.0,\n",
    "#         proxy_channels = 8,\n",
    "#         radial_bins = 4,\n",
    "#         angular_bins = 4,\n",
    "#         detach_freq_token_update = True,\n",
    "#         detach_spec_from_patch = True,\n",
    "#         alpha = 0.10,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# set_seed(2)\n",
    "# model = models.resnet44(weights=None)\n",
    "# model = models.resnet50(weights=None)\n",
    "# model = models.resnet18(weights=None)\n",
    "# model = models.efficientnet_b0(weights=None)\n",
    "# model = models.mobilenet_v2(weights=None)\n",
    "# model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "# replace_activation_func(model)\n",
    "disable_act_inplace(model)\n",
    "# model.apply(lambda m: apply_trunc_init_for_act(m, std=0.02))\n",
    "# model.apply(init_fan_out)\n",
    "# model.apply(lambda m: init_orthogonal_conv(m, gain=math.sqrt(2)))\n",
    "# init(model)\n",
    "# model.load_state_dict(torch.load(\"/home/hice1/yyu496/scratch/Model_Checkpoint/ResNet18_bs_8192_5.pth\"))\n",
    "\n",
    "\n",
    "# model = actnn.QModule(model)\n",
    "# model.cuda()\n",
    "# model.compile(fullgraph=True)\n",
    "\n",
    "\n",
    "# set_seed(49)\n",
    "# torch.set_rng_state(cached_rng_state['CPU'])\n",
    "# torch.cuda.set_rng_state(cached_rng_state['GPU'])\n",
    "# model.load_state_dict(baseline)\n",
    "# disable_act_inplace(model)\n",
    "# # init(model)\n",
    "# for n, m in model.named_modules():\n",
    "#     if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Linear)):\n",
    "#             cahced_init(m.weight)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# compute_stream = torch.cuda.Stream()\n",
    "# controller = Controller(model, config, check_loder, criterion, test=False)\n",
    "# controller.iterate(criterion)\n",
    "# controller.warp_model(graph_mode=True, quantizer=True)\n",
    "# controller.warmup(train_loader, criterion, compute_stream)\n",
    "\n",
    "# blocks.7.mlp.depthconv1\n",
    "# blocks.7.mlp.pointconv2\n",
    "# patch_embed.proj\n",
    "# blocks.11.mlp.fc2\n",
    "# layer4.2.conv3\n",
    "# layer4.1.conv2\n",
    "# features.8.0\n",
    "# features.18.0\n",
    "#'features.8.0' in name or \"features.6.2.block.0.0\" in name or \"features.5.1.block.0.0\" in\n",
    "\n",
    "# for name, module in controller.traced_model.named_modules():\n",
    "#     if isinstance(module, (DOConv2d, DOConv1d, DOLinear)):\n",
    "#         if 'blocks.7.mlp.pointconv2' in name:\n",
    "#             m = module.register_forward_hook(forward_hook(name))\n",
    "#             print(module)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Conv1d)):\n",
    "        if 'blocks.7.mlp.depthconv1' in name:\n",
    "            m = module.register_forward_hook(forward_hook(name))\n",
    "            print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d10e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 14.70 M\n"
     ]
    }
   ],
   "source": [
    "# num_params = sum(p.numel() for p in controller.traced_model.parameters())\n",
    "# print(f\"Total params: {num_params/1e6:.2f} M\")\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {num_params/1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962045d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_LARS(Optimizer):\n",
    "    def __init__(self,\n",
    "                 params,\n",
    "                 lr=0.1,\n",
    "                 momentum=0.9,\n",
    "                 weight_decay=1e-4,\n",
    "                 eta=0.1,\n",
    "                 eps=1e-9,\n",
    "                 nesterov=False,\n",
    "                 trust_coef=True):\n",
    "        defaults = dict(lr=lr,\n",
    "                        momentum=momentum,\n",
    "                        weight_decay=weight_decay,\n",
    "                        eta=eta,\n",
    "                        eps=eps,\n",
    "                        nesterov=nesterov,\n",
    "                        trust_coef=trust_coef)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            momentum = group['momentum']\n",
    "            weight_decay = group['weight_decay']\n",
    "            eta = group['eta']\n",
    "            eps = group['eps']\n",
    "            nesterov = group['nesterov']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                grad = p.grad\n",
    "\n",
    "                # ---- decoupled weight decay ----\n",
    "                if weight_decay != 0 and p.ndim > 1:\n",
    "                    grad = grad.add(p, alpha=weight_decay)\n",
    "\n",
    "                # ---- LARS trust ratio (only apply to weight tensors) ----\n",
    "                if p.ndim > 1:      # don't LARS biases / norms\n",
    "                    w_norm = p.norm()\n",
    "                    g_norm = grad.norm()\n",
    "                    trust_ratio = 0\n",
    "\n",
    "                    # if not torch.isfinite(grad).all():\n",
    "                    #     print(\"grad has NaN/Inf\")\n",
    "                    # if not torch.isfinite(w_norm):\n",
    "                    #     print(\"w_norm NaN/Inf:\", w_norm.item())\n",
    "                    # if not torch.isfinite(g_norm):\n",
    "                    #     print(\"g_norm NaN/Inf:\", g_norm.item())\n",
    "\n",
    "                    if w_norm > 0 and g_norm > 0:\n",
    "                        trust_ratio = eta * (w_norm / (g_norm + eps))\n",
    "                    else:\n",
    "                        trust_ratio = 1.0\n",
    "\n",
    "                    # if not torch.isfinite(trust_ratio):\n",
    "                    #     print(\"trust_ratio NaN/Inf:\", trust_ratio.item())\n",
    "                    # print(\"trust_ratio\", trust_ratio.item(), \"dw_norm\", g_norm.item(), \"w_norm\", w_norm.item())\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    trust_ratio = 1.0\n",
    "\n",
    "                scaled_lr = lr * trust_ratio\n",
    "\n",
    "                # ---- Momentum buffer ----\n",
    "                param_state = self.state[p]\n",
    "                if 'momentum_buffer' not in param_state:\n",
    "                    buf = param_state['momentum_buffer'] = torch.zeros_like(p)\n",
    "                else:\n",
    "                    buf = param_state['momentum_buffer']\n",
    "\n",
    "                buf.mul_(momentum).add_(grad)  # standard momentum update\n",
    "\n",
    "                if nesterov:\n",
    "                    update = grad.add(buf, alpha=momentum)\n",
    "                else:\n",
    "                    update = buf\n",
    "\n",
    "                # ---- Update weights ----\n",
    "                p.add_(update, alpha=-scaled_lr)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb276b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accuracy(task='multiclass', num_classes=10, average='macro')\n",
    "\n",
    "# opt = torch.optim.SGD([torch.tensor([0.], device='cuda', requires_grad=True)], lr=1e-2 * 5)\n",
    "\n",
    "# opt = torch.optim.AdamW(controller.traced_model.parameters(), lr=(1e-5 * 8), weight_decay=1e-4, fused=True, capturable=True)\n",
    "# opt.load_state_dict(torch.load('/home/hice1/yyu496/scratch/Model_Checkpoint/ResNet18_bs_8192_opt_6.pth'))\n",
    "# opt = SGD_LARS(\n",
    "#     controller.traced_model.parameters(),\n",
    "#     lr=1e-3 * 8,                     # LARS needs high LR\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=1e-7,          # decoupled weight decay\n",
    "#     eta=0.1,                  # LARS coefficient (0.001–0.02)\n",
    "#     nesterov=True\n",
    "# )\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=(1e-5 * 8), fused=True, capturable=True)\n",
    "# opt = SGD_LARS(\n",
    "#     model.parameters(),\n",
    "#     lr=1.0,                     # LARS needs high LR\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=1e-7,          # decoupled weight decay\n",
    "#     eta=0.001,                  # LARS coefficient (0.001–0.02)\n",
    "#     nesterov=False\n",
    "# )\n",
    "\n",
    "\n",
    "total_timer_start = torch.cuda.Event(enable_timing=True)\n",
    "total_timer_end = torch.cuda.Event(enable_timing=True)\n",
    "total_time = 0.0\n",
    "\n",
    "e_timer_start = torch.cuda.Event(enable_timing=True)\n",
    "e_timer_end = torch.cuda.Event(enable_timing=True)\n",
    "partile_time = 0.0\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     opt,\n",
    "#     1e-3,\n",
    "#     total_steps= num_epochs * len(train_loader),\n",
    "#     pct_start=0.1,\n",
    "#     div_factor=10,\n",
    "#     final_div_factor=1000\n",
    "# )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "#     opt,\n",
    "#     T_0=10,\n",
    "#     T_mult=2,\n",
    "#     eta_min=1e-5\n",
    "# )\n",
    "\n",
    "warmup_sched = LinearLR(\n",
    "    opt,\n",
    "    start_factor=0.5,   # lr = lr * start_factor\n",
    "    end_factor=1.0,    # lr = lr * end_factor = lr\n",
    "    total_iters=warmup_epochs\n",
    ")\n",
    "\n",
    "# 2. Cosine decay\n",
    "cosine_sched = CosineAnnealingLR(\n",
    "    opt,\n",
    "    T_max=num_epochs - warmup_epochs,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# 3. Combine them\n",
    "scheduler = SequentialLR(\n",
    "    opt,\n",
    "    schedulers=[warmup_sched, cosine_sched],\n",
    "    milestones=[warmup_epochs]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f1d2f4",
   "metadata": {},
   "source": [
    "cuda_graph_generator = cuda_utils.Graph(controller.traced_model,\n",
    "                                        criterion,\n",
    "                                        opt,\n",
    "                                        train_loader,\n",
    "                                        compute_stream,\n",
    "                                        mode='qdrop',\n",
    "                                        num_of_graph=1,\n",
    "                                        device='cuda')\n",
    "\n",
    "\n",
    "# cuda_graph_generator = cuda_utils.Graph(model,\n",
    "#                                         criterion,\n",
    "#                                         opt,\n",
    "#                                         train_loader,\n",
    "#                                         compute_stream,\n",
    "#                                         mode='qdrop',\n",
    "#                                         num_of_graph=1,\n",
    "#                                         device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530033ff",
   "metadata": {},
   "source": [
    "graphs, compute_stream, static_x, static_y, logits, loss = cuda_graph_generator.capture_cuda_graph_qdrop()\n",
    "\n",
    "total_graphs = cuda_graph_generator.num_of_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833f0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def lowpass_param_2d(t: torch.Tensor, k: int = 3):\n",
    "    if t.ndim != 4:\n",
    "        return t\n",
    "\n",
    "    *prefix, H, W = t.shape\n",
    "    if H < k or W < k:\n",
    "        return t  # nothing to do, kernel larger than spatial size\n",
    "\n",
    "    # Merge prefix dims into batch*channels, so shape -> [N, 1, H, W]\n",
    "    t_flat = t.view(-1, 1, H, W)\n",
    "    t_l = F.avg_pool2d(t_flat, kernel_size=k, stride=1, padding=k // 2)\n",
    "    t_l = F.interpolate(t_l, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    return t_l.view_as(t)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inject_grad_noise_large_batch(\n",
    "    model,\n",
    "    step,\n",
    "    batch_size,\n",
    "    total_samples,\n",
    "    base_std=1,\n",
    "    gamma=0.55,\n",
    "    lp_kernel: int = 3\n",
    "):\n",
    "    # Large-batch SGD noise recovery term\n",
    "    gns_scale = (1.0 / batch_size - 1.0 / total_samples) ** 0.5\n",
    "    decay = 1.0 / ((1 + step) ** gamma)\n",
    "\n",
    "    for p in model.parameters():\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "\n",
    "        # Skip bias / norm (critical for ViT & BN stability)\n",
    "        if p.ndim == 1:\n",
    "            continue\n",
    "\n",
    "\n",
    "        grad_std = p.grad.std().clamp(min=1e-6)\n",
    "\n",
    "        noise = torch.randn_like(p.grad) * base_std * gns_scale * grad_std * decay\n",
    "\n",
    "        if lp_kernel is not None and lp_kernel > 1:\n",
    "            noise = lowpass_param_2d(noise, k=lp_kernel)\n",
    "\n",
    "        p.grad.add_(noise)\n",
    "\n",
    "\n",
    "def update_lr(model, scheduler):\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "    for m in model.modules():\n",
    "        if hasattr(m, 'ema_grad_meta'):\n",
    "            m.ema_grad_meta['lr'].copy_(lr)\n",
    "\n",
    "\n",
    "def checkpoint_save_helper(model, acc, max_acc, opt):\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        torch.save(model.state_dict(), \"/home/hice1/yyu496/scratch/Model_Checkpoint/ResNet18_bs_8192_6.pth\")\n",
    "        torch.save(opt.state_dict(), '/home/hice1/yyu496/scratch/Model_Checkpoint/ResNet18_bs_8192_opt_6.pth')\n",
    "        return max_acc\n",
    "    return max_acc\n",
    "\n",
    "\n",
    "def freq_weight(step, warmup_steps=5000, max_w=0.1):\n",
    "    if step >= warmup_steps:\n",
    "        return max_w\n",
    "    t = step / warmup_steps\n",
    "    return max_w * t\n",
    "\n",
    "\n",
    "def debug_check_grads_and_step(model, optimizer):\n",
    "    # 1) check any grad exists\n",
    "    gsum = 0.0\n",
    "    gmax = 0.0\n",
    "    n = 0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "        gn = p.grad.detach().float().norm().item()\n",
    "        gsum += gn\n",
    "        gmax = max(gmax, gn)\n",
    "        n += 1\n",
    "    print(f\"[debug] grad tensors: {n}, grad_norm_sum: {gsum:.4e}, grad_norm_max: {gmax:.4e}\")\n",
    "\n",
    "    # 2) check that optimizer actually changes weights\n",
    "    p0 = None\n",
    "    for p in model.parameters():\n",
    "        if p.requires_grad:\n",
    "            p0 = p.detach().clone()\n",
    "            p_ref = p\n",
    "            break\n",
    "    if p0 is None:\n",
    "        print(\"[debug] no trainable parameter found!\")\n",
    "        return\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    delta = (p0 - p_ref.detach()).abs().mean().item()\n",
    "    print(f\"[debug] mean |Δparam| after step: {delta:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441888b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 3.0790367126464844\n",
      "CE Loss: 2.0988311767578125, Freq(freq) Loss1: 0.9802054166793823\n",
      "Learning Rate: 4e-05\n",
      "Train Accuracy: 0.20214886963367462\n",
      "Peak Mem Reserved: 23662166016\n",
      "Peak Mem Allocated: 21414108160\n",
      "Current train time: 27.949401397705078 s\n",
      "Throughout: 1788.94707934981 samples per second\n",
      "Val Loss: 1.7890625\n",
      "Val Accuracy: 0.30869999527931213\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "Train Loss: 2.819697141647339\n",
      "CE Loss: 1.8394660949707031, Freq(freq) Loss1: 0.9802310466766357\n",
      "Learning Rate: 4.4000000000000006e-05\n",
      "Train Accuracy: 0.2716792821884155\n",
      "Peak Mem Reserved: 23662166016\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75529783630371 s\n",
      "Throughout: 2409.0234885737705 samples per second\n",
      "Val Loss: 1.703125\n",
      "Val Accuracy: 0.37560001015663147\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Train Loss: 2.819685935974121\n",
      "CE Loss: 1.840576171875, Freq(freq) Loss1: 0.9791098833084106\n",
      "Learning Rate: 4.8e-05\n",
      "Train Accuracy: 0.3106737732887268\n",
      "Peak Mem Reserved: 23769120768\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74214990234375 s\n",
      "Throughout: 2410.550508766223 samples per second\n",
      "Val Loss: 1.5859375\n",
      "Val Accuracy: 0.4237000048160553\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Train Loss: 2.667975425720215\n",
      "CE Loss: 1.6883430480957031, Freq(freq) Loss1: 0.9796324372291565\n",
      "Learning Rate: 5.2e-05\n",
      "Train Accuracy: 0.3412999212741852\n",
      "Peak Mem Reserved: 23769120768\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740167297363282 s\n",
      "Throughout: 2410.7809393782736 samples per second\n",
      "Val Loss: 1.515625\n",
      "Val Accuracy: 0.4578000009059906\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Train Loss: 2.674295663833618\n",
      "CE Loss: 1.696481704711914, Freq(freq) Loss1: 0.9778139591217041\n",
      "Learning Rate: 5.599999999999999e-05\n",
      "Train Accuracy: 0.36931607127189636\n",
      "Peak Mem Reserved: 23769120768\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743460479736328 s\n",
      "Throughout: 2410.3982095390265 samples per second\n",
      "Val Loss: 1.453125\n",
      "Val Accuracy: 0.47870004177093506\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Train Loss: 2.540214776992798\n",
      "CE Loss: 1.5611839294433594, Freq(freq) Loss1: 0.9790308475494385\n",
      "Learning Rate: 5.999999999999999e-05\n",
      "Train Accuracy: 0.3921826481819153\n",
      "Peak Mem Reserved: 23769120768\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746057693481447 s\n",
      "Throughout: 2410.0964500696605 samples per second\n",
      "Val Loss: 1.3984375\n",
      "Val Accuracy: 0.48989996314048767\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Train Loss: 2.5067028999328613\n",
      "CE Loss: 1.527602195739746, Freq(freq) Loss1: 0.9791007041931152\n",
      "Learning Rate: 6.399999999999998e-05\n",
      "Train Accuracy: 0.40977048873901367\n",
      "Peak Mem Reserved: 23769120768\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742212158203124 s\n",
      "Throughout: 2410.543273718566 samples per second\n",
      "Val Loss: 1.3671875\n",
      "Val Accuracy: 0.5158999562263489\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "Train Loss: 2.596451759338379\n",
      "CE Loss: 1.615762710571289, Freq(freq) Loss1: 0.9806889295578003\n",
      "Learning Rate: 6.799999999999999e-05\n",
      "Train Accuracy: 0.42564278841018677\n",
      "Peak Mem Reserved: 23769120768\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73860548400879 s\n",
      "Throughout: 2410.9624940092626 samples per second\n",
      "Val Loss: 1.296875\n",
      "Val Accuracy: 0.5493999719619751\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "Train Loss: 2.489497184753418\n",
      "CE Loss: 1.511505126953125, Freq(freq) Loss1: 0.9779921770095825\n",
      "Learning Rate: 7.199999999999999e-05\n",
      "Train Accuracy: 0.43845754861831665\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747532470703124 s\n",
      "Throughout: 2409.9251354638573 samples per second\n",
      "Val Loss: 1.2578125\n",
      "Val Accuracy: 0.5569000244140625\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "Train Loss: 2.3956735134124756\n",
      "CE Loss: 1.4169297218322754, Freq(freq) Loss1: 0.978743851184845\n",
      "Learning Rate: 7.599999999999999e-05\n",
      "Train Accuracy: 0.45108291506767273\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.735986068725587 s\n",
      "Throughout: 2411.2670520844417 samples per second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/yyu496/.conda/envs/lib/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.2578125\n",
      "Val Accuracy: 0.5562000274658203\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Train Loss: 2.4405410289764404\n",
      "CE Loss: 1.4619922637939453, Freq(freq) Loss1: 0.9785487651824951\n",
      "Learning Rate: 8e-05\n",
      "Train Accuracy: 0.46341997385025024\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743200119018553 s\n",
      "Throughout: 2410.428463935858 samples per second\n",
      "Val Loss: 1.1640625\n",
      "Val Accuracy: 0.5642000436782837\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "Train Loss: 2.4384372234344482\n",
      "CE Loss: 1.4610824584960938, Freq(freq) Loss1: 0.9773548245429993\n",
      "Learning Rate: 7.999922650413984e-05\n",
      "Train Accuracy: 0.4738887548446655\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740986038208007 s\n",
      "Throughout: 2410.6857749141 samples per second\n",
      "Val Loss: 1.1328125\n",
      "Val Accuracy: 0.5961999893188477\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "Train Loss: 2.392547130584717\n",
      "CE Loss: 1.4130148887634277, Freq(freq) Loss1: 0.9795323014259338\n",
      "Learning Rate: 7.99969060468528e-05\n",
      "Train Accuracy: 0.4813571572303772\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74178405761719 s\n",
      "Throughout: 2410.5930261885096 samples per second\n",
      "Val Loss: 1.171875\n",
      "Val Accuracy: 0.6011999845504761\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "Train Loss: 2.4718129634857178\n",
      "CE Loss: 1.4924966096878052, Freq(freq) Loss1: 0.9793164134025574\n",
      "Learning Rate: 7.999303871901808e-05\n",
      "Train Accuracy: 0.4960034191608429\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7425086517334 s\n",
      "Throughout: 2410.508817400041 samples per second\n",
      "Val Loss: 1.1328125\n",
      "Val Accuracy: 0.6057000160217285\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "Train Loss: 2.336143970489502\n",
      "CE Loss: 1.3575708866119385, Freq(freq) Loss1: 0.9785730838775635\n",
      "Learning Rate: 7.998762467209705e-05\n",
      "Train Accuracy: 0.5002040863037109\n",
      "Peak Mem Reserved: 24062722048\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74963801574707 s\n",
      "Throughout: 2409.680591153185 samples per second\n",
      "Val Loss: 1.0703125\n",
      "Val Accuracy: 0.6174999475479126\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "Train Loss: 2.2410593032836914\n",
      "CE Loss: 1.2614381313323975, Freq(freq) Loss1: 0.9796212911605835\n",
      "Learning Rate: 7.998066411812733e-05\n",
      "Train Accuracy: 0.5119936466217041\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746890014648436 s\n",
      "Throughout: 2409.999762118432 samples per second\n",
      "Val Loss: 1.0546875\n",
      "Val Accuracy: 0.6331000328063965\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "Train Loss: 2.297513961791992\n",
      "CE Loss: 1.3171141147613525, Freq(freq) Loss1: 0.9803999662399292\n",
      "Learning Rate: 7.997215732971448e-05\n",
      "Train Accuracy: 0.5193953514099121\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750569229125976 s\n",
      "Throughout: 2409.5724530688467 samples per second\n",
      "Val Loss: 1.03125\n",
      "Val Accuracy: 0.6345999836921692\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "Train Loss: 2.290719985961914\n",
      "CE Loss: 1.3121482133865356, Freq(freq) Loss1: 0.9785717129707336\n",
      "Learning Rate: 7.996210464002132e-05\n",
      "Train Accuracy: 0.5283252000808716\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740075057983397 s\n",
      "Throughout: 2410.7916610819443 samples per second\n",
      "Val Loss: 1.0625\n",
      "Val Accuracy: 0.6404999494552612\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "Train Loss: 2.275435447692871\n",
      "CE Loss: 1.2968165874481201, Freq(freq) Loss1: 0.9786187410354614\n",
      "Learning Rate: 7.995050644275484e-05\n",
      "Train Accuracy: 0.5364189743995667\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744895416259766 s\n",
      "Throughout: 2410.231480888074 samples per second\n",
      "Val Loss: 1.0\n",
      "Val Accuracy: 0.6504999995231628\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "Train Loss: 2.2597203254699707\n",
      "CE Loss: 1.2801764011383057, Freq(freq) Loss1: 0.9795438647270203\n",
      "Learning Rate: 7.99373631921509e-05\n",
      "Train Accuracy: 0.5485381484031677\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742795440673827 s\n",
      "Throughout: 2410.4754898154533 samples per second\n",
      "Val Loss: 1.0234375\n",
      "Val Accuracy: 0.6410999894142151\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "Train Loss: 2.1978306770324707\n",
      "CE Loss: 1.2196006774902344, Freq(freq) Loss1: 0.9782299995422363\n",
      "Learning Rate: 7.992267540295633e-05\n",
      "Train Accuracy: 0.5491116642951965\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.723630447387695 s\n",
      "Throughout: 2412.704671941432 samples per second\n",
      "Val Loss: 0.95703125\n",
      "Val Accuracy: 0.6517000198364258\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "Train Loss: 2.1912970542907715\n",
      "CE Loss: 1.2129521369934082, Freq(freq) Loss1: 0.9783450365066528\n",
      "Learning Rate: 7.99064436504088e-05\n",
      "Train Accuracy: 0.5572811365127563\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742120056152345 s\n",
      "Throughout: 2410.5539773485903 samples per second\n",
      "Val Loss: 0.98828125\n",
      "Val Accuracy: 0.6659999489784241\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "Train Loss: 2.2273433208465576\n",
      "CE Loss: 1.248695731163025, Freq(freq) Loss1: 0.9786475300788879\n",
      "Learning Rate: 7.988866857021432e-05\n",
      "Train Accuracy: 0.564188539981842\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74409704589844 s\n",
      "Throughout: 2410.3242425722306 samples per second\n",
      "Val Loss: 0.97265625\n",
      "Val Accuracy: 0.6663999557495117\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "Train Loss: 2.1595957279205322\n",
      "CE Loss: 1.180361032485962, Freq(freq) Loss1: 0.9792346954345703\n",
      "Learning Rate: 7.986935085852228e-05\n",
      "Train Accuracy: 0.5714735984802246\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.738489181518556 s\n",
      "Throughout: 2410.9760148081723 samples per second\n",
      "Val Loss: 0.92578125\n",
      "Val Accuracy: 0.6844000220298767\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "Train Loss: 2.282029628753662\n",
      "CE Loss: 1.3024038076400757, Freq(freq) Loss1: 0.9796257615089417\n",
      "Learning Rate: 7.984849127189828e-05\n",
      "Train Accuracy: 0.578612208366394\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742892654418945 s\n",
      "Throughout: 2410.4641928688907 samples per second\n",
      "Val Loss: 0.984375\n",
      "Val Accuracy: 0.667199969291687\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "Train Loss: 2.1463582515716553\n",
      "CE Loss: 1.1679103374481201, Freq(freq) Loss1: 0.9784479737281799\n",
      "Learning Rate: 7.982609062729438e-05\n",
      "Train Accuracy: 0.5847575664520264\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75256867980957 s\n",
      "Throughout: 2409.3402976493035 samples per second\n",
      "Val Loss: 0.875\n",
      "Val Accuracy: 0.6848000288009644\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "Train Loss: 2.0924084186553955\n",
      "CE Loss: 1.1135550737380981, Freq(freq) Loss1: 0.9788532853126526\n",
      "Learning Rate: 7.980214980201725e-05\n",
      "Train Accuracy: 0.5890944004058838\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753417922973632 s\n",
      "Throughout: 2409.2417058999695 samples per second\n",
      "Val Loss: 0.8984375\n",
      "Val Accuracy: 0.6754999756813049\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "Train Loss: 2.069268226623535\n",
      "CE Loss: 1.0911602973937988, Freq(freq) Loss1: 0.9781080484390259\n",
      "Learning Rate: 7.977666973369365e-05\n",
      "Train Accuracy: 0.5893888473510742\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75198895263672 s\n",
      "Throughout: 2409.407604934517 samples per second\n",
      "Val Loss: 0.86328125\n",
      "Val Accuracy: 0.7029000520706177\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "Train Loss: 2.1277060508728027\n",
      "CE Loss: 1.1493666172027588, Freq(freq) Loss1: 0.9783395528793335\n",
      "Learning Rate: 7.974965142023385e-05\n",
      "Train Accuracy: 0.5969175100326538\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741921798706056 s\n",
      "Throughout: 2410.5770181391367 samples per second\n",
      "Val Loss: 0.8203125\n",
      "Val Accuracy: 0.7179999947547913\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "Train Loss: 2.0355355739593506\n",
      "CE Loss: 1.0569732189178467, Freq(freq) Loss1: 0.9785623550415039\n",
      "Learning Rate: 7.972109591979244e-05\n",
      "Train Accuracy: 0.605731725692749\n",
      "Peak Mem Reserved: 24083693568\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.738790435791017 s\n",
      "Throughout: 2410.940992668018 samples per second\n",
      "Val Loss: 0.8125\n",
      "Val Accuracy: 0.7179000377655029\n",
      "\n",
      "\n",
      "Epoch: 30\n",
      "Train Loss: 2.034494400024414\n",
      "CE Loss: 1.0567946434020996, Freq(freq) Loss1: 0.9776996374130249\n",
      "Learning Rate: 7.969100435072698e-05\n",
      "Train Accuracy: 0.6100283265113831\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.726474533081056 s\n",
      "Throughout: 2412.3736007392927 samples per second\n",
      "Val Loss: 0.78515625\n",
      "Val Accuracy: 0.7282000184059143\n",
      "\n",
      "\n",
      "Epoch: 31\n",
      "Train Loss: 2.093134880065918\n",
      "CE Loss: 1.1127475500106812, Freq(freq) Loss1: 0.9803873896598816\n",
      "Learning Rate: 7.965937789155413e-05\n",
      "Train Accuracy: 0.6195238828659058\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747777877807618 s\n",
      "Throughout: 2409.896630592009 samples per second\n",
      "Val Loss: 0.76953125\n",
      "Val Accuracy: 0.7231999635696411\n",
      "\n",
      "\n",
      "Epoch: 32\n",
      "Train Loss: 2.0136446952819824\n",
      "CE Loss: 1.0351136922836304, Freq(freq) Loss1: 0.9785311222076416\n",
      "Learning Rate: 7.962621778090351e-05\n",
      "Train Accuracy: 0.6240119338035583\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750294815063477 s\n",
      "Throughout: 2409.604318667462 samples per second\n",
      "Val Loss: 0.80078125\n",
      "Val Accuracy: 0.7386999726295471\n",
      "\n",
      "\n",
      "Epoch: 33\n",
      "Train Loss: 1.970820426940918\n",
      "CE Loss: 0.993073582649231, Freq(freq) Loss1: 0.9777467846870422\n",
      "Learning Rate: 7.959152531746922e-05\n",
      "Train Accuracy: 0.6279234886169434\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.729745223999025 s\n",
      "Throughout: 2411.99298205144 samples per second\n",
      "Val Loss: 0.7578125\n",
      "Val Accuracy: 0.732699990272522\n",
      "\n",
      "\n",
      "Epoch: 34\n",
      "Train Loss: 2.1001522541046143\n",
      "CE Loss: 1.12125563621521, Freq(freq) Loss1: 0.9788966178894043\n",
      "Learning Rate: 7.955530185995894e-05\n",
      "Train Accuracy: 0.6290885806083679\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74228987121582 s\n",
      "Throughout: 2410.5342423830093 samples per second\n",
      "Val Loss: 0.73046875\n",
      "Val Accuracy: 0.7397999167442322\n",
      "\n",
      "\n",
      "Epoch: 35\n",
      "Train Loss: 2.069209098815918\n",
      "CE Loss: 1.089835286140442, Freq(freq) Loss1: 0.9793738722801208\n",
      "Learning Rate: 7.951754882704074e-05\n",
      "Train Accuracy: 0.6405196189880371\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74285705566406 s\n",
      "Throughout: 2410.4683296916883 samples per second\n",
      "Val Loss: 0.7578125\n",
      "Val Accuracy: 0.7456000447273254\n",
      "\n",
      "\n",
      "Epoch: 36\n",
      "Train Loss: 1.9372565746307373\n",
      "CE Loss: 0.9596540927886963, Freq(freq) Loss1: 0.9776025414466858\n",
      "Learning Rate: 7.947826769728756e-05\n",
      "Train Accuracy: 0.6379269361495972\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742270431518556 s\n",
      "Throughout: 2410.5365015405146 samples per second\n",
      "Val Loss: 0.69921875\n",
      "Val Accuracy: 0.7537000179290771\n",
      "\n",
      "\n",
      "Epoch: 37\n",
      "Train Loss: 1.869598627090454\n",
      "CE Loss: 0.8907837271690369, Freq(freq) Loss1: 0.978814959526062\n",
      "Learning Rate: 7.943746000911915e-05\n",
      "Train Accuracy: 0.6480352282524109\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70654722595215 s\n",
      "Throughout: 2414.6951905788264 samples per second\n",
      "Val Loss: 0.71875\n",
      "Val Accuracy: 0.7649000287055969\n",
      "\n",
      "\n",
      "Epoch: 38\n",
      "Train Loss: 1.94008469581604\n",
      "CE Loss: 0.9622704982757568, Freq(freq) Loss1: 0.9778141975402832\n",
      "Learning Rate: 7.939512736074201e-05\n",
      "Train Accuracy: 0.6531023383140564\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.728249237060545 s\n",
      "Throughout: 2412.1670589817 samples per second\n",
      "Val Loss: 0.671875\n",
      "Val Accuracy: 0.7662999629974365\n",
      "\n",
      "\n",
      "Epoch: 39\n",
      "Train Loss: 1.9402379989624023\n",
      "CE Loss: 0.9620623588562012, Freq(freq) Loss1: 0.978175699710846\n",
      "Learning Rate: 7.935127141008669e-05\n",
      "Train Accuracy: 0.657896101474762\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73619497680664 s\n",
      "Throughout: 2411.24275962513 samples per second\n",
      "Val Loss: 0.703125\n",
      "Val Accuracy: 0.7587000727653503\n",
      "\n",
      "\n",
      "Epoch: 40\n",
      "Train Loss: 1.9243566989898682\n",
      "CE Loss: 0.9473613500595093, Freq(freq) Loss1: 0.9769954085350037\n",
      "Learning Rate: 7.930589387474286e-05\n",
      "Train Accuracy: 0.662926435470581\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72785903930664 s\n",
      "Throughout: 2412.2124675386895 samples per second\n",
      "Val Loss: 0.671875\n",
      "Val Accuracy: 0.7653999328613281\n",
      "\n",
      "\n",
      "Epoch: 41\n",
      "Train Loss: 1.9386584758758545\n",
      "CE Loss: 0.9612854719161987, Freq(freq) Loss1: 0.9773730039596558\n",
      "Learning Rate: 7.925899653189209e-05\n",
      "Train Accuracy: 0.6684966087341309\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741751846313477 s\n",
      "Throughout: 2410.5967697654582 samples per second\n",
      "Val Loss: 0.6484375\n",
      "Val Accuracy: 0.775700032711029\n",
      "\n",
      "\n",
      "Epoch: 42\n",
      "Train Loss: 1.9224562644958496\n",
      "CE Loss: 0.9449456334114075, Freq(freq) Loss1: 0.9775105714797974\n",
      "Learning Rate: 7.921058121823819e-05\n",
      "Train Accuracy: 0.676405131816864\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73795852661133 s\n",
      "Throughout: 2411.0377082603904 samples per second\n",
      "Val Loss: 0.6328125\n",
      "Val Accuracy: 0.7754999399185181\n",
      "\n",
      "\n",
      "Epoch: 43\n",
      "Train Loss: 1.8462531566619873\n",
      "CE Loss: 0.8684483766555786, Freq(freq) Loss1: 0.9778047204017639\n",
      "Learning Rate: 7.916064982993534e-05\n",
      "Train Accuracy: 0.6804503202438354\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.739943710327147 s\n",
      "Throughout: 2410.8069288106717 samples per second\n",
      "Val Loss: 0.640625\n",
      "Val Accuracy: 0.7861999869346619\n",
      "\n",
      "\n",
      "Epoch: 44\n",
      "Train Loss: 1.9117852449417114\n",
      "CE Loss: 0.93453049659729, Freq(freq) Loss1: 0.9772547483444214\n",
      "Learning Rate: 7.910920432251376e-05\n",
      "Train Accuracy: 0.6854183077812195\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743685317993165 s\n",
      "Throughout: 2410.3720835289464 samples per second\n",
      "Val Loss: 0.625\n",
      "Val Accuracy: 0.7804999947547913\n",
      "\n",
      "\n",
      "Epoch: 45\n",
      "Train Loss: 1.7299432754516602\n",
      "CE Loss: 0.7518313527107239, Freq(freq) Loss1: 0.9781119227409363\n",
      "Learning Rate: 7.905624671080318e-05\n",
      "Train Accuracy: 0.6902692317962646\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74346743774414 s\n",
      "Throughout: 2410.3974010160723 samples per second\n",
      "Val Loss: 0.62109375\n",
      "Val Accuracy: 0.7908999919891357\n",
      "\n",
      "\n",
      "Epoch: 46\n",
      "Train Loss: 1.8617630004882812\n",
      "CE Loss: 0.884133517742157, Freq(freq) Loss1: 0.9776294827461243\n",
      "Learning Rate: 7.90017790688539e-05\n",
      "Train Accuracy: 0.6936421990394592\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.729302536010742 s\n",
      "Throughout: 2412.0444917594546 samples per second\n",
      "Val Loss: 0.62109375\n",
      "Val Accuracy: 0.7913000583648682\n",
      "\n",
      "\n",
      "Epoch: 47\n",
      "Train Loss: 1.8221020698547363\n",
      "CE Loss: 0.8443361520767212, Freq(freq) Loss1: 0.9777659773826599\n",
      "Learning Rate: 7.894580352985557e-05\n",
      "Train Accuracy: 0.697907030582428\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752708923339842 s\n",
      "Throughout: 2409.324015707981 samples per second\n",
      "Val Loss: 0.625\n",
      "Val Accuracy: 0.8026000261306763\n",
      "\n",
      "\n",
      "Epoch: 48\n",
      "Train Loss: 1.7730066776275635\n",
      "CE Loss: 0.7955201864242554, Freq(freq) Loss1: 0.9774864912033081\n",
      "Learning Rate: 7.888832228605362e-05\n",
      "Train Accuracy: 0.7003450393676758\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741693771362304 s\n",
      "Throughout: 2410.603519228219 samples per second\n",
      "Val Loss: 0.6015625\n",
      "Val Accuracy: 0.7958999872207642\n",
      "\n",
      "\n",
      "Epoch: 49\n",
      "Train Loss: 1.8045010566711426\n",
      "CE Loss: 0.8277482986450195, Freq(freq) Loss1: 0.9767526984214783\n",
      "Learning Rate: 7.882933758866349e-05\n",
      "Train Accuracy: 0.7051256895065308\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745041259765625 s\n",
      "Throughout: 2410.2145362792544 samples per second\n",
      "Val Loss: 0.57421875\n",
      "Val Accuracy: 0.8073999881744385\n",
      "\n",
      "\n",
      "Epoch: 50\n",
      "Train Loss: 1.785946249961853\n",
      "CE Loss: 0.8083385229110718, Freq(freq) Loss1: 0.9776077270507812\n",
      "Learning Rate: 7.876885174778232e-05\n",
      "Train Accuracy: 0.7112997770309448\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.757282806396486 s\n",
      "Throughout: 2408.7931193283252 samples per second\n",
      "Val Loss: 0.53125\n",
      "Val Accuracy: 0.8048000931739807\n",
      "\n",
      "\n",
      "Epoch: 51\n",
      "Train Loss: 1.7310922145843506\n",
      "CE Loss: 0.7525315284729004, Freq(freq) Loss1: 0.978560745716095\n",
      "Learning Rate: 7.870686713229861e-05\n",
      "Train Accuracy: 0.71616131067276\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743915557861328 s\n",
      "Throughout: 2410.3453304432433 samples per second\n",
      "Val Loss: 0.5625\n",
      "Val Accuracy: 0.8166000247001648\n",
      "\n",
      "\n",
      "Epoch: 52\n",
      "Train Loss: 1.777820348739624\n",
      "CE Loss: 0.8002034425735474, Freq(freq) Loss1: 0.9776169657707214\n",
      "Learning Rate: 7.864338616979937e-05\n",
      "Train Accuracy: 0.7197140455245972\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753696517944334 s\n",
      "Throughout: 2409.2093645470986 samples per second\n",
      "Val Loss: 0.55859375\n",
      "Val Accuracy: 0.8114999532699585\n",
      "\n",
      "\n",
      "Epoch: 53\n",
      "Train Loss: 1.7245116233825684\n",
      "CE Loss: 0.7455884218215942, Freq(freq) Loss1: 0.9789232611656189\n",
      "Learning Rate: 7.857841134647506e-05\n",
      "Train Accuracy: 0.7215508222579956\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74454539489746 s\n",
      "Throughout: 2410.2721485667507 samples per second\n",
      "Val Loss: 0.5546875\n",
      "Val Accuracy: 0.8112999796867371\n",
      "\n",
      "\n",
      "Epoch: 54\n",
      "Train Loss: 1.7348251342773438\n",
      "CE Loss: 0.7578202486038208, Freq(freq) Loss1: 0.9770048260688782\n",
      "Learning Rate: 7.851194520702224e-05\n",
      "Train Accuracy: 0.7240903973579407\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75713053894043 s\n",
      "Throughout: 2408.8107894393142 samples per second\n",
      "Val Loss: 0.51953125\n",
      "Val Accuracy: 0.823199987411499\n",
      "\n",
      "\n",
      "Epoch: 55\n",
      "Train Loss: 1.6781445741653442\n",
      "CE Loss: 0.6994523406028748, Freq(freq) Loss1: 0.9786922335624695\n",
      "Learning Rate: 7.844399035454386e-05\n",
      "Train Accuracy: 0.7317852973937988\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744048934936522 s\n",
      "Throughout: 2410.3298327546586 samples per second\n",
      "Val Loss: 0.50390625\n",
      "Val Accuracy: 0.8216000199317932\n",
      "\n",
      "\n",
      "Epoch: 56\n",
      "Train Loss: 1.6635562181472778\n",
      "CE Loss: 0.6859179735183716, Freq(freq) Loss1: 0.9776382446289062\n",
      "Learning Rate: 7.83745494504474e-05\n",
      "Train Accuracy: 0.7354854345321655\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.738872802734374 s\n",
      "Throughout: 2410.9314173240705 samples per second\n",
      "Val Loss: 0.50390625\n",
      "Val Accuracy: 0.8285999894142151\n",
      "\n",
      "\n",
      "Epoch: 57\n",
      "Train Loss: 1.7001192569732666\n",
      "CE Loss: 0.7222501635551453, Freq(freq) Loss1: 0.9778691530227661\n",
      "Learning Rate: 7.830362521434052e-05\n",
      "Train Accuracy: 0.7436971068382263\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72692561340332 s\n",
      "Throughout: 2412.3211002246703 samples per second\n",
      "Val Loss: 0.50390625\n",
      "Val Accuracy: 0.8253999948501587\n",
      "\n",
      "\n",
      "Epoch: 58\n",
      "Train Loss: 1.7467551231384277\n",
      "CE Loss: 0.7689889669418335, Freq(freq) Loss1: 0.9777661561965942\n",
      "Learning Rate: 7.823122042392465e-05\n",
      "Train Accuracy: 0.7383763790130615\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.756399276733397 s\n",
      "Throughout: 2408.89565349838 samples per second\n",
      "Val Loss: 0.49609375\n",
      "Val Accuracy: 0.8349999785423279\n",
      "\n",
      "\n",
      "Epoch: 59\n",
      "Train Loss: 1.7447317838668823\n",
      "CE Loss: 0.7676824331283569, Freq(freq) Loss1: 0.9770493507385254\n",
      "Learning Rate: 7.815733791488615e-05\n",
      "Train Accuracy: 0.7446213364601135\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74350924682617 s\n",
      "Throughout: 2410.392542797462 samples per second\n",
      "Val Loss: 0.462890625\n",
      "Val Accuracy: 0.8327000141143799\n",
      "\n",
      "\n",
      "Epoch: 60\n",
      "Train Loss: 1.6885991096496582\n",
      "CE Loss: 0.7115912437438965, Freq(freq) Loss1: 0.9770078659057617\n",
      "Learning Rate: 7.808198058078527e-05\n",
      "Train Accuracy: 0.7516756057739258\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74206394958496 s\n",
      "Throughout: 2410.5604978139354 samples per second\n",
      "Val Loss: 0.44140625\n",
      "Val Accuracy: 0.8349000215530396\n",
      "\n",
      "\n",
      "Epoch: 61\n",
      "Train Loss: 1.6913068294525146\n",
      "CE Loss: 0.7138010263442993, Freq(freq) Loss1: 0.9775058031082153\n",
      "Learning Rate: 7.800515137294281e-05\n",
      "Train Accuracy: 0.7517629861831665\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741808685302736 s\n",
      "Throughout: 2410.5901639826175 samples per second\n",
      "Val Loss: 0.44921875\n",
      "Val Accuracy: 0.8339000344276428\n",
      "\n",
      "\n",
      "Epoch: 62\n",
      "Train Loss: 1.7157795429229736\n",
      "CE Loss: 0.7383084297180176, Freq(freq) Loss1: 0.977471113204956\n",
      "Learning Rate: 7.792685330032456e-05\n",
      "Train Accuracy: 0.7585218548774719\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741262680053712 s\n",
      "Throughout: 2410.6536217818402 samples per second\n",
      "Val Loss: 0.4453125\n",
      "Val Accuracy: 0.837899923324585\n",
      "\n",
      "\n",
      "Epoch: 63\n",
      "Train Loss: 1.6302789449691772\n",
      "CE Loss: 0.6538715362548828, Freq(freq) Loss1: 0.9764074087142944\n",
      "Learning Rate: 7.784708942942344e-05\n",
      "Train Accuracy: 0.7617588043212891\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74993801879883 s\n",
      "Throughout: 2409.6457519391856 samples per second\n",
      "Val Loss: 0.4609375\n",
      "Val Accuracy: 0.8417999744415283\n",
      "\n",
      "\n",
      "Epoch: 64\n",
      "Train Loss: 1.7018277645111084\n",
      "CE Loss: 0.723273515701294, Freq(freq) Loss1: 0.9785541892051697\n",
      "Learning Rate: 7.776586288413938e-05\n",
      "Train Accuracy: 0.7602591514587402\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743540802001952 s\n",
      "Throughout: 2410.38887609653 samples per second\n",
      "Val Loss: 0.470703125\n",
      "Val Accuracy: 0.8454999327659607\n",
      "\n",
      "\n",
      "Epoch: 65\n",
      "Train Loss: 1.693397045135498\n",
      "CE Loss: 0.7154604196548462, Freq(freq) Loss1: 0.9779365658760071\n",
      "Learning Rate: 7.768317684565702e-05\n",
      "Train Accuracy: 0.7697590589523315\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746246154785155 s\n",
      "Throughout: 2410.0745564742765 samples per second\n",
      "Val Loss: 0.44921875\n",
      "Val Accuracy: 0.8501999378204346\n",
      "\n",
      "\n",
      "Epoch: 66\n",
      "Train Loss: 1.6061899662017822\n",
      "CE Loss: 0.6288626194000244, Freq(freq) Loss1: 0.9773273468017578\n",
      "Learning Rate: 7.75990345523211e-05\n",
      "Train Accuracy: 0.7676270008087158\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741484466552734 s\n",
      "Throughout: 2410.6278449177016 samples per second\n",
      "Val Loss: 0.400390625\n",
      "Val Accuracy: 0.8450999855995178\n",
      "\n",
      "\n",
      "Epoch: 67\n",
      "Train Loss: 1.6472716331481934\n",
      "CE Loss: 0.6706882119178772, Freq(freq) Loss1: 0.9765834808349609\n",
      "Learning Rate: 7.751343929950961e-05\n",
      "Train Accuracy: 0.7733771204948425\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740542602539062 s\n",
      "Throughout: 2410.737315709329 samples per second\n",
      "Val Loss: 0.4765625\n",
      "Val Accuracy: 0.8495000004768372\n",
      "\n",
      "\n",
      "Epoch: 68\n",
      "Train Loss: 1.6522178649902344\n",
      "CE Loss: 0.6749575138092041, Freq(freq) Loss1: 0.9772603511810303\n",
      "Learning Rate: 7.742639443950477e-05\n",
      "Train Accuracy: 0.7714500427246094\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748434402465822 s\n",
      "Throughout: 2409.82037632959 samples per second\n",
      "Val Loss: 0.390625\n",
      "Val Accuracy: 0.8536999821662903\n",
      "\n",
      "\n",
      "Epoch: 69\n",
      "Train Loss: 1.632735013961792\n",
      "CE Loss: 0.6554672122001648, Freq(freq) Loss1: 0.9772677421569824\n",
      "Learning Rate: 7.733790338136171e-05\n",
      "Train Accuracy: 0.7738673686981201\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75049380493164 s\n",
      "Throughout: 2409.581211417572 samples per second\n",
      "Val Loss: 0.435546875\n",
      "Val Accuracy: 0.851599931716919\n",
      "\n",
      "\n",
      "Epoch: 70\n",
      "Train Loss: 1.579906940460205\n",
      "CE Loss: 0.6027876138687134, Freq(freq) Loss1: 0.9771193265914917\n",
      "Learning Rate: 7.724796959077495e-05\n",
      "Train Accuracy: 0.7806373238563538\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.755240264892578 s\n",
      "Throughout: 2409.0301707841386 samples per second\n",
      "Val Loss: 0.419921875\n",
      "Val Accuracy: 0.8507000207901001\n",
      "\n",
      "\n",
      "Epoch: 71\n",
      "Train Loss: 1.5846447944641113\n",
      "CE Loss: 0.6065856218338013, Freq(freq) Loss1: 0.9780591130256653\n",
      "Learning Rate: 7.715659658994274e-05\n",
      "Train Accuracy: 0.7829943299293518\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75016993713379 s\n",
      "Throughout: 2409.6188200618885 samples per second\n",
      "Val Loss: 0.43359375\n",
      "Val Accuracy: 0.8532000184059143\n",
      "\n",
      "\n",
      "Epoch: 72\n",
      "Train Loss: 1.5474021434783936\n",
      "CE Loss: 0.5709021091461182, Freq(freq) Loss1: 0.9765000939369202\n",
      "Learning Rate: 7.706378795742899e-05\n",
      "Train Accuracy: 0.7870025634765625\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74874038696289 s\n",
      "Throughout: 2409.7848383806772 samples per second\n",
      "Val Loss: 0.416015625\n",
      "Val Accuracy: 0.8600000143051147\n",
      "\n",
      "\n",
      "Epoch: 73\n",
      "Train Loss: 1.5998365879058838\n",
      "CE Loss: 0.6222441792488098, Freq(freq) Loss1: 0.977592408657074\n",
      "Learning Rate: 7.696954732802325e-05\n",
      "Train Accuracy: 0.7853268384933472\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740440216064453 s\n",
      "Throughout: 2410.7492164642017 samples per second\n",
      "Val Loss: 0.384765625\n",
      "Val Accuracy: 0.8628999590873718\n",
      "\n",
      "\n",
      "Epoch: 74\n",
      "Train Loss: 1.5671488046646118\n",
      "CE Loss: 0.5900160074234009, Freq(freq) Loss1: 0.9771327972412109\n",
      "Learning Rate: 7.687387839259824e-05\n",
      "Train Accuracy: 0.7897973656654358\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748586349487304 s\n",
      "Throughout: 2409.8027286198944 samples per second\n",
      "Val Loss: 0.41015625\n",
      "Val Accuracy: 0.8614999055862427\n",
      "\n",
      "\n",
      "Epoch: 75\n",
      "Train Loss: 1.556136131286621\n",
      "CE Loss: 0.5780572891235352, Freq(freq) Loss1: 0.9780787825584412\n",
      "Learning Rate: 7.677678489796539e-05\n",
      "Train Accuracy: 0.7935196161270142\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744860458374024 s\n",
      "Throughout: 2410.2355424529565 samples per second\n",
      "Val Loss: 0.4140625\n",
      "Val Accuracy: 0.8562999367713928\n",
      "\n",
      "\n",
      "Epoch: 76\n",
      "Train Loss: 1.5582728385925293\n",
      "CE Loss: 0.5798664093017578, Freq(freq) Loss1: 0.9784064292907715\n",
      "Learning Rate: 7.667827064672805e-05\n",
      "Train Accuracy: 0.7960543036460876\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746235733032226 s\n",
      "Throughout: 2410.0757671614533 samples per second\n",
      "Val Loss: 0.421875\n",
      "Val Accuracy: 0.8618000149726868\n",
      "\n",
      "\n",
      "Epoch: 77\n",
      "Train Loss: 1.6193745136260986\n",
      "CE Loss: 0.6426908373832703, Freq(freq) Loss1: 0.9766836762428284\n",
      "Learning Rate: 7.657833949713258e-05\n",
      "Train Accuracy: 0.7995965480804443\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.738941009521483 s\n",
      "Throughout: 2410.9234881879665 samples per second\n",
      "Val Loss: 0.470703125\n",
      "Val Accuracy: 0.8619999885559082\n",
      "\n",
      "\n",
      "Epoch: 78\n",
      "Train Loss: 1.5677387714385986\n",
      "CE Loss: 0.5905318260192871, Freq(freq) Loss1: 0.9772069454193115\n",
      "Learning Rate: 7.647699536291722e-05\n",
      "Train Accuracy: 0.7998313307762146\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744212203979494 s\n",
      "Throughout: 2410.310862053763 samples per second\n",
      "Val Loss: 0.41796875\n",
      "Val Accuracy: 0.8646000027656555\n",
      "\n",
      "\n",
      "Epoch: 79\n",
      "Train Loss: 1.55220627784729\n",
      "CE Loss: 0.5761368274688721, Freq(freq) Loss1: 0.9760693907737732\n",
      "Learning Rate: 7.637424221315886e-05\n",
      "Train Accuracy: 0.8001670241355896\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.759258728027344 s\n",
      "Throughout: 2408.5638439726345 samples per second\n",
      "Val Loss: 0.416015625\n",
      "Val Accuracy: 0.8653001189231873\n",
      "\n",
      "\n",
      "Epoch: 80\n",
      "Train Loss: 1.4550656080245972\n",
      "CE Loss: 0.4785761535167694, Freq(freq) Loss1: 0.9764894247055054\n",
      "Learning Rate: 7.627008407211751e-05\n",
      "Train Accuracy: 0.8019021153450012\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748359161376953 s\n",
      "Throughout: 2409.8291152138404 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.8707000017166138\n",
      "\n",
      "\n",
      "Epoch: 81\n",
      "Train Loss: 1.5556436777114868\n",
      "CE Loss: 0.5783185958862305, Freq(freq) Loss1: 0.9773250818252563\n",
      "Learning Rate: 7.616452501907884e-05\n",
      "Train Accuracy: 0.8055222630500793\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.65826873779297 s\n",
      "Throughout: 2420.338346578299 samples per second\n",
      "Val Loss: 0.392578125\n",
      "Val Accuracy: 0.8698999881744385\n",
      "\n",
      "\n",
      "Epoch: 82\n",
      "Train Loss: 1.506903886795044\n",
      "CE Loss: 0.530026912689209, Freq(freq) Loss1: 0.9768770337104797\n",
      "Learning Rate: 7.605756918819422e-05\n",
      "Train Accuracy: 0.8089002370834351\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743518814086915 s\n",
      "Throughout: 2410.3914310837667 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.871999979019165\n",
      "\n",
      "\n",
      "Epoch: 83\n",
      "Train Loss: 1.5433249473571777\n",
      "CE Loss: 0.5656114816665649, Freq(freq) Loss1: 0.977713406085968\n",
      "Learning Rate: 7.5949220768319e-05\n",
      "Train Accuracy: 0.8100687861442566\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.731580047607423 s\n",
      "Throughout: 2411.779511507632 samples per second\n",
      "Val Loss: 0.416015625\n",
      "Val Accuracy: 0.8676000237464905\n",
      "\n",
      "\n",
      "Epoch: 84\n",
      "Train Loss: 1.4797419309616089\n",
      "CE Loss: 0.501471996307373, Freq(freq) Loss1: 0.9782699346542358\n",
      "Learning Rate: 7.583948400284833e-05\n",
      "Train Accuracy: 0.8111367225646973\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73246533203125 s\n",
      "Throughout: 2411.6765275739294 samples per second\n",
      "Val Loss: 0.400390625\n",
      "Val Accuracy: 0.8729000091552734\n",
      "\n",
      "\n",
      "Epoch: 85\n",
      "Train Loss: 1.4288089275360107\n",
      "CE Loss: 0.4510657787322998, Freq(freq) Loss1: 0.9777431488037109\n",
      "Learning Rate: 7.572836318955097e-05\n",
      "Train Accuracy: 0.8157285451889038\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.76363136291504 s\n",
      "Throughout: 2408.0566219887087 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.8789999485015869\n",
      "\n",
      "\n",
      "Epoch: 86\n",
      "Train Loss: 1.5033912658691406\n",
      "CE Loss: 0.5265175700187683, Freq(freq) Loss1: 0.9768737554550171\n",
      "Learning Rate: 7.561586268040109e-05\n",
      "Train Accuracy: 0.8146421313285828\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746393920898438 s\n",
      "Throughout: 2410.057390727242 samples per second\n",
      "Val Loss: 0.37109375\n",
      "Val Accuracy: 0.8759000301361084\n",
      "\n",
      "\n",
      "Epoch: 87\n",
      "Train Loss: 1.433622121810913\n",
      "CE Loss: 0.45742976665496826, Freq(freq) Loss1: 0.9761923551559448\n",
      "Learning Rate: 7.550198688140768e-05\n",
      "Train Accuracy: 0.8190086483955383\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744520950317384 s\n",
      "Throughout: 2410.2749887427512 samples per second\n",
      "Val Loss: 0.3515625\n",
      "Val Accuracy: 0.8748000860214233\n",
      "\n",
      "\n",
      "Epoch: 88\n",
      "Train Loss: 1.4714198112487793\n",
      "CE Loss: 0.493799090385437, Freq(freq) Loss1: 0.9776206612586975\n",
      "Learning Rate: 7.538674025244211e-05\n",
      "Train Accuracy: 0.8204516768455505\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75889440917969 s\n",
      "Throughout: 2408.606114297192 samples per second\n",
      "Val Loss: 0.408203125\n",
      "Val Accuracy: 0.8776999711990356\n",
      "\n",
      "\n",
      "Epoch: 89\n",
      "Train Loss: 1.4560033082962036\n",
      "CE Loss: 0.4777693748474121, Freq(freq) Loss1: 0.9782339334487915\n",
      "Learning Rate: 7.527012730706337e-05\n",
      "Train Accuracy: 0.8220571279525757\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.705542343139648 s\n",
      "Throughout: 2414.812380732759 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.8762000799179077\n",
      "\n",
      "\n",
      "Epoch: 90\n",
      "Train Loss: 1.4282608032226562\n",
      "CE Loss: 0.45120012760162354, Freq(freq) Loss1: 0.9770606756210327\n",
      "Learning Rate: 7.515215261234137e-05\n",
      "Train Accuracy: 0.8247049450874329\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74203370666504 s\n",
      "Throughout: 2410.5640125313985 samples per second\n",
      "Val Loss: 0.365234375\n",
      "Val Accuracy: 0.8769999742507935\n",
      "\n",
      "\n",
      "Epoch: 91\n",
      "Train Loss: 1.5415136814117432\n",
      "CE Loss: 0.5639664530754089, Freq(freq) Loss1: 0.9775472283363342\n",
      "Learning Rate: 7.503282078867803e-05\n",
      "Train Accuracy: 0.8262190818786621\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741541763305666 s\n",
      "Throughout: 2410.621185762388 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.8751999735832214\n",
      "\n",
      "\n",
      "Epoch: 92\n",
      "Train Loss: 1.5201208591461182\n",
      "CE Loss: 0.5433669090270996, Freq(freq) Loss1: 0.9767539501190186\n",
      "Learning Rate: 7.491213650962633e-05\n",
      "Train Accuracy: 0.8258198499679565\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742229064941405 s\n",
      "Throughout: 2410.541308914103 samples per second\n",
      "Val Loss: 0.34375\n",
      "Val Accuracy: 0.8788000345230103\n",
      "\n",
      "\n",
      "Epoch: 93\n",
      "Train Loss: 1.4947383403778076\n",
      "CE Loss: 0.5166171789169312, Freq(freq) Loss1: 0.9781212210655212\n",
      "Learning Rate: 7.479010450170732e-05\n",
      "Train Accuracy: 0.8322316408157349\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750939376831056 s\n",
      "Throughout: 2409.5294719923018 samples per second\n",
      "Val Loss: 0.33984375\n",
      "Val Accuracy: 0.8801999688148499\n",
      "\n",
      "\n",
      "Epoch: 94\n",
      "Train Loss: 1.4250566959381104\n",
      "CE Loss: 0.447634220123291, Freq(freq) Loss1: 0.9774224758148193\n",
      "Learning Rate: 7.466672954422491e-05\n",
      "Train Accuracy: 0.8295300006866455\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746209930419923 s\n",
      "Throughout: 2410.0787646366957 samples per second\n",
      "Val Loss: 0.33984375\n",
      "Val Accuracy: 0.8797000050544739\n",
      "\n",
      "\n",
      "Epoch: 95\n",
      "Train Loss: 1.5017353296279907\n",
      "CE Loss: 0.5249180793762207, Freq(freq) Loss1: 0.97681725025177\n",
      "Learning Rate: 7.454201646907882e-05\n",
      "Train Accuracy: 0.8354684114456177\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.710922256469726 s\n",
      "Throughout: 2414.1851039193043 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.8822999596595764\n",
      "\n",
      "\n",
      "Epoch: 96\n",
      "Train Loss: 1.4764397144317627\n",
      "CE Loss: 0.49753695726394653, Freq(freq) Loss1: 0.9789027571678162\n",
      "Learning Rate: 7.441597016057523e-05\n",
      "Train Accuracy: 0.8316628932952881\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.749566360473633 s\n",
      "Throughout: 2409.6889125956022 samples per second\n",
      "Val Loss: 0.376953125\n",
      "Val Accuracy: 0.8761999011039734\n",
      "\n",
      "\n",
      "Epoch: 97\n",
      "Train Loss: 1.4822863340377808\n",
      "CE Loss: 0.5050147771835327, Freq(freq) Loss1: 0.977271556854248\n",
      "Learning Rate: 7.428859555523556e-05\n",
      "Train Accuracy: 0.835909903049469\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750072540283202 s\n",
      "Throughout: 2409.630130349298 samples per second\n",
      "Val Loss: 0.337890625\n",
      "Val Accuracy: 0.8774999380111694\n",
      "\n",
      "\n",
      "Epoch: 98\n",
      "Train Loss: 1.3737726211547852\n",
      "CE Loss: 0.3973986804485321, Freq(freq) Loss1: 0.9763739705085754\n",
      "Learning Rate: 7.415989764160308e-05\n",
      "Train Accuracy: 0.8396525382995605\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741434631347655 s\n",
      "Throughout: 2410.6336369053415 samples per second\n",
      "Val Loss: 0.3671875\n",
      "Val Accuracy: 0.8895999789237976\n",
      "\n",
      "\n",
      "Epoch: 99\n",
      "Train Loss: 1.4058222770690918\n",
      "CE Loss: 0.4291304647922516, Freq(freq) Loss1: 0.9766917824745178\n",
      "Learning Rate: 7.402988146004759e-05\n",
      "Train Accuracy: 0.8409854173660278\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740056884765625 s\n",
      "Throughout: 2410.7937735082555 samples per second\n",
      "Val Loss: 0.3671875\n",
      "Val Accuracy: 0.8852999210357666\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "Train Loss: 1.3901340961456299\n",
      "CE Loss: 0.4131696820259094, Freq(freq) Loss1: 0.9769644737243652\n",
      "Learning Rate: 7.389855210256798e-05\n",
      "Train Accuracy: 0.8406805396080017\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75431105041504 s\n",
      "Throughout: 2409.1380281688566 samples per second\n",
      "Val Loss: 0.390625\n",
      "Val Accuracy: 0.8820000290870667\n",
      "\n",
      "\n",
      "Epoch: 101\n",
      "Train Loss: 1.4574267864227295\n",
      "CE Loss: 0.47987687587738037, Freq(freq) Loss1: 0.9775499701499939\n",
      "Learning Rate: 7.376591471259286e-05\n",
      "Train Accuracy: 0.845032274723053\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74413619995117 s\n",
      "Throughout: 2410.319693143824 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.8856999278068542\n",
      "\n",
      "\n",
      "Epoch: 102\n",
      "Train Loss: 1.4531285762786865\n",
      "CE Loss: 0.47553348541259766, Freq(freq) Loss1: 0.9775951504707336\n",
      "Learning Rate: 7.3631974484779e-05\n",
      "Train Accuracy: 0.8449847102165222\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74728860473633 s\n",
      "Throughout: 2409.953461995302 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.886199951171875\n",
      "\n",
      "\n",
      "Epoch: 103\n",
      "Train Loss: 1.328125238418579\n",
      "CE Loss: 0.35086217522621155, Freq(freq) Loss1: 0.9772630333900452\n",
      "Learning Rate: 7.349673666480803e-05\n",
      "Train Accuracy: 0.8460862040519714\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740162322998046 s\n",
      "Throughout: 2410.78151758517 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.89410001039505\n",
      "\n",
      "\n",
      "Epoch: 104\n",
      "Train Loss: 1.3919163942337036\n",
      "CE Loss: 0.41552814841270447, Freq(freq) Loss1: 0.9763882756233215\n",
      "Learning Rate: 7.336020654918089e-05\n",
      "Train Accuracy: 0.8495548963546753\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.723608459472658 s\n",
      "Throughout: 2412.707231840469 samples per second\n",
      "Val Loss: 0.396484375\n",
      "Val Accuracy: 0.8885999321937561\n",
      "\n",
      "\n",
      "Epoch: 105\n",
      "Train Loss: 1.3255903720855713\n",
      "CE Loss: 0.34744107723236084, Freq(freq) Loss1: 0.9781492948532104\n",
      "Learning Rate: 7.322238948501046e-05\n",
      "Train Accuracy: 0.8530877232551575\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.737024139404298 s\n",
      "Throughout: 2411.14634693367 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.8863999843597412\n",
      "\n",
      "\n",
      "Epoch: 106\n",
      "Train Loss: 1.3868744373321533\n",
      "CE Loss: 0.40953758358955383, Freq(freq) Loss1: 0.9773368239402771\n",
      "Learning Rate: 7.30832908698121e-05\n",
      "Train Accuracy: 0.8523629903793335\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.76553907775879 s\n",
      "Throughout: 2407.8353955931334 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.889799952507019\n",
      "\n",
      "\n",
      "Epoch: 107\n",
      "Train Loss: 1.3637280464172363\n",
      "CE Loss: 0.38701385259628296, Freq(freq) Loss1: 0.9767141938209534\n",
      "Learning Rate: 7.294291615129232e-05\n",
      "Train Accuracy: 0.8556303977966309\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.724568328857423 s\n",
      "Throughout: 2412.595486024127 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.8892999887466431\n",
      "\n",
      "\n",
      "Epoch: 108\n",
      "Train Loss: 1.395272970199585\n",
      "CE Loss: 0.41752737760543823, Freq(freq) Loss1: 0.9777456521987915\n",
      "Learning Rate: 7.280127082713532e-05\n",
      "Train Accuracy: 0.8561804890632629\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746034942626952 s\n",
      "Throughout: 2410.0990930688554 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.887700080871582\n",
      "\n",
      "\n",
      "Epoch: 109\n",
      "Train Loss: 1.3907217979431152\n",
      "CE Loss: 0.4135509729385376, Freq(freq) Loss1: 0.9771707653999329\n",
      "Learning Rate: 7.265836044478778e-05\n",
      "Train Accuracy: 0.8593208193778992\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.731552612304686 s\n",
      "Throughout: 2411.782703159616 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.894599974155426\n",
      "\n",
      "\n",
      "Epoch: 110\n",
      "Train Loss: 1.3992246389389038\n",
      "CE Loss: 0.42060285806655884, Freq(freq) Loss1: 0.978621780872345\n",
      "Learning Rate: 7.251419060124158e-05\n",
      "Train Accuracy: 0.8562768697738647\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746466537475587 s\n",
      "Throughout: 2410.04895506818 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.8943999409675598\n",
      "\n",
      "\n",
      "Epoch: 111\n",
      "Train Loss: 1.3273372650146484\n",
      "CE Loss: 0.3506097197532654, Freq(freq) Loss1: 0.9767274856567383\n",
      "Learning Rate: 7.236876694281454e-05\n",
      "Train Accuracy: 0.860356330871582\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74694111633301 s\n",
      "Throughout: 2409.9938260603417 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.8915000557899475\n",
      "\n",
      "\n",
      "Epoch: 112\n",
      "Train Loss: 1.3620349168777466\n",
      "CE Loss: 0.38478946685791016, Freq(freq) Loss1: 0.9772454500198364\n",
      "Learning Rate: 7.222209516492932e-05\n",
      "Train Accuracy: 0.8637348413467407\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745716552734375 s\n",
      "Throughout: 2410.136081484724 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.8902999758720398\n",
      "\n",
      "\n",
      "Epoch: 113\n",
      "Train Loss: 1.4310928583145142\n",
      "CE Loss: 0.4533922076225281, Freq(freq) Loss1: 0.9777006506919861\n",
      "Learning Rate: 7.20741810118904e-05\n",
      "Train Accuracy: 0.8621817827224731\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74744078063965 s\n",
      "Throughout: 2409.935785750366 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.8966999650001526\n",
      "\n",
      "\n",
      "Epoch: 114\n",
      "Train Loss: 1.350088119506836\n",
      "CE Loss: 0.3735432028770447, Freq(freq) Loss1: 0.9765449166297913\n",
      "Learning Rate: 7.192503027665903e-05\n",
      "Train Accuracy: 0.8650559186935425\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74724983215332 s\n",
      "Throughout: 2409.957965730564 samples per second\n",
      "Val Loss: 0.37890625\n",
      "Val Accuracy: 0.8920000195503235\n",
      "\n",
      "\n",
      "Epoch: 115\n",
      "Train Loss: 1.3699028491973877\n",
      "CE Loss: 0.39258891344070435, Freq(freq) Loss1: 0.9773139357566833\n",
      "Learning Rate: 7.17746488006264e-05\n",
      "Train Accuracy: 0.8655720949172974\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748007354736327 s\n",
      "Throughout: 2409.869976674462 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.8942999839782715\n",
      "\n",
      "\n",
      "Epoch: 116\n",
      "Train Loss: 1.4540865421295166\n",
      "CE Loss: 0.4772787094116211, Freq(freq) Loss1: 0.9768078327178955\n",
      "Learning Rate: 7.16230424733849e-05\n",
      "Train Accuracy: 0.8673417568206787\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746615951538086 s\n",
      "Throughout: 2410.031598251722 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.8986999988555908\n",
      "\n",
      "\n",
      "Epoch: 117\n",
      "Train Loss: 1.3316307067871094\n",
      "CE Loss: 0.35496604442596436, Freq(freq) Loss1: 0.9766647219657898\n",
      "Learning Rate: 7.147021723249738e-05\n",
      "Train Accuracy: 0.8703277111053467\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.699000915527343 s\n",
      "Throughout: 2415.5755248308883 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9014000296592712\n",
      "\n",
      "\n",
      "Epoch: 118\n",
      "Train Loss: 1.3306183815002441\n",
      "CE Loss: 0.3538409471511841, Freq(freq) Loss1: 0.9767773747444153\n",
      "Learning Rate: 7.131617906326464e-05\n",
      "Train Accuracy: 0.8721538186073303\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.732099380493164 s\n",
      "Throughout: 2411.7190971525542 samples per second\n",
      "Val Loss: 0.28515625\n",
      "Val Accuracy: 0.8991000056266785\n",
      "\n",
      "\n",
      "Epoch: 119\n",
      "Train Loss: 1.3551466464996338\n",
      "CE Loss: 0.3784050941467285, Freq(freq) Loss1: 0.97674161195755\n",
      "Learning Rate: 7.116093399849107e-05\n",
      "Train Accuracy: 0.8691027760505676\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75364633178711 s\n",
      "Throughout: 2409.2151904611583 samples per second\n",
      "Val Loss: 0.3671875\n",
      "Val Accuracy: 0.8964999914169312\n",
      "\n",
      "\n",
      "Epoch: 120\n",
      "Train Loss: 1.3228161334991455\n",
      "CE Loss: 0.34504732489585876, Freq(freq) Loss1: 0.9777687788009644\n",
      "Learning Rate: 7.10044881182483e-05\n",
      "Train Accuracy: 0.8705695867538452\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73164193725586 s\n",
      "Throughout: 2411.7723116830102 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.8971999883651733\n",
      "\n",
      "\n",
      "Epoch: 121\n",
      "Train Loss: 1.3977903127670288\n",
      "CE Loss: 0.420663446187973, Freq(freq) Loss1: 0.9771268963813782\n",
      "Learning Rate: 7.084684754963713e-05\n",
      "Train Accuracy: 0.8725116848945618\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742890045166014 s\n",
      "Throughout: 2410.464496081738 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.8950999975204468\n",
      "\n",
      "\n",
      "Epoch: 122\n",
      "Train Loss: 1.3670390844345093\n",
      "CE Loss: 0.39036908745765686, Freq(freq) Loss1: 0.97666996717453\n",
      "Learning Rate: 7.068801846654753e-05\n",
      "Train Accuracy: 0.8733312487602234\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.758818054199217 s\n",
      "Throughout: 2408.614973620124 samples per second\n",
      "Val Loss: 0.34375\n",
      "Val Accuracy: 0.898099958896637\n",
      "\n",
      "\n",
      "Epoch: 123\n",
      "Train Loss: 1.292069435119629\n",
      "CE Loss: 0.3151218295097351, Freq(freq) Loss1: 0.9769476652145386\n",
      "Learning Rate: 7.05280070894169e-05\n",
      "Train Accuracy: 0.874467134475708\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740146759033202 s\n",
      "Throughout: 2410.783326700565 samples per second\n",
      "Val Loss: 0.345703125\n",
      "Val Accuracy: 0.9005999565124512\n",
      "\n",
      "\n",
      "Epoch: 124\n",
      "Train Loss: 1.358534574508667\n",
      "CE Loss: 0.3817160725593567, Freq(freq) Loss1: 0.9768185615539551\n",
      "Learning Rate: 7.036681968498639e-05\n",
      "Train Accuracy: 0.8777908086776733\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74376596069336 s\n",
      "Throughout: 2410.3627130552504 samples per second\n",
      "Val Loss: 0.37890625\n",
      "Val Accuracy: 0.8931999802589417\n",
      "\n",
      "\n",
      "Epoch: 125\n",
      "Train Loss: 1.3633155822753906\n",
      "CE Loss: 0.38670942187309265, Freq(freq) Loss1: 0.9766061902046204\n",
      "Learning Rate: 7.020446256605548e-05\n",
      "Train Accuracy: 0.8783309459686279\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.736181991577148 s\n",
      "Throughout: 2411.2442695723616 samples per second\n",
      "Val Loss: 0.337890625\n",
      "Val Accuracy: 0.8985999822616577\n",
      "\n",
      "\n",
      "Epoch: 126\n",
      "Train Loss: 1.3710846900939941\n",
      "CE Loss: 0.39378049969673157, Freq(freq) Loss1: 0.9773041605949402\n",
      "Learning Rate: 7.004094209123479e-05\n",
      "Train Accuracy: 0.8785632252693176\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.730152572631837 s\n",
      "Throughout: 2411.945586257311 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.8988000154495239\n",
      "\n",
      "\n",
      "Epoch: 127\n",
      "Train Loss: 1.31624174118042\n",
      "CE Loss: 0.3390578627586365, Freq(freq) Loss1: 0.9771839380264282\n",
      "Learning Rate: 6.987626466469698e-05\n",
      "Train Accuracy: 0.8797200918197632\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.712572463989257 s\n",
      "Throughout: 2413.9927614944822 samples per second\n",
      "Val Loss: 0.3984375\n",
      "Val Accuracy: 0.8964999318122864\n",
      "\n",
      "\n",
      "Epoch: 128\n",
      "Train Loss: 1.3771628141403198\n",
      "CE Loss: 0.40113720297813416, Freq(freq) Loss1: 0.9760256409645081\n",
      "Learning Rate: 6.9710436735926e-05\n",
      "Train Accuracy: 0.8797919154167175\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.67853675842285 s\n",
      "Throughout: 2417.966057469411 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9005999565124512\n",
      "\n",
      "\n",
      "Epoch: 129\n",
      "Train Loss: 1.3327211141586304\n",
      "CE Loss: 0.35623109340667725, Freq(freq) Loss1: 0.9764900207519531\n",
      "Learning Rate: 6.954346479946444e-05\n",
      "Train Accuracy: 0.8818928599357605\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751825134277343 s\n",
      "Throughout: 2409.4266251989206 samples per second\n",
      "Val Loss: 0.337890625\n",
      "Val Accuracy: 0.9004999995231628\n",
      "\n",
      "\n",
      "Epoch: 130\n",
      "Train Loss: 1.2913472652435303\n",
      "CE Loss: 0.3131238520145416, Freq(freq) Loss1: 0.978223443031311\n",
      "Learning Rate: 6.937535539465922e-05\n",
      "Train Accuracy: 0.8849393725395203\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74767514038086 s\n",
      "Throughout: 2409.908563812329 samples per second\n",
      "Val Loss: 0.388671875\n",
      "Val Accuracy: 0.8986999988555908\n",
      "\n",
      "\n",
      "Epoch: 131\n",
      "Train Loss: 1.2537391185760498\n",
      "CE Loss: 0.2771368622779846, Freq(freq) Loss1: 0.9766022562980652\n",
      "Learning Rate: 6.920611510540546e-05\n",
      "Train Accuracy: 0.887518048286438\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74447280883789 s\n",
      "Throughout: 2410.280582242524 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.8985999226570129\n",
      "\n",
      "\n",
      "Epoch: 132\n",
      "Train Loss: 1.3309259414672852\n",
      "CE Loss: 0.3547518849372864, Freq(freq) Loss1: 0.976173996925354\n",
      "Learning Rate: 6.903575055988863e-05\n",
      "Train Accuracy: 0.8864898681640625\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.759570983886718 s\n",
      "Throughout: 2408.5276154699577 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.8984000086784363\n",
      "\n",
      "\n",
      "Epoch: 133\n",
      "Train Loss: 1.3190569877624512\n",
      "CE Loss: 0.341766357421875, Freq(freq) Loss1: 0.9772906303405762\n",
      "Learning Rate: 6.886426843032498e-05\n",
      "Train Accuracy: 0.8862371444702148\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745559509277342 s\n",
      "Throughout: 2410.154326165085 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9014999866485596\n",
      "\n",
      "\n",
      "Epoch: 134\n",
      "Train Loss: 1.304972767829895\n",
      "CE Loss: 0.3286671042442322, Freq(freq) Loss1: 0.9763056635856628\n",
      "Learning Rate: 6.869167543270019e-05\n",
      "Train Accuracy: 0.8878075480461121\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75606658935547 s\n",
      "Throughout: 2408.9342643389846 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.8988000154495239\n",
      "\n",
      "\n",
      "Epoch: 135\n",
      "Train Loss: 1.2266650199890137\n",
      "CE Loss: 0.24991285800933838, Freq(freq) Loss1: 0.9767521619796753\n",
      "Learning Rate: 6.851797832650636e-05\n",
      "Train Accuracy: 0.887591540813446\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75107487487793 s\n",
      "Throughout: 2409.513738516359 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.8976999521255493\n",
      "\n",
      "\n",
      "Epoch: 136\n",
      "Train Loss: 1.3041102886199951\n",
      "CE Loss: 0.327463835477829, Freq(freq) Loss1: 0.9766464233398438\n",
      "Learning Rate: 6.834318391447732e-05\n",
      "Train Accuracy: 0.8894156217575073\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743261138916015 s\n",
      "Throughout: 2410.4213732428025 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9012999534606934\n",
      "\n",
      "\n",
      "Epoch: 137\n",
      "Train Loss: 1.2671232223510742\n",
      "CE Loss: 0.28825491666793823, Freq(freq) Loss1: 0.978868305683136\n",
      "Learning Rate: 6.816729904232211e-05\n",
      "Train Accuracy: 0.8899188041687012\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72907989501953 s\n",
      "Throughout: 2412.070398359227 samples per second\n",
      "Val Loss: 0.373046875\n",
      "Val Accuracy: 0.8999000787734985\n",
      "\n",
      "\n",
      "Epoch: 138\n",
      "Train Loss: 1.3284950256347656\n",
      "CE Loss: 0.35088050365448, Freq(freq) Loss1: 0.9776145815849304\n",
      "Learning Rate: 6.799033059845697e-05\n",
      "Train Accuracy: 0.8926635384559631\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744930068969726 s\n",
      "Throughout: 2410.227454793401 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9018000364303589\n",
      "\n",
      "\n",
      "Epoch: 139\n",
      "Train Loss: 1.2797611951828003\n",
      "CE Loss: 0.30302000045776367, Freq(freq) Loss1: 0.9767411947250366\n",
      "Learning Rate: 6.78122855137355e-05\n",
      "Train Accuracy: 0.8929129838943481\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74514549255371 s\n",
      "Throughout: 2410.2024262952054 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.90420001745224\n",
      "\n",
      "\n",
      "Epoch: 140\n",
      "Train Loss: 1.2414634227752686\n",
      "CE Loss: 0.2652960419654846, Freq(freq) Loss1: 0.9761673212051392\n",
      "Learning Rate: 6.763317076117723e-05\n",
      "Train Accuracy: 0.8946349024772644\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746819183349608 s\n",
      "Throughout: 2410.007990050233 samples per second\n",
      "Val Loss: 0.28515625\n",
      "Val Accuracy: 0.9010999798774719\n",
      "\n",
      "\n",
      "Epoch: 141\n",
      "Train Loss: 1.3368794918060303\n",
      "CE Loss: 0.3592485785484314, Freq(freq) Loss1: 0.9776309132575989\n",
      "Learning Rate: 6.745299335569457e-05\n",
      "Train Accuracy: 0.8949490785598755\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75924234008789 s\n",
      "Throughout: 2408.5657453617987 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9013999700546265\n",
      "\n",
      "\n",
      "Epoch: 142\n",
      "Train Loss: 1.3024587631225586\n",
      "CE Loss: 0.3253154158592224, Freq(freq) Loss1: 0.9771432876586914\n",
      "Learning Rate: 6.727176035381798e-05\n",
      "Train Accuracy: 0.8950093984603882\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743292694091796 s\n",
      "Throughout: 2410.4177064541564 samples per second\n",
      "Val Loss: 0.34375\n",
      "Val Accuracy: 0.9011000394821167\n",
      "\n",
      "\n",
      "Epoch: 143\n",
      "Train Loss: 1.336965799331665\n",
      "CE Loss: 0.3606295585632324, Freq(freq) Loss1: 0.9763363003730774\n",
      "Learning Rate: 6.708947885341973e-05\n",
      "Train Accuracy: 0.8960943818092346\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.726127166748046 s\n",
      "Throughout: 2412.41403170668 samples per second\n",
      "Val Loss: 0.376953125\n",
      "Val Accuracy: 0.9012000560760498\n",
      "\n",
      "\n",
      "Epoch: 144\n",
      "Train Loss: 1.248685359954834\n",
      "CE Loss: 0.27189901471138, Freq(freq) Loss1: 0.9767863750457764\n",
      "Learning Rate: 6.69061559934358e-05\n",
      "Train Accuracy: 0.89958655834198\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745236114501953 s\n",
      "Throughout: 2410.1918977459845 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.9009000658988953\n",
      "\n",
      "\n",
      "Epoch: 145\n",
      "Train Loss: 1.2112336158752441\n",
      "CE Loss: 0.23466679453849792, Freq(freq) Loss1: 0.9765668511390686\n",
      "Learning Rate: 6.672179895358637e-05\n",
      "Train Accuracy: 0.8995145559310913\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751927032470704 s\n",
      "Throughout: 2409.4147941906604 samples per second\n",
      "Val Loss: 0.345703125\n",
      "Val Accuracy: 0.9071999192237854\n",
      "\n",
      "\n",
      "Epoch: 146\n",
      "Train Loss: 1.322474479675293\n",
      "CE Loss: 0.3441658616065979, Freq(freq) Loss1: 0.9783086180686951\n",
      "Learning Rate: 6.653641495409456e-05\n",
      "Train Accuracy: 0.8985760807991028\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743947677612304 s\n",
      "Throughout: 2410.3415982851707 samples per second\n",
      "Val Loss: 0.353515625\n",
      "Val Accuracy: 0.9043999910354614\n",
      "\n",
      "\n",
      "Epoch: 147\n",
      "Train Loss: 1.2730462551116943\n",
      "CE Loss: 0.29653269052505493, Freq(freq) Loss1: 0.9765135049819946\n",
      "Learning Rate: 6.635001125540375e-05\n",
      "Train Accuracy: 0.899458110332489\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.691861663818358 s\n",
      "Throughout: 2416.4089636955987 samples per second\n",
      "Val Loss: 0.376953125\n",
      "Val Accuracy: 0.905299961566925\n",
      "\n",
      "\n",
      "Epoch: 148\n",
      "Train Loss: 1.2808207273483276\n",
      "CE Loss: 0.303559273481369, Freq(freq) Loss1: 0.977261483669281\n",
      "Learning Rate: 6.616259515789312e-05\n",
      "Train Accuracy: 0.8987333178520203\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74599411010742 s\n",
      "Throughout: 2410.103836655389 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9074000120162964\n",
      "\n",
      "\n",
      "Epoch: 149\n",
      "Train Loss: 1.3090814352035522\n",
      "CE Loss: 0.3321501314640045, Freq(freq) Loss1: 0.9769313335418701\n",
      "Learning Rate: 6.597417400159181e-05\n",
      "Train Accuracy: 0.8986424803733826\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745591125488282 s\n",
      "Throughout: 2410.1506530980164 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9060999751091003\n",
      "\n",
      "\n",
      "Epoch: 150\n",
      "Train Loss: 1.267957091331482\n",
      "CE Loss: 0.29086557030677795, Freq(freq) Loss1: 0.9770914912223816\n",
      "Learning Rate: 6.578475516589145e-05\n",
      "Train Accuracy: 0.902296781539917\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74640612792969 s\n",
      "Throughout: 2410.0559726673764 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9091998934745789\n",
      "\n",
      "\n",
      "Epoch: 151\n",
      "Train Loss: 1.196242332458496\n",
      "CE Loss: 0.2200043797492981, Freq(freq) Loss1: 0.9762378931045532\n",
      "Learning Rate: 6.559434606925711e-05\n",
      "Train Accuracy: 0.9052606821060181\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743213470458983 s\n",
      "Throughout: 2410.4269124553175 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9118000268936157\n",
      "\n",
      "\n",
      "Epoch: 152\n",
      "Train Loss: 1.2378551959991455\n",
      "CE Loss: 0.26015612483024597, Freq(freq) Loss1: 0.9776990413665771\n",
      "Learning Rate: 6.540295416893678e-05\n",
      "Train Accuracy: 0.9029912948608398\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752732513427734 s\n",
      "Throughout: 2409.3212769763345 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9063000082969666\n",
      "\n",
      "\n",
      "Epoch: 153\n",
      "Train Loss: 1.2493733167648315\n",
      "CE Loss: 0.2731785178184509, Freq(freq) Loss1: 0.9761947989463806\n",
      "Learning Rate: 6.521058696066934e-05\n",
      "Train Accuracy: 0.9048904776573181\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.724445205688475 s\n",
      "Throughout: 2412.6098191654332 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9071999788284302\n",
      "\n",
      "\n",
      "Epoch: 154\n",
      "Train Loss: 1.2588847875595093\n",
      "CE Loss: 0.28201237320899963, Freq(freq) Loss1: 0.976872444152832\n",
      "Learning Rate: 6.501725197839094e-05\n",
      "Train Accuracy: 0.9086863994598389\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74328466796875 s\n",
      "Throughout: 2410.418639108237 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9065999984741211\n",
      "\n",
      "\n",
      "Epoch: 155\n",
      "Train Loss: 1.2637989521026611\n",
      "CE Loss: 0.2875223755836487, Freq(freq) Loss1: 0.9762765169143677\n",
      "Learning Rate: 6.482295679393999e-05\n",
      "Train Accuracy: 0.9058967232704163\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746871658325194 s\n",
      "Throughout: 2410.001894427118 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9089000225067139\n",
      "\n",
      "\n",
      "Epoch: 156\n",
      "Train Loss: 1.259706974029541\n",
      "CE Loss: 0.28232505917549133, Freq(freq) Loss1: 0.9773818850517273\n",
      "Learning Rate: 6.462770901676056e-05\n",
      "Train Accuracy: 0.9075474739074707\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.736015197753908 s\n",
      "Throughout: 2411.263664844146 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9097000360488892\n",
      "\n",
      "\n",
      "Epoch: 157\n",
      "Train Loss: 1.2725059986114502\n",
      "CE Loss: 0.2952507734298706, Freq(freq) Loss1: 0.9772552847862244\n",
      "Learning Rate: 6.443151629360445e-05\n",
      "Train Accuracy: 0.9080097675323486\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7572060546875 s\n",
      "Throughout: 2408.8020260659664 samples per second\n",
      "Val Loss: 0.28125\n",
      "Val Accuracy: 0.9068999886512756\n",
      "\n",
      "\n",
      "Epoch: 158\n",
      "Train Loss: 1.2526395320892334\n",
      "CE Loss: 0.27575528621673584, Freq(freq) Loss1: 0.9768843054771423\n",
      "Learning Rate: 6.423438630823159e-05\n",
      "Train Accuracy: 0.9086226224899292\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7478889465332 s\n",
      "Throughout: 2409.883729802524 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9075000286102295\n",
      "\n",
      "\n",
      "Epoch: 159\n",
      "Train Loss: 1.2742605209350586\n",
      "CE Loss: 0.29650431871414185, Freq(freq) Loss1: 0.977756142616272\n",
      "Learning Rate: 6.40363267811092e-05\n",
      "Train Accuracy: 0.9109305739402771\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72942492675781 s\n",
      "Throughout: 2412.0302505574746 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.9085999727249146\n",
      "\n",
      "\n",
      "Epoch: 160\n",
      "Train Loss: 1.2962100505828857\n",
      "CE Loss: 0.3193840980529785, Freq(freq) Loss1: 0.9768259525299072\n",
      "Learning Rate: 6.383734546910943e-05\n",
      "Train Accuracy: 0.912200927734375\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74783383178711 s\n",
      "Throughout: 2409.8901314409295 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9079000353813171\n",
      "\n",
      "\n",
      "Epoch: 161\n",
      "Train Loss: 1.266433596611023\n",
      "CE Loss: 0.2898349463939667, Freq(freq) Loss1: 0.9765986800193787\n",
      "Learning Rate: 6.363745016520547e-05\n",
      "Train Accuracy: 0.9114797115325928\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.717473571777344 s\n",
      "Throughout: 2413.4216861322884 samples per second\n",
      "Val Loss: 0.2890625\n",
      "Val Accuracy: 0.9091000556945801\n",
      "\n",
      "\n",
      "Epoch: 162\n",
      "Train Loss: 1.1997408866882324\n",
      "CE Loss: 0.22224846482276917, Freq(freq) Loss1: 0.9774923920631409\n",
      "Learning Rate: 6.343664869816645e-05\n",
      "Train Accuracy: 0.9111297726631165\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743373733520507 s\n",
      "Throughout: 2410.4082895253387 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.9040000438690186\n",
      "\n",
      "\n",
      "Epoch: 163\n",
      "Train Loss: 1.2010536193847656\n",
      "CE Loss: 0.22407087683677673, Freq(freq) Loss1: 0.9769827127456665\n",
      "Learning Rate: 6.323494893225075e-05\n",
      "Train Accuracy: 0.9124898910522461\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743396041870117 s\n",
      "Throughout: 2410.405697267508 samples per second\n",
      "Val Loss: 0.283203125\n",
      "Val Accuracy: 0.9111999273300171\n",
      "\n",
      "\n",
      "Epoch: 164\n",
      "Train Loss: 1.2049739360809326\n",
      "CE Loss: 0.22853513062000275, Freq(freq) Loss1: 0.9764387607574463\n",
      "Learning Rate: 6.30323587668981e-05\n",
      "Train Accuracy: 0.9127181172370911\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741881774902343 s\n",
      "Throughout: 2410.5816696197717 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.908500075340271\n",
      "\n",
      "\n",
      "Epoch: 165\n",
      "Train Loss: 1.22565758228302\n",
      "CE Loss: 0.2490905374288559, Freq(freq) Loss1: 0.9765670299530029\n",
      "Learning Rate: 6.282888613642006e-05\n",
      "Train Accuracy: 0.9149351716041565\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70711834716797 s\n",
      "Throughout: 2414.628591082462 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.9095000624656677\n",
      "\n",
      "\n",
      "Epoch: 166\n",
      "Train Loss: 1.2417585849761963\n",
      "CE Loss: 0.2632584869861603, Freq(freq) Loss1: 0.9785000681877136\n",
      "Learning Rate: 6.262453900968945e-05\n",
      "Train Accuracy: 0.9154538512229919\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743174362182618 s\n",
      "Throughout: 2410.4314569691032 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9035000205039978\n",
      "\n",
      "\n",
      "Epoch: 167\n",
      "Train Loss: 1.2594356536865234\n",
      "CE Loss: 0.28208786249160767, Freq(freq) Loss1: 0.977347731590271\n",
      "Learning Rate: 6.241932538982809e-05\n",
      "Train Accuracy: 0.9143568277359009\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.708962982177734 s\n",
      "Throughout: 2414.413509890878 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9063000082969666\n",
      "\n",
      "\n",
      "Epoch: 168\n",
      "Train Loss: 1.1774011850357056\n",
      "CE Loss: 0.19956621527671814, Freq(freq) Loss1: 0.977834939956665\n",
      "Learning Rate: 6.221325331389348e-05\n",
      "Train Accuracy: 0.9152880907058716\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746772842407225 s\n",
      "Throughout: 2410.0133731544997 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9106000661849976\n",
      "\n",
      "\n",
      "Epoch: 169\n",
      "Train Loss: 1.190382480621338\n",
      "CE Loss: 0.21456366777420044, Freq(freq) Loss1: 0.9758188724517822\n",
      "Learning Rate: 6.200633085256399e-05\n",
      "Train Accuracy: 0.9176256656646729\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742883865356447 s\n",
      "Throughout: 2410.465214217734 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.911300003528595\n",
      "\n",
      "\n",
      "Epoch: 170\n",
      "Train Loss: 1.1907296180725098\n",
      "CE Loss: 0.21355606615543365, Freq(freq) Loss1: 0.9771735072135925\n",
      "Learning Rate: 6.179856610982276e-05\n",
      "Train Accuracy: 0.9171151518821716\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751042373657228 s\n",
      "Throughout: 2409.5175124057077 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.906999945640564\n",
      "\n",
      "\n",
      "Epoch: 171\n",
      "Train Loss: 1.2087130546569824\n",
      "CE Loss: 0.22971585392951965, Freq(freq) Loss1: 0.9789972305297852\n",
      "Learning Rate: 6.158996722264035e-05\n",
      "Train Accuracy: 0.9188581109046936\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.732591339111327 s\n",
      "Throughout: 2411.6618700565764 samples per second\n",
      "Val Loss: 0.369140625\n",
      "Val Accuracy: 0.9093999266624451\n",
      "\n",
      "\n",
      "Epoch: 172\n",
      "Train Loss: 1.1995456218719482\n",
      "CE Loss: 0.22120437026023865, Freq(freq) Loss1: 0.9783412218093872\n",
      "Learning Rate: 6.138054236065602e-05\n",
      "Train Accuracy: 0.9177247285842896\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74764668273926 s\n",
      "Throughout: 2409.911869262593 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9074000120162964\n",
      "\n",
      "\n",
      "Epoch: 173\n",
      "Train Loss: 1.2505013942718506\n",
      "CE Loss: 0.2739921808242798, Freq(freq) Loss1: 0.9765092730522156\n",
      "Learning Rate: 6.11702997258578e-05\n",
      "Train Accuracy: 0.919191300868988\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752656051635743 s\n",
      "Throughout: 2409.330153961616 samples per second\n",
      "Val Loss: 0.33984375\n",
      "Val Accuracy: 0.9083999991416931\n",
      "\n",
      "\n",
      "Epoch: 174\n",
      "Train Loss: 1.1795861721038818\n",
      "CE Loss: 0.20331385731697083, Freq(freq) Loss1: 0.9762723445892334\n",
      "Learning Rate: 6.095924755226131e-05\n",
      "Train Accuracy: 0.9204363822937012\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75462547302246 s\n",
      "Throughout: 2409.1015308848446 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9073999524116516\n",
      "\n",
      "\n",
      "Epoch: 175\n",
      "Train Loss: 1.2204755544662476\n",
      "CE Loss: 0.2438202202320099, Freq(freq) Loss1: 0.9766553044319153\n",
      "Learning Rate: 6.074739410558714e-05\n",
      "Train Accuracy: 0.9203372001647949\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74293862915039 s\n",
      "Throughout: 2410.4588503064933 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9099000096321106\n",
      "\n",
      "\n",
      "Epoch: 176\n",
      "Train Loss: 1.2780652046203613\n",
      "CE Loss: 0.3012514114379883, Freq(freq) Loss1: 0.976813793182373\n",
      "Learning Rate: 6.053474768293729e-05\n",
      "Train Accuracy: 0.9195374846458435\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.691266204833983 s\n",
      "Throughout: 2416.4785037814063 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9114999771118164\n",
      "\n",
      "\n",
      "Epoch: 177\n",
      "Train Loss: 1.160754919052124\n",
      "CE Loss: 0.1836790144443512, Freq(freq) Loss1: 0.9770759344100952\n",
      "Learning Rate: 6.03213166124701e-05\n",
      "Train Accuracy: 0.9227241277694702\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748881851196288 s\n",
      "Throughout: 2409.7684086584754 samples per second\n",
      "Val Loss: 0.365234375\n",
      "Val Accuracy: 0.9120000004768372\n",
      "\n",
      "\n",
      "Epoch: 178\n",
      "Train Loss: 1.204656720161438\n",
      "CE Loss: 0.22804412245750427, Freq(freq) Loss1: 0.9766125679016113\n",
      "Learning Rate: 6.010710925307418e-05\n",
      "Train Accuracy: 0.9248376488685608\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72631086730957 s\n",
      "Throughout: 2412.392650100706 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9133999943733215\n",
      "\n",
      "\n",
      "Epoch: 179\n",
      "Train Loss: 1.1616134643554688\n",
      "CE Loss: 0.18564391136169434, Freq(freq) Loss1: 0.9759694933891296\n",
      "Learning Rate: 5.989213399404093e-05\n",
      "Train Accuracy: 0.9222990274429321\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.732531677246094 s\n",
      "Throughout: 2411.668810079518 samples per second\n",
      "Val Loss: 0.24609375\n",
      "Val Accuracy: 0.918999969959259\n",
      "\n",
      "\n",
      "Epoch: 180\n",
      "Train Loss: 1.2079724073410034\n",
      "CE Loss: 0.2309969812631607, Freq(freq) Loss1: 0.9769753813743591\n",
      "Learning Rate: 5.9676399254736066e-05\n",
      "Train Accuracy: 0.9234745502471924\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745878189086913 s\n",
      "Throughout: 2410.1173035085985 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9133000373840332\n",
      "\n",
      "\n",
      "Epoch: 181\n",
      "Train Loss: 1.19731605052948\n",
      "CE Loss: 0.2202358990907669, Freq(freq) Loss1: 0.9770801663398743\n",
      "Learning Rate: 5.9459913484269876e-05\n",
      "Train Accuracy: 0.9227761030197144\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752088165283205 s\n",
      "Throughout: 2409.396085915176 samples per second\n",
      "Val Loss: 0.37109375\n",
      "Val Accuracy: 0.9143000245094299\n",
      "\n",
      "\n",
      "Epoch: 182\n",
      "Train Loss: 1.1860955953598022\n",
      "CE Loss: 0.20636901259422302, Freq(freq) Loss1: 0.9797266125679016\n",
      "Learning Rate: 5.924268516116625e-05\n",
      "Train Accuracy: 0.9267827272415161\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743489166259767 s\n",
      "Throughout: 2410.3948761584084 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.9121999740600586\n",
      "\n",
      "\n",
      "Epoch: 183\n",
      "Train Loss: 1.189610242843628\n",
      "CE Loss: 0.21197183430194855, Freq(freq) Loss1: 0.9776383638381958\n",
      "Learning Rate: 5.9024722793030705e-05\n",
      "Train Accuracy: 0.9253016710281372\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74512384033203 s\n",
      "Throughout: 2410.2049418857428 samples per second\n",
      "Val Loss: 0.265625\n",
      "Val Accuracy: 0.9129999876022339\n",
      "\n",
      "\n",
      "Epoch: 184\n",
      "Train Loss: 1.1400485038757324\n",
      "CE Loss: 0.16378796100616455, Freq(freq) Loss1: 0.9762605428695679\n",
      "Learning Rate: 5.880603491621712e-05\n",
      "Train Accuracy: 0.9228026270866394\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745341812133788 s\n",
      "Throughout: 2410.17961780487 samples per second\n",
      "Val Loss: 0.345703125\n",
      "Val Accuracy: 0.9130001068115234\n",
      "\n",
      "\n",
      "Epoch: 185\n",
      "Train Loss: 1.2000693082809448\n",
      "CE Loss: 0.22301027178764343, Freq(freq) Loss1: 0.977059006690979\n",
      "Learning Rate: 5.858663009549348e-05\n",
      "Train Accuracy: 0.9276625514030457\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751529968261718 s\n",
      "Throughout: 2409.460896448221 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9136999845504761\n",
      "\n",
      "\n",
      "Epoch: 186\n",
      "Train Loss: 1.1308096647262573\n",
      "CE Loss: 0.15422189235687256, Freq(freq) Loss1: 0.9765877723693848\n",
      "Learning Rate: 5.836651692370638e-05\n",
      "Train Accuracy: 0.9260721802711487\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745313201904295 s\n",
      "Throughout: 2410.182941726341 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9128000140190125\n",
      "\n",
      "\n",
      "Epoch: 187\n",
      "Train Loss: 1.1966031789779663\n",
      "CE Loss: 0.21963880956172943, Freq(freq) Loss1: 0.9769644141197205\n",
      "Learning Rate: 5.814570402144453e-05\n",
      "Train Accuracy: 0.927703857421875\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752677780151366 s\n",
      "Throughout: 2409.327631339309 samples per second\n",
      "Val Loss: 0.34375\n",
      "Val Accuracy: 0.9158999919891357\n",
      "\n",
      "\n",
      "Epoch: 188\n",
      "Train Loss: 1.2234400510787964\n",
      "CE Loss: 0.2467823624610901, Freq(freq) Loss1: 0.9766576886177063\n",
      "Learning Rate: 5.792420003670115e-05\n",
      "Train Accuracy: 0.9290174841880798\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740156372070313 s\n",
      "Throughout: 2410.7822093054415 samples per second\n",
      "Val Loss: 0.359375\n",
      "Val Accuracy: 0.9186000227928162\n",
      "\n",
      "\n",
      "Epoch: 189\n",
      "Train Loss: 1.1599071025848389\n",
      "CE Loss: 0.18310853838920593, Freq(freq) Loss1: 0.9767985343933105\n",
      "Learning Rate: 5.770201364453523e-05\n",
      "Train Accuracy: 0.9276188015937805\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7436672668457 s\n",
      "Throughout: 2410.3741810356873 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9157000184059143\n",
      "\n",
      "\n",
      "Epoch: 190\n",
      "Train Loss: 1.2261016368865967\n",
      "CE Loss: 0.2494518756866455, Freq(freq) Loss1: 0.9766497015953064\n",
      "Learning Rate: 5.747915354673184e-05\n",
      "Train Accuracy: 0.9282023310661316\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743875869750976 s\n",
      "Throughout: 2410.349942023647 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9133000373840332\n",
      "\n",
      "\n",
      "Epoch: 191\n",
      "Train Loss: 1.1356754302978516\n",
      "CE Loss: 0.15837693214416504, Freq(freq) Loss1: 0.9772984385490417\n",
      "Learning Rate: 5.7255628471461206e-05\n",
      "Train Accuracy: 0.9291139841079712\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74571893310547 s\n",
      "Throughout: 2410.1358049448613 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.9140999913215637\n",
      "\n",
      "\n",
      "Epoch: 192\n",
      "Train Loss: 1.2200123071670532\n",
      "CE Loss: 0.24322053790092468, Freq(freq) Loss1: 0.9767917990684509\n",
      "Learning Rate: 5.7031447172937056e-05\n",
      "Train Accuracy: 0.929219126701355\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.724604705810545 s\n",
      "Throughout: 2412.59125130534 samples per second\n",
      "Val Loss: 0.28125\n",
      "Val Accuracy: 0.9149999618530273\n",
      "\n",
      "\n",
      "Epoch: 193\n",
      "Train Loss: 1.2111164331436157\n",
      "CE Loss: 0.23589208722114563, Freq(freq) Loss1: 0.9752243757247925\n",
      "Learning Rate: 5.680661843107362e-05\n",
      "Train Accuracy: 0.9325911998748779\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747992904663086 s\n",
      "Throughout: 2409.871655043923 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9186000823974609\n",
      "\n",
      "\n",
      "Epoch: 194\n",
      "Train Loss: 1.1620970964431763\n",
      "CE Loss: 0.1840871274471283, Freq(freq) Loss1: 0.9780099391937256\n",
      "Learning Rate: 5.6581151051141836e-05\n",
      "Train Accuracy: 0.9294678568840027\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72628594970703 s\n",
      "Throughout: 2412.395550332874 samples per second\n",
      "Val Loss: 0.275390625\n",
      "Val Accuracy: 0.9155999422073364\n",
      "\n",
      "\n",
      "Epoch: 195\n",
      "Train Loss: 1.1543684005737305\n",
      "CE Loss: 0.17709237337112427, Freq(freq) Loss1: 0.977276086807251\n",
      "Learning Rate: 5.63550538634245e-05\n",
      "Train Accuracy: 0.9298122525215149\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743879119873046 s\n",
      "Throughout: 2410.3495643733777 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9159999489784241\n",
      "\n",
      "\n",
      "Epoch: 196\n",
      "Train Loss: 1.177519679069519\n",
      "CE Loss: 0.2010495364665985, Freq(freq) Loss1: 0.9764701128005981\n",
      "Learning Rate: 5.6128335722870404e-05\n",
      "Train Accuracy: 0.9310389161109924\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.723106201171873 s\n",
      "Throughout: 2412.765707737991 samples per second\n",
      "Val Loss: 0.26953125\n",
      "Val Accuracy: 0.9141000509262085\n",
      "\n",
      "\n",
      "Epoch: 197\n",
      "Train Loss: 1.1739853620529175\n",
      "CE Loss: 0.19535425305366516, Freq(freq) Loss1: 0.9786310791969299\n",
      "Learning Rate: 5.590100550874754e-05\n",
      "Train Accuracy: 0.932296633720398\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750656036376952 s\n",
      "Throughout: 2409.562372984616 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9160000085830688\n",
      "\n",
      "\n",
      "Epoch: 198\n",
      "Train Loss: 1.1630135774612427\n",
      "CE Loss: 0.1853785216808319, Freq(freq) Loss1: 0.9776350259780884\n",
      "Learning Rate: 5.56730721242954e-05\n",
      "Train Accuracy: 0.9336113333702087\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.711484451293945 s\n",
      "Throughout: 2414.1195730118834 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9131999611854553\n",
      "\n",
      "\n",
      "Epoch: 199\n",
      "Train Loss: 1.1996749639511108\n",
      "CE Loss: 0.22231103479862213, Freq(freq) Loss1: 0.9773639440536499\n",
      "Learning Rate: 5.544454449637621e-05\n",
      "Train Accuracy: 0.9351128339767456\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73655096435547 s\n",
      "Throughout: 2411.201365451089 samples per second\n",
      "Val Loss: 0.345703125\n",
      "Val Accuracy: 0.9151999950408936\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "Train Loss: 1.1704509258270264\n",
      "CE Loss: 0.1934126317501068, Freq(freq) Loss1: 0.9770383238792419\n",
      "Learning Rate: 5.5215431575125374e-05\n",
      "Train Accuracy: 0.9321059584617615\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74589974975586 s\n",
      "Throughout: 2410.1147987369604 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.9185999631881714\n",
      "\n",
      "\n",
      "Epoch: 201\n",
      "Train Loss: 1.1732568740844727\n",
      "CE Loss: 0.1966148316860199, Freq(freq) Loss1: 0.9766420125961304\n",
      "Learning Rate: 5.498574233360093e-05\n",
      "Train Accuracy: 0.9350565075874329\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744220672607423 s\n",
      "Throughout: 2410.3098780676105 samples per second\n",
      "Val Loss: 0.37109375\n",
      "Val Accuracy: 0.9178000092506409\n",
      "\n",
      "\n",
      "Epoch: 202\n",
      "Train Loss: 1.133086085319519\n",
      "CE Loss: 0.15702219307422638, Freq(freq) Loss1: 0.9760639071464539\n",
      "Learning Rate: 5.47554857674321e-05\n",
      "Train Accuracy: 0.9339746236801147\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.764465255737306 s\n",
      "Throughout: 2407.959915374406 samples per second\n",
      "Val Loss: 0.365234375\n",
      "Val Accuracy: 0.9183000326156616\n",
      "\n",
      "\n",
      "Epoch: 203\n",
      "Train Loss: 1.176619052886963\n",
      "CE Loss: 0.19976945221424103, Freq(freq) Loss1: 0.9768496155738831\n",
      "Learning Rate: 5.4524670894467024e-05\n",
      "Train Accuracy: 0.935019850730896\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746918197631835 s\n",
      "Throughout: 2409.9964883318075 samples per second\n",
      "Val Loss: 0.3515625\n",
      "Val Accuracy: 0.9160000085830688\n",
      "\n",
      "\n",
      "Epoch: 204\n",
      "Train Loss: 1.1233494281768799\n",
      "CE Loss: 0.1452653706073761, Freq(freq) Loss1: 0.9780840873718262\n",
      "Learning Rate: 5.429330675441957e-05\n",
      "Train Accuracy: 0.9357093572616577\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70670555114746 s\n",
      "Throughout: 2414.6767276182786 samples per second\n",
      "Val Loss: 0.2734375\n",
      "Val Accuracy: 0.91920006275177\n",
      "\n",
      "\n",
      "Epoch: 205\n",
      "Train Loss: 1.1479235887527466\n",
      "CE Loss: 0.17024430632591248, Freq(freq) Loss1: 0.9776792526245117\n",
      "Learning Rate: 5.406140240851528e-05\n",
      "Train Accuracy: 0.9356635808944702\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75430191040039 s\n",
      "Throughout: 2409.1390891323604 samples per second\n",
      "Val Loss: 0.34375\n",
      "Val Accuracy: 0.9160000085830688\n",
      "\n",
      "\n",
      "Epoch: 206\n",
      "Train Loss: 1.1306506395339966\n",
      "CE Loss: 0.15443986654281616, Freq(freq) Loss1: 0.9762107729911804\n",
      "Learning Rate: 5.382896693913651e-05\n",
      "Train Accuracy: 0.9364303350448608\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742671981811522 s\n",
      "Throughout: 2410.489836788777 samples per second\n",
      "Val Loss: 0.357421875\n",
      "Val Accuracy: 0.915399968624115\n",
      "\n",
      "\n",
      "Epoch: 207\n",
      "Train Loss: 1.1829248666763306\n",
      "CE Loss: 0.20527921617031097, Freq(freq) Loss1: 0.9776456952095032\n",
      "Learning Rate: 5.359600944946671e-05\n",
      "Train Accuracy: 0.9366376399993896\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744320190429686 s\n",
      "Throughout: 2410.2983149608012 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9176000356674194\n",
      "\n",
      "\n",
      "Epoch: 208\n",
      "Train Loss: 1.129469871520996\n",
      "CE Loss: 0.1515914499759674, Freq(freq) Loss1: 0.9778784513473511\n",
      "Learning Rate: 5.336253906313391e-05\n",
      "Train Accuracy: 0.9364258646965027\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.756502655029298 s\n",
      "Throughout: 2408.883655931555 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9188999533653259\n",
      "\n",
      "\n",
      "Epoch: 209\n",
      "Train Loss: 1.1319420337677002\n",
      "CE Loss: 0.15328747034072876, Freq(freq) Loss1: 0.9786545634269714\n",
      "Learning Rate: 5.312856492385347e-05\n",
      "Train Accuracy: 0.9364790320396423\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744796875 s\n",
      "Throughout: 2410.2429298913057 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9187000393867493\n",
      "\n",
      "\n",
      "Epoch: 210\n",
      "Train Loss: 1.1610667705535889\n",
      "CE Loss: 0.18461164832115173, Freq(freq) Loss1: 0.9764551520347595\n",
      "Learning Rate: 5.2894096195069805e-05\n",
      "Train Accuracy: 0.938066840171814\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74625434875488 s\n",
      "Throughout: 2410.0736045878484 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.919499933719635\n",
      "\n",
      "\n",
      "Epoch: 211\n",
      "Train Loss: 1.1843781471252441\n",
      "CE Loss: 0.20699018239974976, Freq(freq) Loss1: 0.9773879647254944\n",
      "Learning Rate: 5.2659142059597665e-05\n",
      "Train Accuracy: 0.9374428987503052\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740333435058595 s\n",
      "Throughout: 2410.761628136705 samples per second\n",
      "Val Loss: 0.361328125\n",
      "Val Accuracy: 0.9186999797821045\n",
      "\n",
      "\n",
      "Epoch: 212\n",
      "Train Loss: 1.2217768430709839\n",
      "CE Loss: 0.2444317787885666, Freq(freq) Loss1: 0.9773451089859009\n",
      "Learning Rate: 5.242371171926242e-05\n",
      "Train Accuracy: 0.9365950226783752\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74403840637207 s\n",
      "Throughout: 2410.331056109171 samples per second\n",
      "Val Loss: 0.40625\n",
      "Val Accuracy: 0.914400041103363\n",
      "\n",
      "\n",
      "Epoch: 213\n",
      "Train Loss: 1.1667366027832031\n",
      "CE Loss: 0.18944519758224487, Freq(freq) Loss1: 0.977291464805603\n",
      "Learning Rate: 5.2187814394539694e-05\n",
      "Train Accuracy: 0.9385024905204773\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7463455657959 s\n",
      "Throughout: 2410.0630080332817 samples per second\n",
      "Val Loss: 0.3359375\n",
      "Val Accuracy: 0.9177999496459961\n",
      "\n",
      "\n",
      "Epoch: 214\n",
      "Train Loss: 1.1652560234069824\n",
      "CE Loss: 0.18805283308029175, Freq(freq) Loss1: 0.9772031903266907\n",
      "Learning Rate: 5.195145932419426e-05\n",
      "Train Accuracy: 0.9397692680358887\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742245361328123 s\n",
      "Throughout: 2410.5394150442403 samples per second\n",
      "Val Loss: 0.275390625\n",
      "Val Accuracy: 0.920699954032898\n",
      "\n",
      "\n",
      "Epoch: 215\n",
      "Train Loss: 1.1625789403915405\n",
      "CE Loss: 0.1849537193775177, Freq(freq) Loss1: 0.9776251912117004\n",
      "Learning Rate: 5.171465576491819e-05\n",
      "Train Accuracy: 0.9392884969711304\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740585983276368 s\n",
      "Throughout: 2410.732273442814 samples per second\n",
      "Val Loss: 0.2431640625\n",
      "Val Accuracy: 0.9182000160217285\n",
      "\n",
      "\n",
      "Epoch: 216\n",
      "Train Loss: 1.1513367891311646\n",
      "CE Loss: 0.17513784766197205, Freq(freq) Loss1: 0.9761989116668701\n",
      "Learning Rate: 5.147741299096832e-05\n",
      "Train Accuracy: 0.941274881362915\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746366912841797 s\n",
      "Throughout: 2410.0605281906246 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9147999882698059\n",
      "\n",
      "\n",
      "Epoch: 217\n",
      "Train Loss: 1.1306366920471191\n",
      "CE Loss: 0.1523141711950302, Freq(freq) Loss1: 0.9783225059509277\n",
      "Learning Rate: 5.1239740293803074e-05\n",
      "Train Accuracy: 0.9391512870788574\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751584915161132 s\n",
      "Throughout: 2409.454516578632 samples per second\n",
      "Val Loss: 0.275390625\n",
      "Val Accuracy: 0.9170000553131104\n",
      "\n",
      "\n",
      "Epoch: 218\n",
      "Train Loss: 1.1267814636230469\n",
      "CE Loss: 0.15049105882644653, Freq(freq) Loss1: 0.9762904047966003\n",
      "Learning Rate: 5.10016469817185e-05\n",
      "Train Accuracy: 0.9405006170272827\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74466436767578 s\n",
      "Throughout: 2410.2583254087117 samples per second\n",
      "Val Loss: 0.33984375\n",
      "Val Accuracy: 0.9191999435424805\n",
      "\n",
      "\n",
      "Epoch: 219\n",
      "Train Loss: 1.1296684741973877\n",
      "CE Loss: 0.15164843201637268, Freq(freq) Loss1: 0.9780200123786926\n",
      "Learning Rate: 5.0763142379483795e-05\n",
      "Train Accuracy: 0.9388145804405212\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.726373046875 s\n",
      "Throughout: 2412.3854128708113 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.917699933052063\n",
      "\n",
      "\n",
      "Epoch: 220\n",
      "Train Loss: 1.1515520811080933\n",
      "CE Loss: 0.17480340600013733, Freq(freq) Loss1: 0.9767487049102783\n",
      "Learning Rate: 5.052423582797604e-05\n",
      "Train Accuracy: 0.9413453936576843\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.719472259521485 s\n",
      "Throughout: 2413.1888772901953 samples per second\n",
      "Val Loss: 0.287109375\n",
      "Val Accuracy: 0.9204000234603882\n",
      "\n",
      "\n",
      "Epoch: 221\n",
      "Train Loss: 1.1291701793670654\n",
      "CE Loss: 0.152802512049675, Freq(freq) Loss1: 0.976367712020874\n",
      "Learning Rate: 5.028493668381439e-05\n",
      "Train Accuracy: 0.9417706727981567\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742216690063476 s\n",
      "Throughout: 2410.5427470513514 samples per second\n",
      "Val Loss: 0.2314453125\n",
      "Val Accuracy: 0.9187000393867493\n",
      "\n",
      "\n",
      "Epoch: 222\n",
      "Train Loss: 1.1317503452301025\n",
      "CE Loss: 0.15502363443374634, Freq(freq) Loss1: 0.9767267107963562\n",
      "Learning Rate: 5.0045254318993646e-05\n",
      "Train Accuracy: 0.943252444267273\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748298248291015 s\n",
      "Throughout: 2409.8361900170958 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9185000061988831\n",
      "\n",
      "\n",
      "Epoch: 223\n",
      "Train Loss: 1.1342207193374634\n",
      "CE Loss: 0.1567181795835495, Freq(freq) Loss1: 0.9775025248527527\n",
      "Learning Rate: 4.980519812051723e-05\n",
      "Train Accuracy: 0.9413591623306274\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74284130859375 s\n",
      "Throughout: 2410.470159615261 samples per second\n",
      "Val Loss: 0.263671875\n",
      "Val Accuracy: 0.9147000312805176\n",
      "\n",
      "\n",
      "Epoch: 224\n",
      "Train Loss: 1.1069765090942383\n",
      "CE Loss: 0.127973735332489, Freq(freq) Loss1: 0.979002833366394\n",
      "Learning Rate: 4.956477749002944e-05\n",
      "Train Accuracy: 0.942423939704895\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.724314498901368 s\n",
      "Throughout: 2412.625035325081 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9147000908851624\n",
      "\n",
      "\n",
      "Epoch: 225\n",
      "Train Loss: 1.1004319190979004\n",
      "CE Loss: 0.12356989830732346, Freq(freq) Loss1: 0.9768620729446411\n",
      "Learning Rate: 4.932400184344738e-05\n",
      "Train Accuracy: 0.9415580034255981\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751893005371095 s\n",
      "Throughout: 2409.418744933717 samples per second\n",
      "Val Loss: 0.251953125\n",
      "Val Accuracy: 0.919700026512146\n",
      "\n",
      "\n",
      "Epoch: 226\n",
      "Train Loss: 1.179133653640747\n",
      "CE Loss: 0.20270481705665588, Freq(freq) Loss1: 0.9764288067817688\n",
      "Learning Rate: 4.908288061059212e-05\n",
      "Train Accuracy: 0.9431402087211609\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74441651916504 s\n",
      "Throughout: 2410.2871225038675 samples per second\n",
      "Val Loss: 0.34765625\n",
      "Val Accuracy: 0.9162000417709351\n",
      "\n",
      "\n",
      "Epoch: 227\n",
      "Train Loss: 1.1462454795837402\n",
      "CE Loss: 0.1699102222919464, Freq(freq) Loss1: 0.9763352274894714\n",
      "Learning Rate: 4.8841423234819345e-05\n",
      "Train Accuracy: 0.9443828463554382\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752846405029295 s\n",
      "Throughout: 2409.3080546234314 samples per second\n",
      "Val Loss: 0.337890625\n",
      "Val Accuracy: 0.9186999201774597\n",
      "\n",
      "\n",
      "Epoch: 228\n",
      "Train Loss: 1.1248310804367065\n",
      "CE Loss: 0.14693105220794678, Freq(freq) Loss1: 0.9779000282287598\n",
      "Learning Rate: 4.859963917264962e-05\n",
      "Train Accuracy: 0.9437534809112549\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.685221618652342 s\n",
      "Throughout: 2417.184641372846 samples per second\n",
      "Val Loss: 0.3359375\n",
      "Val Accuracy: 0.924500048160553\n",
      "\n",
      "\n",
      "Epoch: 229\n",
      "Train Loss: 1.1256111860275269\n",
      "CE Loss: 0.14972557127475739, Freq(freq) Loss1: 0.9758855700492859\n",
      "Learning Rate: 4.8357537893397905e-05\n",
      "Train Accuracy: 0.9451815485954285\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.761193786621092 s\n",
      "Throughout: 2408.339352442293 samples per second\n",
      "Val Loss: 0.28125\n",
      "Val Accuracy: 0.9223000407218933\n",
      "\n",
      "\n",
      "Epoch: 230\n",
      "Train Loss: 1.1427422761917114\n",
      "CE Loss: 0.16494762897491455, Freq(freq) Loss1: 0.9777946472167969\n",
      "Learning Rate: 4.811512887880283e-05\n",
      "Train Accuracy: 0.9434568881988525\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70402410888672 s\n",
      "Throughout: 2414.9894598769647 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9180000424385071\n",
      "\n",
      "\n",
      "Epoch: 231\n",
      "Train Loss: 1.1971962451934814\n",
      "CE Loss: 0.2199619561433792, Freq(freq) Loss1: 0.9772342443466187\n",
      "Learning Rate: 4.787242162265523e-05\n",
      "Train Accuracy: 0.9462252259254456\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74742837524414 s\n",
      "Throughout: 2409.9372267099893 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9199000597000122\n",
      "\n",
      "\n",
      "Epoch: 232\n",
      "Train Loss: 1.1595280170440674\n",
      "CE Loss: 0.18296200037002563, Freq(freq) Loss1: 0.9765660166740417\n",
      "Learning Rate: 4.762942563042638e-05\n",
      "Train Accuracy: 0.9465268850326538\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741254776000975 s\n",
      "Throughout: 2410.6545404308595 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.9248999953269958\n",
      "\n",
      "\n",
      "Epoch: 233\n",
      "Train Loss: 1.1221708059310913\n",
      "CE Loss: 0.14474701881408691, Freq(freq) Loss1: 0.9774237871170044\n",
      "Learning Rate: 4.738615041889573e-05\n",
      "Train Accuracy: 0.9452334046363831\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748036834716796 s\n",
      "Throughout: 2409.866552595335 samples per second\n",
      "Val Loss: 0.267578125\n",
      "Val Accuracy: 0.9193000197410583\n",
      "\n",
      "\n",
      "Epoch: 234\n",
      "Train Loss: 1.113707423210144\n",
      "CE Loss: 0.13674388825893402, Freq(freq) Loss1: 0.9769635200500488\n",
      "Learning Rate: 4.714260551577819e-05\n",
      "Train Accuracy: 0.9454749822616577\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746469100952147 s\n",
      "Throughout: 2410.048657277555 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9196000099182129\n",
      "\n",
      "\n",
      "Epoch: 235\n",
      "Train Loss: 1.1376919746398926\n",
      "CE Loss: 0.16080784797668457, Freq(freq) Loss1: 0.976884126663208\n",
      "Learning Rate: 4.68988004593509e-05\n",
      "Train Accuracy: 0.9464335441589355\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740279586791992 s\n",
      "Throughout: 2410.7678872295164 samples per second\n",
      "Val Loss: 0.353515625\n",
      "Val Accuracy: 0.9197999835014343\n",
      "\n",
      "\n",
      "Epoch: 236\n",
      "Train Loss: 1.1480704545974731\n",
      "CE Loss: 0.17124998569488525, Freq(freq) Loss1: 0.9768204689025879\n",
      "Learning Rate: 4.66547447980798e-05\n",
      "Train Accuracy: 0.9472439289093018\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744870254516602 s\n",
      "Throughout: 2410.2344042915347 samples per second\n",
      "Val Loss: 0.271484375\n",
      "Val Accuracy: 0.9212000370025635\n",
      "\n",
      "\n",
      "Epoch: 237\n",
      "Train Loss: 1.1365362405776978\n",
      "CE Loss: 0.1596750169992447, Freq(freq) Loss1: 0.9768612384796143\n",
      "Learning Rate: 4.641044809024558e-05\n",
      "Train Accuracy: 0.9472623467445374\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.761620010375978 s\n",
      "Throughout: 2408.289910662638 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9228000044822693\n",
      "\n",
      "\n",
      "Epoch: 238\n",
      "Train Loss: 1.1332796812057495\n",
      "CE Loss: 0.15681128203868866, Freq(freq) Loss1: 0.9764683842658997\n",
      "Learning Rate: 4.616591990356935e-05\n",
      "Train Accuracy: 0.9478732347488403\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742783447265627 s\n",
      "Throughout: 2410.4768835443415 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9194000363349915\n",
      "\n",
      "\n",
      "Epoch: 239\n",
      "Train Loss: 1.1127277612686157\n",
      "CE Loss: 0.13501109182834625, Freq(freq) Loss1: 0.9777166247367859\n",
      "Learning Rate: 4.592116981483797e-05\n",
      "Train Accuracy: 0.9450739622116089\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752203811645508 s\n",
      "Throughout: 2409.3826590090407 samples per second\n",
      "Val Loss: 0.337890625\n",
      "Val Accuracy: 0.9210000038146973\n",
      "\n",
      "\n",
      "Epoch: 240\n",
      "Train Loss: 1.1082967519760132\n",
      "CE Loss: 0.13226543366909027, Freq(freq) Loss1: 0.9760313034057617\n",
      "Learning Rate: 4.5676207409528904e-05\n",
      "Train Accuracy: 0.948327898979187\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753396865844728 s\n",
      "Throughout: 2409.2441504016333 samples per second\n",
      "Val Loss: 0.359375\n",
      "Val Accuracy: 0.9196000099182129\n",
      "\n",
      "\n",
      "Epoch: 241\n",
      "Train Loss: 1.0894227027893066\n",
      "CE Loss: 0.11302356421947479, Freq(freq) Loss1: 0.9763991236686707\n",
      "Learning Rate: 4.5431042281434904e-05\n",
      "Train Accuracy: 0.949134349822998\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.728052856445313 s\n",
      "Throughout: 2412.1899122064756 samples per second\n",
      "Val Loss: 0.283203125\n",
      "Val Accuracy: 0.9212000370025635\n",
      "\n",
      "\n",
      "Epoch: 242\n",
      "Train Loss: 1.1230586767196655\n",
      "CE Loss: 0.14523573219776154, Freq(freq) Loss1: 0.9778229594230652\n",
      "Learning Rate: 4.51856840322882e-05\n",
      "Train Accuracy: 0.947986364364624\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740434997558594 s\n",
      "Throughout: 2410.7498230333945 samples per second\n",
      "Val Loss: 0.287109375\n",
      "Val Accuracy: 0.9188999533653259\n",
      "\n",
      "\n",
      "Epoch: 243\n",
      "Train Loss: 1.213456630706787\n",
      "CE Loss: 0.23682646453380585, Freq(freq) Loss1: 0.9766302108764648\n",
      "Learning Rate: 4.4940142271384466e-05\n",
      "Train Accuracy: 0.9497612714767456\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743581802368166 s\n",
      "Throughout: 2410.384111884275 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9207000136375427\n",
      "\n",
      "\n",
      "Epoch: 244\n",
      "Train Loss: 1.1090919971466064\n",
      "CE Loss: 0.13130760192871094, Freq(freq) Loss1: 0.9777843356132507\n",
      "Learning Rate: 4.469442661520653e-05\n",
      "Train Accuracy: 0.9471589922904968\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744284866333007 s\n",
      "Throughout: 2410.302419301406 samples per second\n",
      "Val Loss: 0.37109375\n",
      "Val Accuracy: 0.9182000160217285\n",
      "\n",
      "\n",
      "Epoch: 245\n",
      "Train Loss: 1.1081440448760986\n",
      "CE Loss: 0.13148562610149384, Freq(freq) Loss1: 0.9766584634780884\n",
      "Learning Rate: 4.4448546687047714e-05\n",
      "Train Accuracy: 0.9495189785957336\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747751586914063 s\n",
      "Throughout: 2409.8996843366776 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9197999835014343\n",
      "\n",
      "\n",
      "Epoch: 246\n",
      "Train Loss: 1.1320133209228516\n",
      "CE Loss: 0.155985027551651, Freq(freq) Loss1: 0.9760282635688782\n",
      "Learning Rate: 4.4202512116634914e-05\n",
      "Train Accuracy: 0.9477201700210571\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744285812377928 s\n",
      "Throughout: 2410.3023093793595 samples per second\n",
      "Val Loss: 0.259765625\n",
      "Val Accuracy: 0.9192000031471252\n",
      "\n",
      "\n",
      "Epoch: 247\n",
      "Train Loss: 1.1130543947219849\n",
      "CE Loss: 0.13462363183498383, Freq(freq) Loss1: 0.9784307479858398\n",
      "Learning Rate: 4.395633253975151e-05\n",
      "Train Accuracy: 0.9515672326087952\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7458751373291 s\n",
      "Throughout: 2410.117658041452 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9208999872207642\n",
      "\n",
      "\n",
      "Epoch: 248\n",
      "Train Loss: 1.1728301048278809\n",
      "CE Loss: 0.19630518555641174, Freq(freq) Loss1: 0.9765248894691467\n",
      "Learning Rate: 4.371001759785997e-05\n",
      "Train Accuracy: 0.95110684633255\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74583139038086 s\n",
      "Throughout: 2410.1227402813706 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9177000522613525\n",
      "\n",
      "\n",
      "Epoch: 249\n",
      "Train Loss: 1.1103683710098267\n",
      "CE Loss: 0.13336625695228577, Freq(freq) Loss1: 0.9770021438598633\n",
      "Learning Rate: 4.346357693772421e-05\n",
      "Train Accuracy: 0.9508920311927795\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.760840591430664 s\n",
      "Throughout: 2408.3803244767564 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9225000143051147\n",
      "\n",
      "\n",
      "Epoch: 250\n",
      "Train Loss: 1.0892812013626099\n",
      "CE Loss: 0.11152534931898117, Freq(freq) Loss1: 0.9777559041976929\n",
      "Learning Rate: 4.321702021103189e-05\n",
      "Train Accuracy: 0.9512873291969299\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7446681060791 s\n",
      "Throughout: 2410.257891055283 samples per second\n",
      "Val Loss: 0.2734375\n",
      "Val Accuracy: 0.9232000112533569\n",
      "\n",
      "\n",
      "Epoch: 251\n",
      "Train Loss: 1.177525520324707\n",
      "CE Loss: 0.20053350925445557, Freq(freq) Loss1: 0.9769920110702515\n",
      "Learning Rate: 4.297035707401623e-05\n",
      "Train Accuracy: 0.9512503743171692\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.740572525024415 s\n",
      "Throughout: 2410.7338377314704 samples per second\n",
      "Val Loss: 0.28515625\n",
      "Val Accuracy: 0.9199000000953674\n",
      "\n",
      "\n",
      "Epoch: 252\n",
      "Train Loss: 1.130814552307129\n",
      "CE Loss: 0.15249784290790558, Freq(freq) Loss1: 0.9783167243003845\n",
      "Learning Rate: 4.2723597187078066e-05\n",
      "Train Accuracy: 0.9519792795181274\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746392959594726 s\n",
      "Throughout: 2410.057502399527 samples per second\n",
      "Val Loss: 0.2890625\n",
      "Val Accuracy: 0.9203001260757446\n",
      "\n",
      "\n",
      "Epoch: 253\n",
      "Train Loss: 1.0978223085403442\n",
      "CE Loss: 0.1209220215678215, Freq(freq) Loss1: 0.9769002795219421\n",
      "Learning Rate: 4.24767502144073e-05\n",
      "Train Accuracy: 0.9531086087226868\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745862045288085 s\n",
      "Throughout: 2410.119178988577 samples per second\n",
      "Val Loss: 0.232421875\n",
      "Val Accuracy: 0.9213000535964966\n",
      "\n",
      "\n",
      "Epoch: 254\n",
      "Train Loss: 1.112051248550415\n",
      "CE Loss: 0.13535110652446747, Freq(freq) Loss1: 0.9767001867294312\n",
      "Learning Rate: 4.2229825823604506e-05\n",
      "Train Accuracy: 0.9525769352912903\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.707076217651366 s\n",
      "Throughout: 2414.633503757446 samples per second\n",
      "Val Loss: 0.23046875\n",
      "Val Accuracy: 0.9233999848365784\n",
      "\n",
      "\n",
      "Epoch: 255\n",
      "Train Loss: 1.1182727813720703\n",
      "CE Loss: 0.14002937078475952, Freq(freq) Loss1: 0.9782434105873108\n",
      "Learning Rate: 4.198283368530231e-05\n",
      "Train Accuracy: 0.9537116289138794\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74316911315918 s\n",
      "Throughout: 2410.4320669246576 samples per second\n",
      "Val Loss: 0.28515625\n",
      "Val Accuracy: 0.919700026512146\n",
      "\n",
      "\n",
      "Epoch: 256\n",
      "Train Loss: 1.1237136125564575\n",
      "CE Loss: 0.14655658602714539, Freq(freq) Loss1: 0.9771570563316345\n",
      "Learning Rate: 4.17357834727866e-05\n",
      "Train Accuracy: 0.9537097215652466\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.749682235717774 s\n",
      "Throughout: 2409.6754558453795 samples per second\n",
      "Val Loss: 0.28515625\n",
      "Val Accuracy: 0.9252000451087952\n",
      "\n",
      "\n",
      "Epoch: 257\n",
      "Train Loss: 1.0813055038452148\n",
      "CE Loss: 0.10503756999969482, Freq(freq) Loss1: 0.9762678742408752\n",
      "Learning Rate: 4.14886848616177e-05\n",
      "Train Accuracy: 0.9512917399406433\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75311848449707 s\n",
      "Throughout: 2409.276467888469 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9211000204086304\n",
      "\n",
      "\n",
      "Epoch: 258\n",
      "Train Loss: 1.1198827028274536\n",
      "CE Loss: 0.14306090772151947, Freq(freq) Loss1: 0.9768218398094177\n",
      "Learning Rate: 4.1241547529251464e-05\n",
      "Train Accuracy: 0.9538764953613281\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.769630798339843 s\n",
      "Throughout: 2407.3610400429743 samples per second\n",
      "Val Loss: 0.28515625\n",
      "Val Accuracy: 0.9219000935554504\n",
      "\n",
      "\n",
      "Epoch: 259\n",
      "Train Loss: 1.119079828262329\n",
      "CE Loss: 0.14223173260688782, Freq(freq) Loss1: 0.9768480658531189\n",
      "Learning Rate: 4.099438115466023e-05\n",
      "Train Accuracy: 0.9536710977554321\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.757649932861327 s\n",
      "Throughout: 2408.7505166394226 samples per second\n",
      "Val Loss: 0.2333984375\n",
      "Val Accuracy: 0.9223998785018921\n",
      "\n",
      "\n",
      "Epoch: 260\n",
      "Train Loss: 1.1098734140396118\n",
      "CE Loss: 0.13271012902259827, Freq(freq) Loss1: 0.9771633148193359\n",
      "Learning Rate: 4.074719541795372e-05\n",
      "Train Accuracy: 0.952947199344635\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.732975967407228 s\n",
      "Throughout: 2411.6171300541364 samples per second\n",
      "Val Loss: 0.2275390625\n",
      "Val Accuracy: 0.9240999817848206\n",
      "\n",
      "\n",
      "Epoch: 261\n",
      "Train Loss: 1.093568205833435\n",
      "CE Loss: 0.11590918898582458, Freq(freq) Loss1: 0.9776589870452881\n",
      "Learning Rate: 4.0499999999999995e-05\n",
      "Train Accuracy: 0.9553820490837097\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70805221557617 s\n",
      "Throughout: 2414.51969888269 samples per second\n",
      "Val Loss: 0.287109375\n",
      "Val Accuracy: 0.9233999848365784\n",
      "\n",
      "\n",
      "Epoch: 262\n",
      "Train Loss: 1.1055471897125244\n",
      "CE Loss: 0.12786102294921875, Freq(freq) Loss1: 0.9776861667633057\n",
      "Learning Rate: 4.025280458204627e-05\n",
      "Train Accuracy: 0.9551391005516052\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72896908569336 s\n",
      "Throughout: 2412.083292386634 samples per second\n",
      "Val Loss: 0.2294921875\n",
      "Val Accuracy: 0.9248000383377075\n",
      "\n",
      "\n",
      "Epoch: 263\n",
      "Train Loss: 1.0656417608261108\n",
      "CE Loss: 0.08669134974479675, Freq(freq) Loss1: 0.9789503812789917\n",
      "Learning Rate: 4.000561884533976e-05\n",
      "Train Accuracy: 0.9544202089309692\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748435333251955 s\n",
      "Throughout: 2409.820268223733 samples per second\n",
      "Val Loss: 0.2490234375\n",
      "Val Accuracy: 0.9252000451087952\n",
      "\n",
      "\n",
      "Epoch: 264\n",
      "Train Loss: 1.0907368659973145\n",
      "CE Loss: 0.1134086325764656, Freq(freq) Loss1: 0.9773281812667847\n",
      "Learning Rate: 3.975845247074852e-05\n",
      "Train Accuracy: 0.9560272693634033\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74504054260254 s\n",
      "Throughout: 2410.214619601188 samples per second\n",
      "Val Loss: 0.232421875\n",
      "Val Accuracy: 0.9210999608039856\n",
      "\n",
      "\n",
      "Epoch: 265\n",
      "Train Loss: 1.1198409795761108\n",
      "CE Loss: 0.14316557347774506, Freq(freq) Loss1: 0.9766753911972046\n",
      "Learning Rate: 3.951131513838228e-05\n",
      "Train Accuracy: 0.9547741413116455\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72071765136719 s\n",
      "Throughout: 2413.0438357042576 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9215999245643616\n",
      "\n",
      "\n",
      "Epoch: 266\n",
      "Train Loss: 1.1200757026672363\n",
      "CE Loss: 0.14254827797412872, Freq(freq) Loss1: 0.977527379989624\n",
      "Learning Rate: 3.926421652721339e-05\n",
      "Train Accuracy: 0.9541081786155701\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744669403076173 s\n",
      "Throughout: 2410.257740361272 samples per second\n",
      "Val Loss: 0.2470703125\n",
      "Val Accuracy: 0.9235000014305115\n",
      "\n",
      "\n",
      "Epoch: 267\n",
      "Train Loss: 1.068239450454712\n",
      "CE Loss: 0.09080782532691956, Freq(freq) Loss1: 0.97743159532547\n",
      "Learning Rate: 3.901716631469768e-05\n",
      "Train Accuracy: 0.9568728804588318\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748481063842775 s\n",
      "Throughout: 2409.8149568708536 samples per second\n",
      "Val Loss: 0.2421875\n",
      "Val Accuracy: 0.9248999953269958\n",
      "\n",
      "\n",
      "Epoch: 268\n",
      "Train Loss: 1.1317811012268066\n",
      "CE Loss: 0.1543644666671753, Freq(freq) Loss1: 0.9774166345596313\n",
      "Learning Rate: 3.877017417639548e-05\n",
      "Train Accuracy: 0.9550708532333374\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744688735961915 s\n",
      "Throughout: 2410.2554941363182 samples per second\n",
      "Val Loss: 0.240234375\n",
      "Val Accuracy: 0.9223000407218933\n",
      "\n",
      "\n",
      "Epoch: 269\n",
      "Train Loss: 1.0785068273544312\n",
      "CE Loss: 0.10184699296951294, Freq(freq) Loss1: 0.9766598343849182\n",
      "Learning Rate: 3.8523249785592685e-05\n",
      "Train Accuracy: 0.9564637541770935\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74468161010742 s\n",
      "Throughout: 2410.256322065629 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9208999872207642\n",
      "\n",
      "\n",
      "Epoch: 270\n",
      "Train Loss: 1.1000280380249023\n",
      "CE Loss: 0.12221869826316833, Freq(freq) Loss1: 0.9778093099594116\n",
      "Learning Rate: 3.8276402812921925e-05\n",
      "Train Accuracy: 0.9541047811508179\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744231369018554 s\n",
      "Throughout: 2410.3086352321952 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9248000979423523\n",
      "\n",
      "\n",
      "Epoch: 271\n",
      "Train Loss: 1.1152936220169067\n",
      "CE Loss: 0.13728561997413635, Freq(freq) Loss1: 0.978007972240448\n",
      "Learning Rate: 3.802964292598375e-05\n",
      "Train Accuracy: 0.9551639556884766\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72786051940918 s\n",
      "Throughout: 2412.2122952912064 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9248000383377075\n",
      "\n",
      "\n",
      "Epoch: 272\n",
      "Train Loss: 1.1139230728149414\n",
      "CE Loss: 0.13783618807792664, Freq(freq) Loss1: 0.9760869145393372\n",
      "Learning Rate: 3.778297978896811e-05\n",
      "Train Accuracy: 0.956348180770874\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743566589355467 s\n",
      "Throughout: 2410.3858796229106 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9256999492645264\n",
      "\n",
      "\n",
      "Epoch: 273\n",
      "Train Loss: 1.119000792503357\n",
      "CE Loss: 0.14233985543251038, Freq(freq) Loss1: 0.9766609072685242\n",
      "Learning Rate: 3.7536423062275765e-05\n",
      "Train Accuracy: 0.9567118883132935\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743024963378907 s\n",
      "Throughout: 2410.4488177723965 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9223999381065369\n",
      "\n",
      "\n",
      "Epoch: 274\n",
      "Train Loss: 1.117193341255188\n",
      "CE Loss: 0.1395394504070282, Freq(freq) Loss1: 0.9776539206504822\n",
      "Learning Rate: 3.728998240214002e-05\n",
      "Train Accuracy: 0.9564142227172852\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75115547180176 s\n",
      "Throughout: 2409.5043800304898 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.921999990940094\n",
      "\n",
      "\n",
      "Epoch: 275\n",
      "Train Loss: 1.1099107265472412\n",
      "CE Loss: 0.13294366002082825, Freq(freq) Loss1: 0.9769670963287354\n",
      "Learning Rate: 3.704366746024848e-05\n",
      "Train Accuracy: 0.9557192921638489\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.728930053710936 s\n",
      "Throughout: 2412.087834270486 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.926300048828125\n",
      "\n",
      "\n",
      "Epoch: 276\n",
      "Train Loss: 1.0596747398376465\n",
      "CE Loss: 0.0817461609840393, Freq(freq) Loss1: 0.9779285192489624\n",
      "Learning Rate: 3.679748788336507e-05\n",
      "Train Accuracy: 0.958541989326477\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73062400817871 s\n",
      "Throughout: 2411.8907361531346 samples per second\n",
      "Val Loss: 0.29296875\n",
      "Val Accuracy: 0.9218999743461609\n",
      "\n",
      "\n",
      "Epoch: 277\n",
      "Train Loss: 1.120917797088623\n",
      "CE Loss: 0.14379535615444183, Freq(freq) Loss1: 0.9771224856376648\n",
      "Learning Rate: 3.655145331295227e-05\n",
      "Train Accuracy: 0.9560520648956299\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746403533935545 s\n",
      "Throughout: 2410.056274004958 samples per second\n",
      "Val Loss: 0.33984375\n",
      "Val Accuracy: 0.9232999086380005\n",
      "\n",
      "\n",
      "Epoch: 278\n",
      "Train Loss: 1.058521032333374\n",
      "CE Loss: 0.0817539393901825, Freq(freq) Loss1: 0.9767670631408691\n",
      "Learning Rate: 3.6305573384793454e-05\n",
      "Train Accuracy: 0.9571537971496582\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752947845458984 s\n",
      "Throughout: 2409.296277923266 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9207000136375427\n",
      "\n",
      "\n",
      "Epoch: 279\n",
      "Train Loss: 1.0875180959701538\n",
      "CE Loss: 0.10871494561433792, Freq(freq) Loss1: 0.9788030982017517\n",
      "Learning Rate: 3.605985772861553e-05\n",
      "Train Accuracy: 0.9579747915267944\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74645768737793 s\n",
      "Throughout: 2410.049983155429 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9255000352859497\n",
      "\n",
      "\n",
      "Epoch: 280\n",
      "Train Loss: 1.0888664722442627\n",
      "CE Loss: 0.11163207143545151, Freq(freq) Loss1: 0.977234423160553\n",
      "Learning Rate: 3.58143159677118e-05\n",
      "Train Accuracy: 0.9586153030395508\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74108251953125 s\n",
      "Throughout: 2410.6745611236306 samples per second\n",
      "Val Loss: 0.279296875\n",
      "Val Accuracy: 0.9264999628067017\n",
      "\n",
      "\n",
      "Epoch: 281\n",
      "Train Loss: 1.0888009071350098\n",
      "CE Loss: 0.11173638701438904, Freq(freq) Loss1: 0.9770644903182983\n",
      "Learning Rate: 3.5568957718565093e-05\n",
      "Train Accuracy: 0.959901750087738\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75458776855469 s\n",
      "Throughout: 2409.105907454114 samples per second\n",
      "Val Loss: 0.34765625\n",
      "Val Accuracy: 0.9225999712944031\n",
      "\n",
      "\n",
      "Epoch: 282\n",
      "Train Loss: 1.1270546913146973\n",
      "CE Loss: 0.14961427450180054, Freq(freq) Loss1: 0.977440357208252\n",
      "Learning Rate: 3.532379259047108e-05\n",
      "Train Accuracy: 0.960477888584137\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746337799072265 s\n",
      "Throughout: 2410.063910278946 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9240999817848206\n",
      "\n",
      "\n",
      "Epoch: 283\n",
      "Train Loss: 1.0879559516906738\n",
      "CE Loss: 0.11161564290523529, Freq(freq) Loss1: 0.9763403534889221\n",
      "Learning Rate: 3.507883018516203e-05\n",
      "Train Accuracy: 0.9596890807151794\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743370025634764 s\n",
      "Throughout: 2410.4087203867907 samples per second\n",
      "Val Loss: 0.2490234375\n",
      "Val Accuracy: 0.927299976348877\n",
      "\n",
      "\n",
      "Epoch: 284\n",
      "Train Loss: 1.0836331844329834\n",
      "CE Loss: 0.10706867277622223, Freq(freq) Loss1: 0.9765644669532776\n",
      "Learning Rate: 3.483408009643064e-05\n",
      "Train Accuracy: 0.9592809677124023\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.755261535644532 s\n",
      "Throughout: 2409.0277019218156 samples per second\n",
      "Val Loss: 0.373046875\n",
      "Val Accuracy: 0.9246000647544861\n",
      "\n",
      "\n",
      "Epoch: 285\n",
      "Train Loss: 1.123123049736023\n",
      "CE Loss: 0.14518675208091736, Freq(freq) Loss1: 0.9779362678527832\n",
      "Learning Rate: 3.458955190975441e-05\n",
      "Train Accuracy: 0.958963930606842\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746372665405275 s\n",
      "Throughout: 2410.059859927965 samples per second\n",
      "Val Loss: 0.267578125\n",
      "Val Accuracy: 0.9251000285148621\n",
      "\n",
      "\n",
      "Epoch: 286\n",
      "Train Loss: 1.0960899591445923\n",
      "CE Loss: 0.11908876895904541, Freq(freq) Loss1: 0.9770011901855469\n",
      "Learning Rate: 3.4345255201920195e-05\n",
      "Train Accuracy: 0.9599353671073914\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750798568725585 s\n",
      "Throughout: 2409.545822268119 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9234000444412231\n",
      "\n",
      "\n",
      "Epoch: 287\n",
      "Train Loss: 1.0758897066116333\n",
      "CE Loss: 0.0982978343963623, Freq(freq) Loss1: 0.977591872215271\n",
      "Learning Rate: 3.410119954064909e-05\n",
      "Train Accuracy: 0.9588181376457214\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.754800720214845 s\n",
      "Throughout: 2409.0811891679978 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.923799991607666\n",
      "\n",
      "\n",
      "Epoch: 288\n",
      "Train Loss: 1.1320956945419312\n",
      "CE Loss: 0.155145525932312, Freq(freq) Loss1: 0.9769501686096191\n",
      "Learning Rate: 3.38573944842218e-05\n",
      "Train Accuracy: 0.9594662189483643\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74104975891113 s\n",
      "Throughout: 2410.678368799445 samples per second\n",
      "Val Loss: 0.287109375\n",
      "Val Accuracy: 0.922700047492981\n",
      "\n",
      "\n",
      "Epoch: 289\n",
      "Train Loss: 1.1275060176849365\n",
      "CE Loss: 0.15043187141418457, Freq(freq) Loss1: 0.9770740866661072\n",
      "Learning Rate: 3.361384958110426e-05\n",
      "Train Accuracy: 0.9598124027252197\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.738789245605467 s\n",
      "Throughout: 2410.941131030345 samples per second\n",
      "Val Loss: 0.26953125\n",
      "Val Accuracy: 0.9243000149726868\n",
      "\n",
      "\n",
      "Epoch: 290\n",
      "Train Loss: 1.0895593166351318\n",
      "CE Loss: 0.11214760690927505, Freq(freq) Loss1: 0.9774117469787598\n",
      "Learning Rate: 3.337057436957361e-05\n",
      "Train Accuracy: 0.9609997272491455\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745850509643553 s\n",
      "Throughout: 2410.120519125397 samples per second\n",
      "Val Loss: 0.267578125\n",
      "Val Accuracy: 0.9268999695777893\n",
      "\n",
      "\n",
      "Epoch: 291\n",
      "Train Loss: 1.0858306884765625\n",
      "CE Loss: 0.10958106815814972, Freq(freq) Loss1: 0.9762495756149292\n",
      "Learning Rate: 3.312757837734476e-05\n",
      "Train Accuracy: 0.9592845439910889\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742827758789062 s\n",
      "Throughout: 2410.4717342028844 samples per second\n",
      "Val Loss: 0.29296875\n",
      "Val Accuracy: 0.9261999726295471\n",
      "\n",
      "\n",
      "Epoch: 292\n",
      "Train Loss: 1.1338192224502563\n",
      "CE Loss: 0.15724532306194305, Freq(freq) Loss1: 0.9765739440917969\n",
      "Learning Rate: 3.288487112119716e-05\n",
      "Train Accuracy: 0.960586428642273\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747579208374024 s\n",
      "Throughout: 2409.919706672057 samples per second\n",
      "Val Loss: 0.2578125\n",
      "Val Accuracy: 0.9255000352859497\n",
      "\n",
      "\n",
      "Epoch: 293\n",
      "Train Loss: 1.0855118036270142\n",
      "CE Loss: 0.1083986684679985, Freq(freq) Loss1: 0.9771131277084351\n",
      "Learning Rate: 3.264246210660207e-05\n",
      "Train Accuracy: 0.9616867303848267\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72999459838867 s\n",
      "Throughout: 2411.963966642156 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9221999645233154\n",
      "\n",
      "\n",
      "Epoch: 294\n",
      "Train Loss: 1.0789616107940674\n",
      "CE Loss: 0.10328373312950134, Freq(freq) Loss1: 0.9756778478622437\n",
      "Learning Rate: 3.240036082735038e-05\n",
      "Train Accuracy: 0.9617568850517273\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.739893981933594 s\n",
      "Throughout: 2410.8127092431005 samples per second\n",
      "Val Loss: 0.279296875\n",
      "Val Accuracy: 0.926300048828125\n",
      "\n",
      "\n",
      "Epoch: 295\n",
      "Train Loss: 1.1251550912857056\n",
      "CE Loss: 0.14804580807685852, Freq(freq) Loss1: 0.9771093130111694\n",
      "Learning Rate: 3.215857676518064e-05\n",
      "Train Accuracy: 0.9624261856079102\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744268173217772 s\n",
      "Throughout: 2410.304358895308 samples per second\n",
      "Val Loss: 0.26953125\n",
      "Val Accuracy: 0.9253000020980835\n",
      "\n",
      "\n",
      "Epoch: 296\n",
      "Train Loss: 1.0524271726608276\n",
      "CE Loss: 0.07565868645906448, Freq(freq) Loss1: 0.976768434047699\n",
      "Learning Rate: 3.191711938940787e-05\n",
      "Train Accuracy: 0.9620480537414551\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.723974731445313 s\n",
      "Throughout: 2412.6645900669337 samples per second\n",
      "Val Loss: 0.259765625\n",
      "Val Accuracy: 0.9251000285148621\n",
      "\n",
      "\n",
      "Epoch: 297\n",
      "Train Loss: 1.09718656539917\n",
      "CE Loss: 0.11991161108016968, Freq(freq) Loss1: 0.977275013923645\n",
      "Learning Rate: 3.16759981565526e-05\n",
      "Train Accuracy: 0.9621313214302063\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74771319580078 s\n",
      "Throughout: 2409.904143562179 samples per second\n",
      "Val Loss: 0.259765625\n",
      "Val Accuracy: 0.925599992275238\n",
      "\n",
      "\n",
      "Epoch: 298\n",
      "Train Loss: 1.087623119354248\n",
      "CE Loss: 0.11131850630044937, Freq(freq) Loss1: 0.9763046503067017\n",
      "Learning Rate: 3.1435222509970545e-05\n",
      "Train Accuracy: 0.9611605405807495\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74567057800293 s\n",
      "Throughout: 2410.1414226164397 samples per second\n",
      "Val Loss: 0.279296875\n",
      "Val Accuracy: 0.9233999848365784\n",
      "\n",
      "\n",
      "Epoch: 299\n",
      "Train Loss: 1.0725889205932617\n",
      "CE Loss: 0.09617511928081512, Freq(freq) Loss1: 0.9764137864112854\n",
      "Learning Rate: 3.119480187948276e-05\n",
      "Train Accuracy: 0.9611915946006775\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73860235595703 s\n",
      "Throughout: 2410.962857660358 samples per second\n",
      "Val Loss: 0.265625\n",
      "Val Accuracy: 0.9269999861717224\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "Train Loss: 1.0732479095458984\n",
      "CE Loss: 0.09647507965564728, Freq(freq) Loss1: 0.9767728447914124\n",
      "Learning Rate: 3.095474568100633e-05\n",
      "Train Accuracy: 0.9618780612945557\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743051864624025 s\n",
      "Throughout: 2410.445691709997 samples per second\n",
      "Val Loss: 0.271484375\n",
      "Val Accuracy: 0.9256000518798828\n",
      "\n",
      "\n",
      "Epoch: 301\n",
      "Train Loss: 1.073722243309021\n",
      "CE Loss: 0.0970124825835228, Freq(freq) Loss1: 0.97670978307724\n",
      "Learning Rate: 3.0715063316185594e-05\n",
      "Train Accuracy: 0.9629319906234741\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744287490844727 s\n",
      "Throughout: 2410.302114356397 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9255000352859497\n",
      "\n",
      "\n",
      "Epoch: 302\n",
      "Train Loss: 1.0908957719802856\n",
      "CE Loss: 0.1144239604473114, Freq(freq) Loss1: 0.9764718413352966\n",
      "Learning Rate: 3.047576417202394e-05\n",
      "Train Accuracy: 0.9624417424201965\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72858804321289 s\n",
      "Throughout: 2412.127632415917 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.9288000464439392\n",
      "\n",
      "\n",
      "Epoch: 303\n",
      "Train Loss: 1.0954298973083496\n",
      "CE Loss: 0.11850520223379135, Freq(freq) Loss1: 0.9769247174263\n",
      "Learning Rate: 3.0236857620516182e-05\n",
      "Train Accuracy: 0.9624281525611877\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752506225585936 s\n",
      "Throughout: 2409.3475485073986 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9238001108169556\n",
      "\n",
      "\n",
      "Epoch: 304\n",
      "Train Loss: 1.0815619230270386\n",
      "CE Loss: 0.10484413057565689, Freq(freq) Loss1: 0.9767177700996399\n",
      "Learning Rate: 2.9998353018281463e-05\n",
      "Train Accuracy: 0.9632516503334045\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752703720092775 s\n",
      "Throughout: 2409.324619788697 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9261999726295471\n",
      "\n",
      "\n",
      "Epoch: 305\n",
      "Train Loss: 1.1015602350234985\n",
      "CE Loss: 0.12553457915782928, Freq(freq) Loss1: 0.9760257005691528\n",
      "Learning Rate: 2.9760259706196903e-05\n",
      "Train Accuracy: 0.9635115265846252\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743902435302733 s\n",
      "Throughout: 2410.3468552237387 samples per second\n",
      "Val Loss: 0.283203125\n",
      "Val Accuracy: 0.9266999959945679\n",
      "\n",
      "\n",
      "Epoch: 306\n",
      "Train Loss: 1.0852340459823608\n",
      "CE Loss: 0.10880174487829208, Freq(freq) Loss1: 0.9764323234558105\n",
      "Learning Rate: 2.952258700903165e-05\n",
      "Train Accuracy: 0.9639764428138733\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74631785583496 s\n",
      "Throughout: 2410.066227050376 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.927299976348877\n",
      "\n",
      "\n",
      "Epoch: 307\n",
      "Train Loss: 1.080180287361145\n",
      "CE Loss: 0.10281922668218613, Freq(freq) Loss1: 0.9773610830307007\n",
      "Learning Rate: 2.928534423508178e-05\n",
      "Train Accuracy: 0.9643010497093201\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75358932495117 s\n",
      "Throughout: 2409.221808195226 samples per second\n",
      "Val Loss: 0.26171875\n",
      "Val Accuracy: 0.9267000555992126\n",
      "\n",
      "\n",
      "Epoch: 308\n",
      "Train Loss: 1.0957311391830444\n",
      "CE Loss: 0.117025226354599, Freq(freq) Loss1: 0.9787059426307678\n",
      "Learning Rate: 2.9048540675805716e-05\n",
      "Train Accuracy: 0.964038074016571\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73929426574707 s\n",
      "Throughout: 2410.8824224833816 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.92249995470047\n",
      "\n",
      "\n",
      "Epoch: 309\n",
      "Train Loss: 1.1036560535430908\n",
      "CE Loss: 0.1254538893699646, Freq(freq) Loss1: 0.978202223777771\n",
      "Learning Rate: 2.8812185605460276e-05\n",
      "Train Accuracy: 0.963956892490387\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.69555903625488 s\n",
      "Throughout: 2415.9772592955346 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9242000579833984\n",
      "\n",
      "\n",
      "Epoch: 310\n",
      "Train Loss: 1.0797864198684692\n",
      "CE Loss: 0.10263504087924957, Freq(freq) Loss1: 0.9771513938903809\n",
      "Learning Rate: 2.857628828073755e-05\n",
      "Train Accuracy: 0.9644790887832642\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743791458129884 s\n",
      "Throughout: 2410.359750334072 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9246999025344849\n",
      "\n",
      "\n",
      "Epoch: 311\n",
      "Train Loss: 1.109774112701416\n",
      "CE Loss: 0.13280975818634033, Freq(freq) Loss1: 0.9769643545150757\n",
      "Learning Rate: 2.8340857940402315e-05\n",
      "Train Accuracy: 0.9657530784606934\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.720846984863282 s\n",
      "Throughout: 2413.0287741869497 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9271000623703003\n",
      "\n",
      "\n",
      "Epoch: 312\n",
      "Train Loss: 1.0670521259307861\n",
      "CE Loss: 0.0906439870595932, Freq(freq) Loss1: 0.9764081239700317\n",
      "Learning Rate: 2.810590380493017e-05\n",
      "Train Accuracy: 0.9633967876434326\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.749763931274416 s\n",
      "Throughout: 2409.665968519242 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9270000457763672\n",
      "\n",
      "\n",
      "Epoch: 313\n",
      "Train Loss: 1.100885033607483\n",
      "CE Loss: 0.1244184672832489, Freq(freq) Loss1: 0.9764665961265564\n",
      "Learning Rate: 2.787143507614651e-05\n",
      "Train Accuracy: 0.9637928009033203\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75410153198242 s\n",
      "Throughout: 2409.1623490879215 samples per second\n",
      "Val Loss: 0.287109375\n",
      "Val Accuracy: 0.9276999831199646\n",
      "\n",
      "\n",
      "Epoch: 314\n",
      "Train Loss: 1.0656359195709229\n",
      "CE Loss: 0.08920742571353912, Freq(freq) Loss1: 0.9764285087585449\n",
      "Learning Rate: 2.763746093686605e-05\n",
      "Train Accuracy: 0.9648987650871277\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.763633209228516 s\n",
      "Throughout: 2408.0564078630136 samples per second\n",
      "Val Loss: 0.275390625\n",
      "Val Accuracy: 0.928100049495697\n",
      "\n",
      "\n",
      "Epoch: 315\n",
      "Train Loss: 1.0824518203735352\n",
      "CE Loss: 0.10559572279453278, Freq(freq) Loss1: 0.9768560528755188\n",
      "Learning Rate: 2.7403990550533262e-05\n",
      "Train Accuracy: 0.9656100869178772\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743527572631837 s\n",
      "Throughout: 2410.39041334358 samples per second\n",
      "Val Loss: 0.251953125\n",
      "Val Accuracy: 0.924299955368042\n",
      "\n",
      "\n",
      "Epoch: 316\n",
      "Train Loss: 1.072908639907837\n",
      "CE Loss: 0.09685812890529633, Freq(freq) Loss1: 0.9760504961013794\n",
      "Learning Rate: 2.717103306086347e-05\n",
      "Train Accuracy: 0.9657124876976013\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744602462768555 s\n",
      "Throughout: 2410.2655179696826 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9254999756813049\n",
      "\n",
      "\n",
      "Epoch: 317\n",
      "Train Loss: 1.0769627094268799\n",
      "CE Loss: 0.10018311440944672, Freq(freq) Loss1: 0.976779580116272\n",
      "Learning Rate: 2.693859759148469e-05\n",
      "Train Accuracy: 0.9652444124221802\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741974975585936 s\n",
      "Throughout: 2410.5708380639658 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9247000217437744\n",
      "\n",
      "\n",
      "Epoch: 318\n",
      "Train Loss: 1.1046488285064697\n",
      "CE Loss: 0.1280650496482849, Freq(freq) Loss1: 0.9765838384628296\n",
      "Learning Rate: 2.6706693245580395e-05\n",
      "Train Accuracy: 0.9663516283035278\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.739478057861326 s\n",
      "Throughout: 2410.861057375908 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9265000820159912\n",
      "\n",
      "\n",
      "Epoch: 319\n",
      "Train Loss: 1.0699846744537354\n",
      "CE Loss: 0.09258216619491577, Freq(freq) Loss1: 0.9774025082588196\n",
      "Learning Rate: 2.647532910553295e-05\n",
      "Train Accuracy: 0.9652759432792664\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747531692504882 s\n",
      "Throughout: 2409.9252258553083 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9301999807357788\n",
      "\n",
      "\n",
      "Epoch: 320\n",
      "Train Loss: 1.1055655479431152\n",
      "CE Loss: 0.12941128015518188, Freq(freq) Loss1: 0.9761543273925781\n",
      "Learning Rate: 2.624451423256788e-05\n",
      "Train Accuracy: 0.9665863513946533\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748379241943358 s\n",
      "Throughout: 2409.826782948124 samples per second\n",
      "Val Loss: 0.29296875\n",
      "Val Accuracy: 0.9256999492645264\n",
      "\n",
      "\n",
      "Epoch: 321\n",
      "Train Loss: 1.0814396142959595\n",
      "CE Loss: 0.10422587394714355, Freq(freq) Loss1: 0.9772137403488159\n",
      "Learning Rate: 2.6014257666399046e-05\n",
      "Train Accuracy: 0.9678243398666382\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747064300537108 s\n",
      "Throughout: 2409.9795168951 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9255999326705933\n",
      "\n",
      "\n",
      "Epoch: 322\n",
      "Train Loss: 1.0864062309265137\n",
      "CE Loss: 0.10989561676979065, Freq(freq) Loss1: 0.9765105843544006\n",
      "Learning Rate: 2.5784568424874602e-05\n",
      "Train Accuracy: 0.9665724635124207\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743618927001954 s\n",
      "Throughout: 2410.3797980455106 samples per second\n",
      "Val Loss: 0.263671875\n",
      "Val Accuracy: 0.925399899482727\n",
      "\n",
      "\n",
      "Epoch: 323\n",
      "Train Loss: 1.0831873416900635\n",
      "CE Loss: 0.10572651773691177, Freq(freq) Loss1: 0.9774608612060547\n",
      "Learning Rate: 2.555545550362376e-05\n",
      "Train Accuracy: 0.9653712511062622\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72420265197754 s\n",
      "Throughout: 2412.638056076378 samples per second\n",
      "Val Loss: 0.255859375\n",
      "Val Accuracy: 0.92930006980896\n",
      "\n",
      "\n",
      "Epoch: 324\n",
      "Train Loss: 1.0540735721588135\n",
      "CE Loss: 0.07710802555084229, Freq(freq) Loss1: 0.9769654870033264\n",
      "Learning Rate: 2.5326927875704582e-05\n",
      "Train Accuracy: 0.967502236366272\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.749903472900392 s\n",
      "Throughout: 2409.64976368688 samples per second\n",
      "Val Loss: 0.25\n",
      "Val Accuracy: 0.925800085067749\n",
      "\n",
      "\n",
      "Epoch: 325\n",
      "Train Loss: 1.0637520551681519\n",
      "CE Loss: 0.08667656034231186, Freq(freq) Loss1: 0.9770755171775818\n",
      "Learning Rate: 2.5098994491252426e-05\n",
      "Train Accuracy: 0.9661885499954224\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747892196655272 s\n",
      "Throughout: 2409.8833522983314 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9260000586509705\n",
      "\n",
      "\n",
      "Epoch: 326\n",
      "Train Loss: 1.0814346075057983\n",
      "CE Loss: 0.10500091314315796, Freq(freq) Loss1: 0.9764336943626404\n",
      "Learning Rate: 2.487166427712957e-05\n",
      "Train Accuracy: 0.9669522643089294\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.731450271606445 s\n",
      "Throughout: 2411.7946089125962 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9258000254631042\n",
      "\n",
      "\n",
      "Epoch: 327\n",
      "Train Loss: 1.0753883123397827\n",
      "CE Loss: 0.09826648235321045, Freq(freq) Loss1: 0.9771218299865723\n",
      "Learning Rate: 2.4644946136575478e-05\n",
      "Train Accuracy: 0.9684487581253052\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742632339477538 s\n",
      "Throughout: 2410.494443602494 samples per second\n",
      "Val Loss: 0.369140625\n",
      "Val Accuracy: 0.9250999689102173\n",
      "\n",
      "\n",
      "Epoch: 328\n",
      "Train Loss: 1.0859159231185913\n",
      "CE Loss: 0.10914085805416107, Freq(freq) Loss1: 0.976775050163269\n",
      "Learning Rate: 2.4418848948858134e-05\n",
      "Train Accuracy: 0.9679050445556641\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746133682250978 s\n",
      "Throughout: 2410.087622388007 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9273999333381653\n",
      "\n",
      "\n",
      "Epoch: 329\n",
      "Train Loss: 1.0597939491271973\n",
      "CE Loss: 0.0828060582280159, Freq(freq) Loss1: 0.9769878387451172\n",
      "Learning Rate: 2.419338156892636e-05\n",
      "Train Accuracy: 0.9671808481216431\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.704905380249023 s\n",
      "Throughout: 2414.886669692119 samples per second\n",
      "Val Loss: 0.2890625\n",
      "Val Accuracy: 0.927299976348877\n",
      "\n",
      "\n",
      "Epoch: 330\n",
      "Train Loss: 1.049813151359558\n",
      "CE Loss: 0.07273359596729279, Freq(freq) Loss1: 0.9770795702934265\n",
      "Learning Rate: 2.3968552827062924e-05\n",
      "Train Accuracy: 0.9662585258483887\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.726675277709962 s\n",
      "Throughout: 2412.3502361119818 samples per second\n",
      "Val Loss: 0.34765625\n",
      "Val Accuracy: 0.9258999824523926\n",
      "\n",
      "\n",
      "Epoch: 331\n",
      "Train Loss: 1.0507651567459106\n",
      "CE Loss: 0.07447300851345062, Freq(freq) Loss1: 0.9762921929359436\n",
      "Learning Rate: 2.374437152853878e-05\n",
      "Train Accuracy: 0.9669955372810364\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744712509155274 s\n",
      "Throughout: 2410.2527320122404 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9269000291824341\n",
      "\n",
      "\n",
      "Epoch: 332\n",
      "Train Loss: 1.081375002861023\n",
      "CE Loss: 0.1044670045375824, Freq(freq) Loss1: 0.9769079685211182\n",
      "Learning Rate: 2.3520846453268156e-05\n",
      "Train Accuracy: 0.9686644673347473\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746367111206055 s\n",
      "Throughout: 2410.0605051470784 samples per second\n",
      "Val Loss: 0.2890625\n",
      "Val Accuracy: 0.9259000420570374\n",
      "\n",
      "\n",
      "Epoch: 333\n",
      "Train Loss: 1.0443098545074463\n",
      "CE Loss: 0.06622475385665894, Freq(freq) Loss1: 0.9780851006507874\n",
      "Learning Rate: 2.3297986355464743e-05\n",
      "Train Accuracy: 0.9687145352363586\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747308532714843 s\n",
      "Throughout: 2409.9511472130866 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.925000011920929\n",
      "\n",
      "\n",
      "Epoch: 334\n",
      "Train Loss: 1.035545825958252\n",
      "CE Loss: 0.056979723274707794, Freq(freq) Loss1: 0.97856605052948\n",
      "Learning Rate: 2.307579996329883e-05\n",
      "Train Accuracy: 0.9674561619758606\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753560272216795 s\n",
      "Throughout: 2409.225180844561 samples per second\n",
      "Val Loss: 0.232421875\n",
      "Val Accuracy: 0.9294999837875366\n",
      "\n",
      "\n",
      "Epoch: 335\n",
      "Train Loss: 1.0837074518203735\n",
      "CE Loss: 0.10730206221342087, Freq(freq) Loss1: 0.9764054417610168\n",
      "Learning Rate: 2.2854295978555455e-05\n",
      "Train Accuracy: 0.9677802324295044\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.689847763061522 s\n",
      "Throughout: 2416.6441712184637 samples per second\n",
      "Val Loss: 0.271484375\n",
      "Val Accuracy: 0.9240000247955322\n",
      "\n",
      "\n",
      "Epoch: 336\n",
      "Train Loss: 1.09469735622406\n",
      "CE Loss: 0.1177891343832016, Freq(freq) Loss1: 0.9769082069396973\n",
      "Learning Rate: 2.263348307629361e-05\n",
      "Train Accuracy: 0.9672410488128662\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745567398071287 s\n",
      "Throughout: 2410.153409669985 samples per second\n",
      "Val Loss: 0.244140625\n",
      "Val Accuracy: 0.9270000457763672\n",
      "\n",
      "\n",
      "Epoch: 337\n",
      "Train Loss: 1.0690958499908447\n",
      "CE Loss: 0.09293261170387268, Freq(freq) Loss1: 0.9761632084846497\n",
      "Learning Rate: 2.2413369904506504e-05\n",
      "Train Accuracy: 0.968485414981842\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.728415420532226 s\n",
      "Throughout: 2412.147720200225 samples per second\n",
      "Val Loss: 0.2412109375\n",
      "Val Accuracy: 0.9264000058174133\n",
      "\n",
      "\n",
      "Epoch: 338\n",
      "Train Loss: 1.043099284172058\n",
      "CE Loss: 0.06628440320491791, Freq(freq) Loss1: 0.9768149256706238\n",
      "Learning Rate: 2.2193965083782867e-05\n",
      "Train Accuracy: 0.9707240462303162\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746257568359376 s\n",
      "Throughout: 2410.073230569364 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9243999719619751\n",
      "\n",
      "\n",
      "Epoch: 339\n",
      "Train Loss: 1.055667757987976\n",
      "CE Loss: 0.07829400151968002, Freq(freq) Loss1: 0.9773737192153931\n",
      "Learning Rate: 2.197527720696927e-05\n",
      "Train Accuracy: 0.9691560864448547\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75220248413086 s\n",
      "Throughout: 2409.3828131368145 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9250000715255737\n",
      "\n",
      "\n",
      "Epoch: 340\n",
      "Train Loss: 1.0631892681121826\n",
      "CE Loss: 0.08710178732872009, Freq(freq) Loss1: 0.9760874509811401\n",
      "Learning Rate: 2.175731483883373e-05\n",
      "Train Accuracy: 0.9704793691635132\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746450698852538 s\n",
      "Throughout: 2410.0507949904627 samples per second\n",
      "Val Loss: 0.279296875\n",
      "Val Accuracy: 0.9253000020980835\n",
      "\n",
      "\n",
      "Epoch: 341\n",
      "Train Loss: 1.0492744445800781\n",
      "CE Loss: 0.07106466591358185, Freq(freq) Loss1: 0.9782097935676575\n",
      "Learning Rate: 2.1540086515730107e-05\n",
      "Train Accuracy: 0.968002438545227\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751433776855468 s\n",
      "Throughout: 2409.4720652876576 samples per second\n",
      "Val Loss: 0.294921875\n",
      "Val Accuracy: 0.9262000322341919\n",
      "\n",
      "\n",
      "Epoch: 342\n",
      "Train Loss: 1.0512300729751587\n",
      "CE Loss: 0.07395406812429428, Freq(freq) Loss1: 0.9772759675979614\n",
      "Learning Rate: 2.1323600745263907e-05\n",
      "Train Accuracy: 0.9680461883544922\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74796226501465 s\n",
      "Throughout: 2409.8752138329423 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.926300048828125\n",
      "\n",
      "\n",
      "Epoch: 343\n",
      "Train Loss: 1.0663988590240479\n",
      "CE Loss: 0.08924971520900726, Freq(freq) Loss1: 0.9771491289138794\n",
      "Learning Rate: 2.1107866005959048e-05\n",
      "Train Accuracy: 0.9695068001747131\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743685745239258 s\n",
      "Throughout: 2410.3720338838607 samples per second\n",
      "Val Loss: 0.265625\n",
      "Val Accuracy: 0.9265999794006348\n",
      "\n",
      "\n",
      "Epoch: 344\n",
      "Train Loss: 1.0710017681121826\n",
      "CE Loss: 0.09445017576217651, Freq(freq) Loss1: 0.9765516519546509\n",
      "Learning Rate: 2.08928907469258e-05\n",
      "Train Accuracy: 0.9695571660995483\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746330902099608 s\n",
      "Throughout: 2410.0647114878425 samples per second\n",
      "Val Loss: 0.283203125\n",
      "Val Accuracy: 0.9266999959945679\n",
      "\n",
      "\n",
      "Epoch: 345\n",
      "Train Loss: 1.0772461891174316\n",
      "CE Loss: 0.10033130645751953, Freq(freq) Loss1: 0.9769148230552673\n",
      "Learning Rate: 2.0678683387529878e-05\n",
      "Train Accuracy: 0.9699218273162842\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74333186340332 s\n",
      "Throughout: 2410.413154899822 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9280999898910522\n",
      "\n",
      "\n",
      "Epoch: 346\n",
      "Train Loss: 1.046164631843567\n",
      "CE Loss: 0.06952884048223495, Freq(freq) Loss1: 0.976635754108429\n",
      "Learning Rate: 2.046525231706268e-05\n",
      "Train Accuracy: 0.9699925780296326\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74343588256836 s\n",
      "Throughout: 2410.4010677429405 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9264000058174133\n",
      "\n",
      "\n",
      "Epoch: 347\n",
      "Train Loss: 1.0619111061096191\n",
      "CE Loss: 0.08473537117242813, Freq(freq) Loss1: 0.9771757125854492\n",
      "Learning Rate: 2.025260589441284e-05\n",
      "Train Accuracy: 0.9698939323425293\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.738937103271486 s\n",
      "Throughout: 2410.9239422936816 samples per second\n",
      "Val Loss: 0.25\n",
      "Val Accuracy: 0.9284000396728516\n",
      "\n",
      "\n",
      "Epoch: 348\n",
      "Train Loss: 1.0601214170455933\n",
      "CE Loss: 0.082713782787323, Freq(freq) Loss1: 0.9774076342582703\n",
      "Learning Rate: 2.0040752447738673e-05\n",
      "Train Accuracy: 0.9704028964042664\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.727201919555664 s\n",
      "Throughout: 2412.288942523693 samples per second\n",
      "Val Loss: 0.2734375\n",
      "Val Accuracy: 0.9273000359535217\n",
      "\n",
      "\n",
      "Epoch: 349\n",
      "Train Loss: 1.0652079582214355\n",
      "CE Loss: 0.08840683102607727, Freq(freq) Loss1: 0.9768010973930359\n",
      "Learning Rate: 1.9829700274142163e-05\n",
      "Train Accuracy: 0.9701440334320068\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.69128535461426 s\n",
      "Throughout: 2416.4762673310556 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9282999634742737\n",
      "\n",
      "\n",
      "Epoch: 350\n",
      "Train Loss: 1.0844953060150146\n",
      "CE Loss: 0.10791183263063431, Freq(freq) Loss1: 0.9765834212303162\n",
      "Learning Rate: 1.961945763934395e-05\n",
      "Train Accuracy: 0.9698992967605591\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747207962036132 s\n",
      "Throughout: 2409.9628292872712 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9267999529838562\n",
      "\n",
      "\n",
      "Epoch: 351\n",
      "Train Loss: 1.0632994174957275\n",
      "CE Loss: 0.0871509537100792, Freq(freq) Loss1: 0.9761484861373901\n",
      "Learning Rate: 1.9410032777359632e-05\n",
      "Train Accuracy: 0.9702801704406738\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748437561035157 s\n",
      "Throughout: 2409.8200094786057 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9289000034332275\n",
      "\n",
      "\n",
      "Epoch: 352\n",
      "Train Loss: 1.1034942865371704\n",
      "CE Loss: 0.125278502702713, Freq(freq) Loss1: 0.9782158136367798\n",
      "Learning Rate: 1.920143389017719e-05\n",
      "Train Accuracy: 0.9689675569534302\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744053451538086 s\n",
      "Throughout: 2410.329307953683 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9271999597549438\n",
      "\n",
      "\n",
      "Epoch: 353\n",
      "Train Loss: 1.076962947845459\n",
      "CE Loss: 0.10035649687051773, Freq(freq) Loss1: 0.9766064882278442\n",
      "Learning Rate: 1.8993669147435947e-05\n",
      "Train Accuracy: 0.9699028134346008\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751276473999024 s\n",
      "Throughout: 2409.4903300357983 samples per second\n",
      "Val Loss: 0.37890625\n",
      "Val Accuracy: 0.9264999628067017\n",
      "\n",
      "\n",
      "Epoch: 354\n",
      "Train Loss: 1.113831639289856\n",
      "CE Loss: 0.1380188763141632, Freq(freq) Loss1: 0.9758127331733704\n",
      "Learning Rate: 1.878674668610646e-05\n",
      "Train Accuracy: 0.9711416959762573\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75648387145996 s\n",
      "Throughout: 2408.8858358495727 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.9280999898910522\n",
      "\n",
      "\n",
      "Epoch: 355\n",
      "Train Loss: 1.0598478317260742\n",
      "CE Loss: 0.0831981897354126, Freq(freq) Loss1: 0.9766497015953064\n",
      "Learning Rate: 1.8580674610171834e-05\n",
      "Train Accuracy: 0.970442533493042\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744081314086912 s\n",
      "Throughout: 2410.3260705040693 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.927600085735321\n",
      "\n",
      "\n",
      "Epoch: 356\n",
      "Train Loss: 1.0167382955551147\n",
      "CE Loss: 0.040422502905130386, Freq(freq) Loss1: 0.9763157367706299\n",
      "Learning Rate: 1.8375460990310482e-05\n",
      "Train Accuracy: 0.9706211686134338\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.727118057250976 s\n",
      "Throughout: 2412.2987026895657 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9285000562667847\n",
      "\n",
      "\n",
      "Epoch: 357\n",
      "Train Loss: 1.076427698135376\n",
      "CE Loss: 0.09809452295303345, Freq(freq) Loss1: 0.9783332347869873\n",
      "Learning Rate: 1.8171113863579856e-05\n",
      "Train Accuracy: 0.9693773984909058\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744505249023437 s\n",
      "Throughout: 2410.2768130540876 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9297000765800476\n",
      "\n",
      "\n",
      "Epoch: 358\n",
      "Train Loss: 1.0419820547103882\n",
      "CE Loss: 0.06585393846035004, Freq(freq) Loss1: 0.9761281609535217\n",
      "Learning Rate: 1.7967641233101823e-05\n",
      "Train Accuracy: 0.9718530178070068\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.755173416137694 s\n",
      "Throughout: 2409.0379298456587 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9276000261306763\n",
      "\n",
      "\n",
      "Epoch: 359\n",
      "Train Loss: 1.0728211402893066\n",
      "CE Loss: 0.09633594751358032, Freq(freq) Loss1: 0.9764851331710815\n",
      "Learning Rate: 1.7765051067749157e-05\n",
      "Train Accuracy: 0.9703463912010193\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.694797729492187 s\n",
      "Throughout: 2416.0661366960317 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9305000305175781\n",
      "\n",
      "\n",
      "Epoch: 360\n",
      "Train Loss: 1.0803090333938599\n",
      "CE Loss: 0.10261526703834534, Freq(freq) Loss1: 0.9776937961578369\n",
      "Learning Rate: 1.7563351301833473e-05\n",
      "Train Accuracy: 0.9716290235519409\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751377548217775 s\n",
      "Throughout: 2409.4785940750344 samples per second\n",
      "Val Loss: 0.365234375\n",
      "Val Accuracy: 0.9263999462127686\n",
      "\n",
      "\n",
      "Epoch: 361\n",
      "Train Loss: 1.0521912574768066\n",
      "CE Loss: 0.07315689325332642, Freq(freq) Loss1: 0.9790343642234802\n",
      "Learning Rate: 1.736254983479443e-05\n",
      "Train Accuracy: 0.9716488718986511\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.754004486083986 s\n",
      "Throughout: 2409.173614351201 samples per second\n",
      "Val Loss: 0.41015625\n",
      "Val Accuracy: 0.9244999885559082\n",
      "\n",
      "\n",
      "Epoch: 362\n",
      "Train Loss: 1.070176362991333\n",
      "CE Loss: 0.09268974512815475, Freq(freq) Loss1: 0.9774866104125977\n",
      "Learning Rate: 1.7162654530890478e-05\n",
      "Train Accuracy: 0.9720290899276733\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75903530883789 s\n",
      "Throughout: 2408.5897661493523 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9287000298500061\n",
      "\n",
      "\n",
      "Epoch: 363\n",
      "Train Loss: 1.0365737676620483\n",
      "CE Loss: 0.05912153050303459, Freq(freq) Loss1: 0.9774522185325623\n",
      "Learning Rate: 1.6963673218890703e-05\n",
      "Train Accuracy: 0.9712612628936768\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74303775024414 s\n",
      "Throughout: 2410.447331872185 samples per second\n",
      "Val Loss: 0.34765625\n",
      "Val Accuracy: 0.9287999868392944\n",
      "\n",
      "\n",
      "Epoch: 364\n",
      "Train Loss: 1.050871729850769\n",
      "CE Loss: 0.07451271265745163, Freq(freq) Loss1: 0.9763590097427368\n",
      "Learning Rate: 1.6765613691768325e-05\n",
      "Train Accuracy: 0.9719697833061218\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74609484863281 s\n",
      "Throughout: 2410.0921337152304 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9286000728607178\n",
      "\n",
      "\n",
      "Epoch: 365\n",
      "Train Loss: 1.0764782428741455\n",
      "CE Loss: 0.09981276839971542, Freq(freq) Loss1: 0.9766654372215271\n",
      "Learning Rate: 1.6568483706395472e-05\n",
      "Train Accuracy: 0.9715555310249329\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.755484024047853 s\n",
      "Throughout: 2409.0018783502555 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9268999695777893\n",
      "\n",
      "\n",
      "Epoch: 366\n",
      "Train Loss: 1.050969123840332\n",
      "CE Loss: 0.07453393936157227, Freq(freq) Loss1: 0.9764352440834045\n",
      "Learning Rate: 1.6372290983239354e-05\n",
      "Train Accuracy: 0.9730976819992065\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72971614074707 s\n",
      "Throughout: 2411.996366014787 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.927299976348877\n",
      "\n",
      "\n",
      "Epoch: 367\n",
      "Train Loss: 1.054986834526062\n",
      "CE Loss: 0.07843227684497833, Freq(freq) Loss1: 0.9765545725822449\n",
      "Learning Rate: 1.6177043206059947e-05\n",
      "Train Accuracy: 0.9727550148963928\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744088104248046 s\n",
      "Throughout: 2410.325281532179 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.9285999536514282\n",
      "\n",
      "\n",
      "Epoch: 368\n",
      "Train Loss: 1.0643049478530884\n",
      "CE Loss: 0.0873701348900795, Freq(freq) Loss1: 0.9769347906112671\n",
      "Learning Rate: 1.5982748021608976e-05\n",
      "Train Accuracy: 0.973643958568573\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.722645858764647 s\n",
      "Throughout: 2412.8193060275885 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.927899956703186\n",
      "\n",
      "\n",
      "Epoch: 369\n",
      "Train Loss: 1.051505446434021\n",
      "CE Loss: 0.07427181303501129, Freq(freq) Loss1: 0.9772336483001709\n",
      "Learning Rate: 1.5789413039330583e-05\n",
      "Train Accuracy: 0.9737457036972046\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753421112060547 s\n",
      "Throughout: 2409.2413356823968 samples per second\n",
      "Val Loss: 0.38671875\n",
      "Val Accuracy: 0.9265000820159912\n",
      "\n",
      "\n",
      "Epoch: 370\n",
      "Train Loss: 1.0642648935317993\n",
      "CE Loss: 0.08783033490180969, Freq(freq) Loss1: 0.976434588432312\n",
      "Learning Rate: 1.5597045831063137e-05\n",
      "Train Accuracy: 0.9716292023658752\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743610443115234 s\n",
      "Throughout: 2410.380783861804 samples per second\n",
      "Val Loss: 0.369140625\n",
      "Val Accuracy: 0.9289999008178711\n",
      "\n",
      "\n",
      "Epoch: 371\n",
      "Train Loss: 1.0763213634490967\n",
      "CE Loss: 0.09987591207027435, Freq(freq) Loss1: 0.9764454960823059\n",
      "Learning Rate: 1.5405653930742807e-05\n",
      "Train Accuracy: 0.9728653430938721\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747127532958984 s\n",
      "Throughout: 2409.9721718377527 samples per second\n",
      "Val Loss: 0.38671875\n",
      "Val Accuracy: 0.9273000359535217\n",
      "\n",
      "\n",
      "Epoch: 372\n",
      "Train Loss: 1.0405470132827759\n",
      "CE Loss: 0.06270070374011993, Freq(freq) Loss1: 0.9778463244438171\n",
      "Learning Rate: 1.5215244834108461e-05\n",
      "Train Accuracy: 0.9739850163459778\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.758329513549803 s\n",
      "Throughout: 2408.671659603581 samples per second\n",
      "Val Loss: 0.369140625\n",
      "Val Accuracy: 0.927299976348877\n",
      "\n",
      "\n",
      "Epoch: 373\n",
      "Train Loss: 1.0462703704833984\n",
      "CE Loss: 0.06817933917045593, Freq(freq) Loss1: 0.9780910015106201\n",
      "Learning Rate: 1.5025825998408094e-05\n",
      "Train Accuracy: 0.9740447402000427\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743766677856446 s\n",
      "Throughout: 2410.362629723077 samples per second\n",
      "Val Loss: 0.33984375\n",
      "Val Accuracy: 0.9275999665260315\n",
      "\n",
      "\n",
      "Epoch: 374\n",
      "Train Loss: 1.0572936534881592\n",
      "CE Loss: 0.07635219395160675, Freq(freq) Loss1: 0.9809414148330688\n",
      "Learning Rate: 1.4837404842106787e-05\n",
      "Train Accuracy: 0.9733623266220093\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743963806152344 s\n",
      "Throughout: 2410.3397242320084 samples per second\n",
      "Val Loss: 0.287109375\n",
      "Val Accuracy: 0.9282000064849854\n",
      "\n",
      "\n",
      "Epoch: 375\n",
      "Train Loss: 1.0588146448135376\n",
      "CE Loss: 0.08185859769582748, Freq(freq) Loss1: 0.9769560098648071\n",
      "Learning Rate: 1.4649988744596153e-05\n",
      "Train Accuracy: 0.9733961820602417\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745028533935546 s\n",
      "Throughout: 2410.216014801233 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9282000660896301\n",
      "\n",
      "\n",
      "Epoch: 376\n",
      "Train Loss: 1.0641963481903076\n",
      "CE Loss: 0.08815225958824158, Freq(freq) Loss1: 0.9760440587997437\n",
      "Learning Rate: 1.4463585045905346e-05\n",
      "Train Accuracy: 0.9725571870803833\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74594694519043 s\n",
      "Throughout: 2410.109315911058 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9277999401092529\n",
      "\n",
      "\n",
      "Epoch: 377\n",
      "Train Loss: 1.0714259147644043\n",
      "CE Loss: 0.0944807231426239, Freq(freq) Loss1: 0.9769452214241028\n",
      "Learning Rate: 1.4278201046413527e-05\n",
      "Train Accuracy: 0.9727356433868408\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747036178588868 s\n",
      "Throughout: 2409.982783545751 samples per second\n",
      "Val Loss: 0.3515625\n",
      "Val Accuracy: 0.9288999438285828\n",
      "\n",
      "\n",
      "Epoch: 378\n",
      "Train Loss: 1.0793936252593994\n",
      "CE Loss: 0.10134971141815186, Freq(freq) Loss1: 0.9780438542366028\n",
      "Learning Rate: 1.4093844006564103e-05\n",
      "Train Accuracy: 0.9726145267486572\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.749465499877928 s\n",
      "Throughout: 2409.7006257965613 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9275000095367432\n",
      "\n",
      "\n",
      "Epoch: 379\n",
      "Train Loss: 1.0397409200668335\n",
      "CE Loss: 0.06341106444597244, Freq(freq) Loss1: 0.9763298630714417\n",
      "Learning Rate: 1.3910521146580174e-05\n",
      "Train Accuracy: 0.9738420248031616\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744215301513673 s\n",
      "Throughout: 2410.310502145221 samples per second\n",
      "Val Loss: 0.3515625\n",
      "Val Accuracy: 0.9297999739646912\n",
      "\n",
      "\n",
      "Epoch: 380\n",
      "Train Loss: 1.0574774742126465\n",
      "CE Loss: 0.07904317229986191, Freq(freq) Loss1: 0.9784343242645264\n",
      "Learning Rate: 1.372823964618192e-05\n",
      "Train Accuracy: 0.9739848971366882\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75359860229492 s\n",
      "Throughout: 2409.220731216755 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9282000064849854\n",
      "\n",
      "\n",
      "Epoch: 381\n",
      "Train Loss: 1.0553970336914062\n",
      "CE Loss: 0.07830346375703812, Freq(freq) Loss1: 0.977093517780304\n",
      "Learning Rate: 1.3547006644305341e-05\n",
      "Train Accuracy: 0.9738829135894775\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753729446411132 s\n",
      "Throughout: 2409.205542025909 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9286999702453613\n",
      "\n",
      "\n",
      "Epoch: 382\n",
      "Train Loss: 1.0458128452301025\n",
      "CE Loss: 0.06933427602052689, Freq(freq) Loss1: 0.9764785766601562\n",
      "Learning Rate: 1.3366829238822686e-05\n",
      "Train Accuracy: 0.9754159450531006\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7429909362793 s\n",
      "Throughout: 2410.4527719071825 samples per second\n",
      "Val Loss: 0.275390625\n",
      "Val Accuracy: 0.9280000329017639\n",
      "\n",
      "\n",
      "Epoch: 383\n",
      "Train Loss: 1.0349454879760742\n",
      "CE Loss: 0.05756279453635216, Freq(freq) Loss1: 0.9773826599121094\n",
      "Learning Rate: 1.3187714486264421e-05\n",
      "Train Accuracy: 0.9751176834106445\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.704966247558595 s\n",
      "Throughout: 2414.879570542439 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9298999905586243\n",
      "\n",
      "\n",
      "Epoch: 384\n",
      "Train Loss: 1.0839287042617798\n",
      "CE Loss: 0.10620924830436707, Freq(freq) Loss1: 0.9777194857597351\n",
      "Learning Rate: 1.300966940154293e-05\n",
      "Train Accuracy: 0.973484456539154\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751555725097656 s\n",
      "Throughout: 2409.4579058247787 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.9294999837875366\n",
      "\n",
      "\n",
      "Epoch: 385\n",
      "Train Loss: 1.0543209314346313\n",
      "CE Loss: 0.07618101686239243, Freq(freq) Loss1: 0.9781399369239807\n",
      "Learning Rate: 1.2832700957677793e-05\n",
      "Train Accuracy: 0.9743649959564209\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744449462890625 s\n",
      "Throughout: 2410.2832947890042 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9273000955581665\n",
      "\n",
      "\n",
      "Epoch: 386\n",
      "Train Loss: 1.08412766456604\n",
      "CE Loss: 0.10696947574615479, Freq(freq) Loss1: 0.97715824842453\n",
      "Learning Rate: 1.2656816085522582e-05\n",
      "Train Accuracy: 0.9746303558349609\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750443130493164 s\n",
      "Throughout: 2409.587095830453 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.9277999401092529\n",
      "\n",
      "\n",
      "Epoch: 387\n",
      "Train Loss: 1.0248701572418213\n",
      "CE Loss: 0.04819969832897186, Freq(freq) Loss1: 0.9766704440116882\n",
      "Learning Rate: 1.248202167349353e-05\n",
      "Train Accuracy: 0.9744088053703308\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743202133178713 s\n",
      "Throughout: 2410.4282298838084 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9266000390052795\n",
      "\n",
      "\n",
      "Epoch: 388\n",
      "Train Loss: 1.0784063339233398\n",
      "CE Loss: 0.10179448127746582, Freq(freq) Loss1: 0.9766117930412292\n",
      "Learning Rate: 1.230832456729971e-05\n",
      "Train Accuracy: 0.9752329587936401\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74524540710449 s\n",
      "Throughout: 2410.190818127262 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9276000261306763\n",
      "\n",
      "\n",
      "Epoch: 389\n",
      "Train Loss: 1.039307951927185\n",
      "CE Loss: 0.06296122819185257, Freq(freq) Loss1: 0.9763466715812683\n",
      "Learning Rate: 1.2135731569674937e-05\n",
      "Train Accuracy: 0.973726212978363\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74449186706543 s\n",
      "Throughout: 2410.2783678872115 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9285000562667847\n",
      "\n",
      "\n",
      "Epoch: 390\n",
      "Train Loss: 1.0543049573898315\n",
      "CE Loss: 0.0777374804019928, Freq(freq) Loss1: 0.9765675067901611\n",
      "Learning Rate: 1.1964249440111273e-05\n",
      "Train Accuracy: 0.9759396314620972\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74429170227051 s\n",
      "Throughout: 2410.301625026194 samples per second\n",
      "Val Loss: 0.34375\n",
      "Val Accuracy: 0.927899956703186\n",
      "\n",
      "\n",
      "Epoch: 391\n",
      "Train Loss: 1.0592565536499023\n",
      "CE Loss: 0.08198276907205582, Freq(freq) Loss1: 0.9772738218307495\n",
      "Learning Rate: 1.1793884894594464e-05\n",
      "Train Accuracy: 0.9745656847953796\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742678115844726 s\n",
      "Throughout: 2410.4891239577432 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9282001256942749\n",
      "\n",
      "\n",
      "Epoch: 392\n",
      "Train Loss: 1.0490349531173706\n",
      "CE Loss: 0.07163753360509872, Freq(freq) Loss1: 0.9773974418640137\n",
      "Learning Rate: 1.1624644605340704e-05\n",
      "Train Accuracy: 0.973725438117981\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747793075561525 s\n",
      "Throughout: 2409.894865343252 samples per second\n",
      "Val Loss: 0.283203125\n",
      "Val Accuracy: 0.9292000532150269\n",
      "\n",
      "\n",
      "Epoch: 393\n",
      "Train Loss: 1.070125699043274\n",
      "CE Loss: 0.09333527833223343, Freq(freq) Loss1: 0.9767904281616211\n",
      "Learning Rate: 1.145653520053548e-05\n",
      "Train Accuracy: 0.974753201007843\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74497639465332 s\n",
      "Throughout: 2410.222072505548 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9274999499320984\n",
      "\n",
      "\n",
      "Epoch: 394\n",
      "Train Loss: 1.0391480922698975\n",
      "CE Loss: 0.06171423941850662, Freq(freq) Loss1: 0.9774338603019714\n",
      "Learning Rate: 1.1289563264073916e-05\n",
      "Train Accuracy: 0.9749104976654053\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742326705932616 s\n",
      "Throughout: 2410.529961699005 samples per second\n",
      "Val Loss: 0.341796875\n",
      "Val Accuracy: 0.9289000034332275\n",
      "\n",
      "\n",
      "Epoch: 395\n",
      "Train Loss: 1.06856107711792\n",
      "CE Loss: 0.09151852130889893, Freq(freq) Loss1: 0.9770426154136658\n",
      "Learning Rate: 1.112373533530293e-05\n",
      "Train Accuracy: 0.9755802154541016\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75002975463867 s\n",
      "Throughout: 2409.6350989001594 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.92930006980896\n",
      "\n",
      "\n",
      "Epoch: 396\n",
      "Train Loss: 1.0563818216323853\n",
      "CE Loss: 0.07931414246559143, Freq(freq) Loss1: 0.9770677089691162\n",
      "Learning Rate: 1.0959057908765126e-05\n",
      "Train Accuracy: 0.975840151309967\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746541336059572 s\n",
      "Throughout: 2410.040265993396 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9306999444961548\n",
      "\n",
      "\n",
      "Epoch: 397\n",
      "Train Loss: 1.0656193494796753\n",
      "CE Loss: 0.08859606832265854, Freq(freq) Loss1: 0.9770232439041138\n",
      "Learning Rate: 1.0795537433944432e-05\n",
      "Train Accuracy: 0.9764636158943176\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.736635787963866 s\n",
      "Throughout: 2411.1915023854267 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9262999296188354\n",
      "\n",
      "\n",
      "Epoch: 398\n",
      "Train Loss: 1.0288386344909668\n",
      "CE Loss: 0.05223916098475456, Freq(freq) Loss1: 0.9765995144844055\n",
      "Learning Rate: 1.063318031501354e-05\n",
      "Train Accuracy: 0.975940465927124\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745847290039062 s\n",
      "Throughout: 2410.1208931585584 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9284999966621399\n",
      "\n",
      "\n",
      "Epoch: 399\n",
      "Train Loss: 1.0392221212387085\n",
      "CE Loss: 0.06300170719623566, Freq(freq) Loss1: 0.9762203693389893\n",
      "Learning Rate: 1.0471992910583014e-05\n",
      "Train Accuracy: 0.9760180115699768\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743872894287108 s\n",
      "Throughout: 2410.3502877599135 samples per second\n",
      "Val Loss: 0.275390625\n",
      "Val Accuracy: 0.9286999702453613\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "Train Loss: 1.04486083984375\n",
      "CE Loss: 0.06753735989332199, Freq(freq) Loss1: 0.9773235321044922\n",
      "Learning Rate: 1.0311981533452394e-05\n",
      "Train Accuracy: 0.9748903512954712\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743475448608397 s\n",
      "Throughout: 2410.396470151501 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9279999732971191\n",
      "\n",
      "\n",
      "Epoch: 401\n",
      "Train Loss: 1.018999695777893\n",
      "CE Loss: 0.04256119579076767, Freq(freq) Loss1: 0.9764384627342224\n",
      "Learning Rate: 1.01531524503628e-05\n",
      "Train Accuracy: 0.9758569002151489\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.754342391967775 s\n",
      "Throughout: 2409.1343900807337 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9287000298500061\n",
      "\n",
      "\n",
      "Epoch: 402\n",
      "Train Loss: 1.0201826095581055\n",
      "CE Loss: 0.043229300528764725, Freq(freq) Loss1: 0.9769532680511475\n",
      "Learning Rate: 9.995511881751624e-06\n",
      "Train Accuracy: 0.975921094417572\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74939680480957 s\n",
      "Throughout: 2409.7086035971097 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.928100049495697\n",
      "\n",
      "\n",
      "Epoch: 403\n",
      "Train Loss: 1.0624265670776367\n",
      "CE Loss: 0.08632279932498932, Freq(freq) Loss1: 0.9761037230491638\n",
      "Learning Rate: 9.839066001508854e-06\n",
      "Train Accuracy: 0.9745684266090393\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.732015411376953 s\n",
      "Throughout: 2411.728865133 samples per second\n",
      "Val Loss: 0.35546875\n",
      "Val Accuracy: 0.9282000660896301\n",
      "\n",
      "\n",
      "Epoch: 404\n",
      "Train Loss: 1.0399808883666992\n",
      "CE Loss: 0.06350716948509216, Freq(freq) Loss1: 0.9764736890792847\n",
      "Learning Rate: 9.683820936735292e-06\n",
      "Train Accuracy: 0.9767438173294067\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.706835327148436 s\n",
      "Throughout: 2414.6615941087684 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9290000200271606\n",
      "\n",
      "\n",
      "Epoch: 405\n",
      "Train Loss: 1.0388182401657104\n",
      "CE Loss: 0.06265701353549957, Freq(freq) Loss1: 0.9761612415313721\n",
      "Learning Rate: 9.529782767502556e-06\n",
      "Train Accuracy: 0.9768826961517334\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745892303466796 s\n",
      "Throughout: 2410.115663795508 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9270999431610107\n",
      "\n",
      "\n",
      "Epoch: 406\n",
      "Train Loss: 1.0646438598632812\n",
      "CE Loss: 0.08873604983091354, Freq(freq) Loss1: 0.9759078621864319\n",
      "Learning Rate: 9.376957526615021e-06\n",
      "Train Accuracy: 0.9756987690925598\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.756852798461914 s\n",
      "Throughout: 2408.8430209277685 samples per second\n",
      "Val Loss: 0.29296875\n",
      "Val Accuracy: 0.9249999523162842\n",
      "\n",
      "\n",
      "Epoch: 407\n",
      "Train Loss: 1.0495015382766724\n",
      "CE Loss: 0.07285400480031967, Freq(freq) Loss1: 0.9766475558280945\n",
      "Learning Rate: 9.225351199373525e-06\n",
      "Train Accuracy: 0.9762397408485413\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74527912902832 s\n",
      "Throughout: 2410.18690030718 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9280000329017639\n",
      "\n",
      "\n",
      "Epoch: 408\n",
      "Train Loss: 1.034842610359192\n",
      "CE Loss: 0.056589558720588684, Freq(freq) Loss1: 0.9782530069351196\n",
      "Learning Rate: 9.074969723340906e-06\n",
      "Train Accuracy: 0.9771231412887573\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70503855895996 s\n",
      "Throughout: 2414.8711366858506 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9293000102043152\n",
      "\n",
      "\n",
      "Epoch: 409\n",
      "Train Loss: 1.047808289527893\n",
      "CE Loss: 0.07010269165039062, Freq(freq) Loss1: 0.9777055978775024\n",
      "Learning Rate: 8.925818988109532e-06\n",
      "Train Accuracy: 0.9755117893218994\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.734486450195313 s\n",
      "Throughout: 2411.4414466015874 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9280000329017639\n",
      "\n",
      "\n",
      "Epoch: 410\n",
      "Train Loss: 1.0411689281463623\n",
      "CE Loss: 0.06290841847658157, Freq(freq) Loss1: 0.9782605171203613\n",
      "Learning Rate: 8.7779048350706e-06\n",
      "Train Accuracy: 0.9756178855895996\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.729336181640626 s\n",
      "Throughout: 2412.040576788154 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9294000267982483\n",
      "\n",
      "\n",
      "Epoch: 411\n",
      "Train Loss: 1.0375196933746338\n",
      "CE Loss: 0.06127144396305084, Freq(freq) Loss1: 0.9762482643127441\n",
      "Learning Rate: 8.631233057185398e-06\n",
      "Train Accuracy: 0.9768245816230774\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745513900756837 s\n",
      "Throughout: 2410.1596248322344 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9286999702453613\n",
      "\n",
      "\n",
      "Epoch: 412\n",
      "Train Loss: 1.0239551067352295\n",
      "CE Loss: 0.04766349866986275, Freq(freq) Loss1: 0.9762916564941406\n",
      "Learning Rate: 8.485809398758348e-06\n",
      "Train Accuracy: 0.9759178757667542\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75349067687988 s\n",
      "Throughout: 2409.2332600077616 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9267999529838562\n",
      "\n",
      "\n",
      "Epoch: 413\n",
      "Train Loss: 1.0465364456176758\n",
      "CE Loss: 0.07037069648504257, Freq(freq) Loss1: 0.9761657118797302\n",
      "Learning Rate: 8.34163955521216e-06\n",
      "Train Accuracy: 0.9767460823059082\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748932312011718 s\n",
      "Throughout: 2409.76254816999 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9285999536514282\n",
      "\n",
      "\n",
      "Epoch: 414\n",
      "Train Loss: 1.051689863204956\n",
      "CE Loss: 0.07519346475601196, Freq(freq) Loss1: 0.9764963984489441\n",
      "Learning Rate: 8.198729172864636e-06\n",
      "Train Accuracy: 0.977008044719696\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7431789855957 s\n",
      "Throughout: 2410.4309197119965 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9268999695777893\n",
      "\n",
      "\n",
      "Epoch: 415\n",
      "Train Loss: 1.0252395868301392\n",
      "CE Loss: 0.048942212015390396, Freq(freq) Loss1: 0.9762973189353943\n",
      "Learning Rate: 8.057083848707638e-06\n",
      "Train Accuracy: 0.9770727157592773\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744422744750977 s\n",
      "Throughout: 2410.286399155245 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9294000267982483\n",
      "\n",
      "\n",
      "Epoch: 416\n",
      "Train Loss: 1.0342776775360107\n",
      "CE Loss: 0.05585267394781113, Freq(freq) Loss1: 0.9784250259399414\n",
      "Learning Rate: 7.916709130187842e-06\n",
      "Train Accuracy: 0.9767612814903259\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746984176635742 s\n",
      "Throughout: 2409.988824125465 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9306000471115112\n",
      "\n",
      "\n",
      "Epoch: 417\n",
      "Train Loss: 1.0279159545898438\n",
      "CE Loss: 0.05076366662979126, Freq(freq) Loss1: 0.9771523475646973\n",
      "Learning Rate: 7.777610514989485e-06\n",
      "Train Accuracy: 0.9772071242332458\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751197967529297 s\n",
      "Throughout: 2409.4994456820345 samples per second\n",
      "Val Loss: 0.337890625\n",
      "Val Accuracy: 0.9290000200271606\n",
      "\n",
      "\n",
      "Epoch: 418\n",
      "Train Loss: 1.0399259328842163\n",
      "CE Loss: 0.06338103115558624, Freq(freq) Loss1: 0.9765449166297913\n",
      "Learning Rate: 7.639793450819051e-06\n",
      "Train Accuracy: 0.9773274064064026\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73845669555664 s\n",
      "Throughout: 2410.9797915055487 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9293999671936035\n",
      "\n",
      "\n",
      "Epoch: 419\n",
      "Train Loss: 1.0360451936721802\n",
      "CE Loss: 0.05948696285486221, Freq(freq) Loss1: 0.976558268070221\n",
      "Learning Rate: 7.503263335191903e-06\n",
      "Train Accuracy: 0.9765430092811584\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.760531784057616 s\n",
      "Throughout: 2408.416148491721 samples per second\n",
      "Val Loss: 0.357421875\n",
      "Val Accuracy: 0.9275000691413879\n",
      "\n",
      "\n",
      "Epoch: 420\n",
      "Train Loss: 1.0519095659255981\n",
      "CE Loss: 0.07572677731513977, Freq(freq) Loss1: 0.976182758808136\n",
      "Learning Rate: 7.368025515220932e-06\n",
      "Train Accuracy: 0.9775081276893616\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747133850097658 s\n",
      "Throughout: 2409.9714380434602 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9291000366210938\n",
      "\n",
      "\n",
      "Epoch: 421\n",
      "Train Loss: 1.0430494546890259\n",
      "CE Loss: 0.06644119322299957, Freq(freq) Loss1: 0.9766082167625427\n",
      "Learning Rate: 7.234085287407061e-06\n",
      "Train Accuracy: 0.9766193628311157\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74429933166504 s\n",
      "Throughout: 2410.3007385589412 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9294999837875366\n",
      "\n",
      "\n",
      "Epoch: 422\n",
      "Train Loss: 1.0471934080123901\n",
      "CE Loss: 0.07012094557285309, Freq(freq) Loss1: 0.9770724177360535\n",
      "Learning Rate: 7.101447897431937e-06\n",
      "Train Accuracy: 0.9772676825523376\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74683102416992 s\n",
      "Throughout: 2410.006614588528 samples per second\n",
      "Val Loss: 0.373046875\n",
      "Val Accuracy: 0.9275999665260315\n",
      "\n",
      "\n",
      "Epoch: 423\n",
      "Train Loss: 1.026695966720581\n",
      "CE Loss: 0.05011590197682381, Freq(freq) Loss1: 0.976580023765564\n",
      "Learning Rate: 6.970118539952339e-06\n",
      "Train Accuracy: 0.9778702259063721\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747400604248046 s\n",
      "Throughout: 2409.9404524807055 samples per second\n",
      "Val Loss: 0.36328125\n",
      "Val Accuracy: 0.9287000298500061\n",
      "\n",
      "\n",
      "Epoch: 424\n",
      "Train Loss: 1.042690634727478\n",
      "CE Loss: 0.06486628949642181, Freq(freq) Loss1: 0.977824330329895\n",
      "Learning Rate: 6.840102358396855e-06\n",
      "Train Accuracy: 0.9781729578971863\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74422509765625 s\n",
      "Throughout: 2410.3093639130034 samples per second\n",
      "Val Loss: 0.34765625\n",
      "Val Accuracy: 0.9297000169754028\n",
      "\n",
      "\n",
      "Epoch: 425\n",
      "Train Loss: 1.036056637763977\n",
      "CE Loss: 0.0594826303422451, Freq(freq) Loss1: 0.9765740633010864\n",
      "Learning Rate: 6.711404444764377e-06\n",
      "Train Accuracy: 0.9780771136283875\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7437233581543 s\n",
      "Throughout: 2410.3676633512923 samples per second\n",
      "Val Loss: 0.349609375\n",
      "Val Accuracy: 0.930899977684021\n",
      "\n",
      "\n",
      "Epoch: 426\n",
      "Train Loss: 1.0231577157974243\n",
      "CE Loss: 0.04584163799881935, Freq(freq) Loss1: 0.9773160815238953\n",
      "Learning Rate: 6.5840298394247035e-06\n",
      "Train Accuracy: 0.9769029021263123\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745194961547853 s\n",
      "Throughout: 2410.19667892624 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9314999580383301\n",
      "\n",
      "\n",
      "Epoch: 427\n",
      "Train Loss: 1.0464030504226685\n",
      "CE Loss: 0.06944277882575989, Freq(freq) Loss1: 0.9769602417945862\n",
      "Learning Rate: 6.4579835309211255e-06\n",
      "Train Accuracy: 0.978681206703186\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742709976196288 s\n",
      "Throughout: 2410.4854214988545 samples per second\n",
      "Val Loss: 0.353515625\n",
      "Val Accuracy: 0.9299999475479126\n",
      "\n",
      "\n",
      "Epoch: 428\n",
      "Train Loss: 1.0532885789871216\n",
      "CE Loss: 0.07678452134132385, Freq(freq) Loss1: 0.9765040874481201\n",
      "Learning Rate: 6.3332704557750284e-06\n",
      "Train Accuracy: 0.9782975912094116\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73843037414551 s\n",
      "Throughout: 2410.9828515438053 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.92930006980896\n",
      "\n",
      "\n",
      "Epoch: 429\n",
      "Train Loss: 1.0293623208999634\n",
      "CE Loss: 0.052369311451911926, Freq(freq) Loss1: 0.9769930243492126\n",
      "Learning Rate: 6.209895498292637e-06\n",
      "Train Accuracy: 0.9781966209411621\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747551315307618 s\n",
      "Throughout: 2409.9229465748963 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9292000532150269\n",
      "\n",
      "\n",
      "Epoch: 430\n",
      "Train Loss: 1.054565191268921\n",
      "CE Loss: 0.07804736495018005, Freq(freq) Loss1: 0.9765177965164185\n",
      "Learning Rate: 6.0878634903736196e-06\n",
      "Train Accuracy: 0.9778954982757568\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.762655364990234 s\n",
      "Throughout: 2408.1698184091356 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9305000305175781\n",
      "\n",
      "\n",
      "Epoch: 431\n",
      "Train Loss: 1.0453768968582153\n",
      "CE Loss: 0.06799285858869553, Freq(freq) Loss1: 0.9773840308189392\n",
      "Learning Rate: 5.967179211321923e-06\n",
      "Train Accuracy: 0.9773826003074646\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74364762878418 s\n",
      "Throughout: 2410.3764629427706 samples per second\n",
      "Val Loss: 0.3359375\n",
      "Val Accuracy: 0.9293999671936035\n",
      "\n",
      "\n",
      "Epoch: 432\n",
      "Train Loss: 1.0462679862976074\n",
      "CE Loss: 0.06969202309846878, Freq(freq) Loss1: 0.9765759110450745\n",
      "Learning Rate: 5.847847387658581e-06\n",
      "Train Accuracy: 0.9782732725143433\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748700439453124 s\n",
      "Throughout: 2409.789477943702 samples per second\n",
      "Val Loss: 0.3359375\n",
      "Val Accuracy: 0.9305999875068665\n",
      "\n",
      "\n",
      "Epoch: 433\n",
      "Train Loss: 1.0475882291793823\n",
      "CE Loss: 0.07096908241510391, Freq(freq) Loss1: 0.9766191840171814\n",
      "Learning Rate: 5.7298726929365885e-06\n",
      "Train Accuracy: 0.9770921468734741\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74521154785156 s\n",
      "Throughout: 2410.1947519150826 samples per second\n",
      "Val Loss: 0.333984375\n",
      "Val Accuracy: 0.9301000833511353\n",
      "\n",
      "\n",
      "Epoch: 434\n",
      "Train Loss: 1.024298071861267\n",
      "CE Loss: 0.04840277135372162, Freq(freq) Loss1: 0.9758952856063843\n",
      "Learning Rate: 5.613259747557843e-06\n",
      "Train Accuracy: 0.978314220905304\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743326263427733 s\n",
      "Throughout: 2410.4138056274173 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9298000335693359\n",
      "\n",
      "\n",
      "Epoch: 435\n",
      "Train Loss: 1.0266003608703613\n",
      "CE Loss: 0.04987924173474312, Freq(freq) Loss1: 0.9767211079597473\n",
      "Learning Rate: 5.498013118592277e-06\n",
      "Train Accuracy: 0.977534294128418\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75714044189453 s\n",
      "Throughout: 2408.809640227902 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9301999807357788\n",
      "\n",
      "\n",
      "Epoch: 436\n",
      "Train Loss: 1.037869930267334\n",
      "CE Loss: 0.06071382761001587, Freq(freq) Loss1: 0.9771561026573181\n",
      "Learning Rate: 5.3841373195988745e-06\n",
      "Train Accuracy: 0.9780327081680298\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750206787109374 s\n",
      "Throughout: 2409.614540856597 samples per second\n",
      "Val Loss: 0.33203125\n",
      "Val Accuracy: 0.9301999807357788\n",
      "\n",
      "\n",
      "Epoch: 437\n",
      "Train Loss: 1.0263915061950684\n",
      "CE Loss: 0.04989137127995491, Freq(freq) Loss1: 0.9765001535415649\n",
      "Learning Rate: 5.27163681044898e-06\n",
      "Train Accuracy: 0.978274941444397\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.733008010864257 s\n",
      "Throughout: 2411.6134028308684 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9294999837875366\n",
      "\n",
      "\n",
      "Epoch: 438\n",
      "Train Loss: 1.032809853553772\n",
      "CE Loss: 0.056322842836380005, Freq(freq) Loss1: 0.9764870405197144\n",
      "Learning Rate: 5.160515997151635e-06\n",
      "Train Accuracy: 0.979708731174469\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.70762559509277 s\n",
      "Throughout: 2414.569443048499 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9299999475479126\n",
      "\n",
      "\n",
      "Epoch: 439\n",
      "Train Loss: 1.0223604440689087\n",
      "CE Loss: 0.045618705451488495, Freq(freq) Loss1: 0.9767417311668396\n",
      "Learning Rate: 5.050779231680952e-06\n",
      "Train Accuracy: 0.9775687456130981\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745621826171874 s\n",
      "Throughout: 2410.1470864046087 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9287000298500061\n",
      "\n",
      "\n",
      "Epoch: 440\n",
      "Train Loss: 1.0406320095062256\n",
      "CE Loss: 0.06416983902454376, Freq(freq) Loss1: 0.976462185382843\n",
      "Learning Rate: 4.942430811805732e-06\n",
      "Train Accuracy: 0.978393018245697\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.76094921875 s\n",
      "Throughout: 2408.367723131036 samples per second\n",
      "Val Loss: 0.357421875\n",
      "Val Accuracy: 0.928399920463562\n",
      "\n",
      "\n",
      "Epoch: 441\n",
      "Train Loss: 1.0323020219802856\n",
      "CE Loss: 0.05578451231122017, Freq(freq) Loss1: 0.9765175580978394\n",
      "Learning Rate: 4.835474980921124e-06\n",
      "Train Accuracy: 0.9775699973106384\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742602935791016 s\n",
      "Throughout: 2410.497860600023 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9315000176429749\n",
      "\n",
      "\n",
      "Epoch: 442\n",
      "Train Loss: 1.0137943029403687\n",
      "CE Loss: 0.03688756376504898, Freq(freq) Loss1: 0.9769067168235779\n",
      "Learning Rate: 4.729915927882454e-06\n",
      "Train Accuracy: 0.9791015386581421\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75360546875 s\n",
      "Throughout: 2409.2199341115993 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9294999241828918\n",
      "\n",
      "\n",
      "Epoch: 443\n",
      "Train Loss: 1.0433112382888794\n",
      "CE Loss: 0.06597144901752472, Freq(freq) Loss1: 0.9773398041725159\n",
      "Learning Rate: 4.625757786841117e-06\n",
      "Train Accuracy: 0.9789779186248779\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.732243743896483 s\n",
      "Throughout: 2411.7023037952595 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9305999875068665\n",
      "\n",
      "\n",
      "Epoch: 444\n",
      "Train Loss: 1.0243403911590576\n",
      "CE Loss: 0.0476442351937294, Freq(freq) Loss1: 0.9766961932182312\n",
      "Learning Rate: 4.523004637082753e-06\n",
      "Train Accuracy: 0.9793603420257568\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743498809814454 s\n",
      "Throughout: 2410.3937555772077 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.930400013923645\n",
      "\n",
      "\n",
      "Epoch: 445\n",
      "Train Loss: 1.060459017753601\n",
      "CE Loss: 0.08352318406105042, Freq(freq) Loss1: 0.9769358038902283\n",
      "Learning Rate: 4.421660502867393e-06\n",
      "Train Accuracy: 0.9784552454948425\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75212367248535 s\n",
      "Throughout: 2409.391963401489 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9327999353408813\n",
      "\n",
      "\n",
      "Epoch: 446\n",
      "Train Loss: 1.0308364629745483\n",
      "CE Loss: 0.054906561970710754, Freq(freq) Loss1: 0.9759299159049988\n",
      "Learning Rate: 4.3217293532719235e-06\n",
      "Train Accuracy: 0.9791239500045776\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.759600708007813 s\n",
      "Throughout: 2408.5241668792305 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9320999979972839\n",
      "\n",
      "\n",
      "Epoch: 447\n",
      "Train Loss: 1.039928674697876\n",
      "CE Loss: 0.0632113665342331, Freq(freq) Loss1: 0.9767172932624817\n",
      "Learning Rate: 4.2232151020345806e-06\n",
      "Train Accuracy: 0.9790194630622864\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744347549438476 s\n",
      "Throughout: 2410.2951361009877 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9298999309539795\n",
      "\n",
      "\n",
      "Epoch: 448\n",
      "Train Loss: 1.0317530632019043\n",
      "CE Loss: 0.05403362214565277, Freq(freq) Loss1: 0.9777194857597351\n",
      "Learning Rate: 4.126121607401737e-06\n",
      "Train Accuracy: 0.9791581630706787\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.770508041381834 s\n",
      "Throughout: 2407.259365075866 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9323999881744385\n",
      "\n",
      "\n",
      "Epoch: 449\n",
      "Train Loss: 1.0359725952148438\n",
      "CE Loss: 0.058694466948509216, Freq(freq) Loss1: 0.9772781729698181\n",
      "Learning Rate: 4.030452671976742e-06\n",
      "Train Accuracy: 0.9788796305656433\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74688671875 s\n",
      "Throughout: 2410.000144976571 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9320999979972839\n",
      "\n",
      "\n",
      "Epoch: 450\n",
      "Train Loss: 1.0364453792572021\n",
      "CE Loss: 0.06029996648430824, Freq(freq) Loss1: 0.9761454463005066\n",
      "Learning Rate: 3.936212042570993e-06\n",
      "Train Accuracy: 0.979202926158905\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742577545166014 s\n",
      "Throughout: 2410.5008112481337 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9316999912261963\n",
      "\n",
      "\n",
      "Epoch: 451\n",
      "Train Loss: 1.0411800146102905\n",
      "CE Loss: 0.06427586823701859, Freq(freq) Loss1: 0.9769041538238525\n",
      "Learning Rate: 3.843403410057261e-06\n",
      "Train Accuracy: 0.9788962602615356\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747971557617188 s\n",
      "Throughout: 2409.874134497911 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9310999512672424\n",
      "\n",
      "\n",
      "Epoch: 452\n",
      "Train Loss: 1.0294359922409058\n",
      "CE Loss: 0.05209723114967346, Freq(freq) Loss1: 0.9773387312889099\n",
      "Learning Rate: 3.7520304092250443e-06\n",
      "Train Accuracy: 0.9773472547531128\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746331878662108 s\n",
      "Throughout: 2410.0645980423024 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9314000010490417\n",
      "\n",
      "\n",
      "Epoch: 453\n",
      "Train Loss: 1.0522264242172241\n",
      "CE Loss: 0.07542373239994049, Freq(freq) Loss1: 0.9768027067184448\n",
      "Learning Rate: 3.6620966186383014e-06\n",
      "Train Accuracy: 0.9778330326080322\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747177627563477 s\n",
      "Throughout: 2409.9663528967403 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9314000010490417\n",
      "\n",
      "\n",
      "Epoch: 454\n",
      "Train Loss: 1.0240631103515625\n",
      "CE Loss: 0.045721106231212616, Freq(freq) Loss1: 0.9783419966697693\n",
      "Learning Rate: 3.5736055604952346e-06\n",
      "Train Accuracy: 0.9790785312652588\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.716979293823243 s\n",
      "Throughout: 2413.4792669753488 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9306999444961548\n",
      "\n",
      "\n",
      "Epoch: 455\n",
      "Train Loss: 1.0396913290023804\n",
      "CE Loss: 0.0633285790681839, Freq(freq) Loss1: 0.9763627052307129\n",
      "Learning Rate: 3.486560700490394e-06\n",
      "Train Accuracy: 0.9785799980163574\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.758590225219727 s\n",
      "Throughout: 2408.6414085699676 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9301000833511353\n",
      "\n",
      "\n",
      "Epoch: 456\n",
      "Train Loss: 1.0480815172195435\n",
      "CE Loss: 0.07151234149932861, Freq(freq) Loss1: 0.9765691757202148\n",
      "Learning Rate: 3.400965447678894e-06\n",
      "Train Accuracy: 0.9783536791801453\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748377059936523 s\n",
      "Throughout: 2409.827036377995 samples per second\n",
      "Val Loss: 0.291015625\n",
      "Val Accuracy: 0.9307999610900879\n",
      "\n",
      "\n",
      "Epoch: 457\n",
      "Train Loss: 1.0312048196792603\n",
      "CE Loss: 0.05485996603965759, Freq(freq) Loss1: 0.976344883441925\n",
      "Learning Rate: 3.3168231543429747e-06\n",
      "Train Accuracy: 0.9800851345062256\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.69064505004883 s\n",
      "Throughout: 2416.5510489911962 samples per second\n",
      "Val Loss: 0.296875\n",
      "Val Accuracy: 0.9301999807357788\n",
      "\n",
      "\n",
      "Epoch: 458\n",
      "Train Loss: 1.057310938835144\n",
      "CE Loss: 0.0805685967206955, Freq(freq) Loss1: 0.9767423272132874\n",
      "Learning Rate: 3.234137115860612e-06\n",
      "Train Accuracy: 0.9791220426559448\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75510887145996 s\n",
      "Throughout: 2409.045421522903 samples per second\n",
      "Val Loss: 0.30078125\n",
      "Val Accuracy: 0.9310999512672424\n",
      "\n",
      "\n",
      "Epoch: 459\n",
      "Train Loss: 1.0400936603546143\n",
      "CE Loss: 0.06362631171941757, Freq(freq) Loss1: 0.9764673709869385\n",
      "Learning Rate: 3.1529105705765422e-06\n",
      "Train Accuracy: 0.9795234799385071\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74349884033203 s\n",
      "Throughout: 2410.3937520310665 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9326000213623047\n",
      "\n",
      "\n",
      "Epoch: 460\n",
      "Train Loss: 1.00867760181427\n",
      "CE Loss: 0.03172672912478447, Freq(freq) Loss1: 0.9769508838653564\n",
      "Learning Rate: 3.073146699675421e-06\n",
      "Train Accuracy: 0.9799413681030273\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.739497619628906 s\n",
      "Throughout: 2410.8587834199743 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9320999979972839\n",
      "\n",
      "\n",
      "Epoch: 461\n",
      "Train Loss: 1.0521352291107178\n",
      "CE Loss: 0.074954554438591, Freq(freq) Loss1: 0.9771806597709656\n",
      "Learning Rate: 2.994848627057172e-06\n",
      "Train Accuracy: 0.9781770706176758\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743749618530273 s\n",
      "Throughout: 2410.3646119665505 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9308000206947327\n",
      "\n",
      "\n",
      "Epoch: 462\n",
      "Train Loss: 1.0436372756958008\n",
      "CE Loss: 0.06690147519111633, Freq(freq) Loss1: 0.9767357707023621\n",
      "Learning Rate: 2.9180194192147153e-06\n",
      "Train Accuracy: 0.979301393032074\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.750780715942383 s\n",
      "Throughout: 2409.547895303335 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9318000078201294\n",
      "\n",
      "\n",
      "Epoch: 463\n",
      "Train Loss: 1.0272241830825806\n",
      "CE Loss: 0.05093152076005936, Freq(freq) Loss1: 0.976292610168457\n",
      "Learning Rate: 2.8426620851138314e-06\n",
      "Train Accuracy: 0.9791442155838013\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751230072021485 s\n",
      "Throughout: 2409.4957179147714 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.932699978351593\n",
      "\n",
      "\n",
      "Epoch: 464\n",
      "Train Loss: 1.0252386331558228\n",
      "CE Loss: 0.0478590652346611, Freq(freq) Loss1: 0.977379560470581\n",
      "Learning Rate: 2.7687795760753377e-06\n",
      "Train Accuracy: 0.9803854823112488\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.73476266479492 s\n",
      "Throughout: 2411.4093229962 samples per second\n",
      "Val Loss: 0.298828125\n",
      "Val Accuracy: 0.9322999715805054\n",
      "\n",
      "\n",
      "Epoch: 465\n",
      "Train Loss: 1.0272233486175537\n",
      "CE Loss: 0.04995168745517731, Freq(freq) Loss1: 0.9772716760635376\n",
      "Learning Rate: 2.696374785659462e-06\n",
      "Train Accuracy: 0.9791173338890076\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.751601531982423 s\n",
      "Throughout: 2409.4525872106724 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9320999979972839\n",
      "\n",
      "\n",
      "Epoch: 466\n",
      "Train Loss: 1.0253950357437134\n",
      "CE Loss: 0.048768240958452225, Freq(freq) Loss1: 0.9766267538070679\n",
      "Learning Rate: 2.6254505495525867e-06\n",
      "Train Accuracy: 0.9800253510475159\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.707281036376955 s\n",
      "Throughout: 2414.6096202666035 samples per second\n",
      "Val Loss: 0.326171875\n",
      "Val Accuracy: 0.9312000274658203\n",
      "\n",
      "\n",
      "Epoch: 467\n",
      "Train Loss: 1.0241456031799316\n",
      "CE Loss: 0.047356292605400085, Freq(freq) Loss1: 0.9767892956733704\n",
      "Learning Rate: 2.556009645456117e-06\n",
      "Train Accuracy: 0.9796422719955444\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.748839431762697 s\n",
      "Throughout: 2409.7733352478067 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9315999746322632\n",
      "\n",
      "\n",
      "Epoch: 468\n",
      "Train Loss: 1.055287480354309\n",
      "CE Loss: 0.0782027393579483, Freq(freq) Loss1: 0.9770846962928772\n",
      "Learning Rate: 2.488054792977752e-06\n",
      "Train Accuracy: 0.97791588306427\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75728631591797 s\n",
      "Throughout: 2408.7927120635663 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9320999383926392\n",
      "\n",
      "\n",
      "Epoch: 469\n",
      "Train Loss: 1.03943932056427\n",
      "CE Loss: 0.06233660504221916, Freq(freq) Loss1: 0.9771026968955994\n",
      "Learning Rate: 2.4215886535249233e-06\n",
      "Train Accuracy: 0.9789381623268127\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742510711669922 s\n",
      "Throughout: 2410.508578012668 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9309999942779541\n",
      "\n",
      "\n",
      "Epoch: 470\n",
      "Train Loss: 1.0383845567703247\n",
      "CE Loss: 0.061200786381959915, Freq(freq) Loss1: 0.9771838188171387\n",
      "Learning Rate: 2.3566138302006147e-06\n",
      "Train Accuracy: 0.9797622561454773\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74364990234375 s\n",
      "Throughout: 2410.3761987590565 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9307999610900879\n",
      "\n",
      "\n",
      "Epoch: 471\n",
      "Train Loss: 1.031937599182129\n",
      "CE Loss: 0.055830467492341995, Freq(freq) Loss1: 0.976107120513916\n",
      "Learning Rate: 2.2931328677013784e-06\n",
      "Train Accuracy: 0.9793189764022827\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.706317092895507 s\n",
      "Throughout: 2414.7220278566765 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9315999746322632\n",
      "\n",
      "\n",
      "Epoch: 472\n",
      "Train Loss: 1.0309165716171265\n",
      "CE Loss: 0.054602112621068954, Freq(freq) Loss1: 0.9763144254684448\n",
      "Learning Rate: 2.231148252217667e-06\n",
      "Train Accuracy: 0.9797587394714355\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741642028808595 s\n",
      "Throughout: 2410.6095327724643 samples per second\n",
      "Val Loss: 0.330078125\n",
      "Val Accuracy: 0.9312999248504639\n",
      "\n",
      "\n",
      "Epoch: 473\n",
      "Train Loss: 1.0190589427947998\n",
      "CE Loss: 0.04180784523487091, Freq(freq) Loss1: 0.9772511124610901\n",
      "Learning Rate: 2.170662411336503e-06\n",
      "Train Accuracy: 0.9796048402786255\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747896759033203 s\n",
      "Throughout: 2409.8828223748046 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9314000010490417\n",
      "\n",
      "\n",
      "Epoch: 474\n",
      "Train Loss: 1.041821002960205\n",
      "CE Loss: 0.06519579142332077, Freq(freq) Loss1: 0.9766252636909485\n",
      "Learning Rate: 2.1116777139463666e-06\n",
      "Train Accuracy: 0.9795582294464111\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75185205078125 s\n",
      "Throughout: 2409.4235000156355 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9318999648094177\n",
      "\n",
      "\n",
      "Epoch: 475\n",
      "Train Loss: 1.0446020364761353\n",
      "CE Loss: 0.06820395588874817, Freq(freq) Loss1: 0.9763980507850647\n",
      "Learning Rate: 2.054196470144431e-06\n",
      "Train Accuracy: 0.9802466034889221\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.7645154876709 s\n",
      "Throughout: 2407.9540902212675 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9307999610900879\n",
      "\n",
      "\n",
      "Epoch: 476\n",
      "Train Loss: 1.0400763750076294\n",
      "CE Loss: 0.06218470633029938, Freq(freq) Loss1: 0.9778916835784912\n",
      "Learning Rate: 1.9982209311460954e-06\n",
      "Train Accuracy: 0.9799652695655823\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.71537814331055 s\n",
      "Throughout: 2413.665811654329 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9307000637054443\n",
      "\n",
      "\n",
      "Epoch: 477\n",
      "Train Loss: 1.0197396278381348\n",
      "CE Loss: 0.04347710683941841, Freq(freq) Loss1: 0.9762625694274902\n",
      "Learning Rate: 1.9437532891968185e-06\n",
      "Train Accuracy: 0.9795467853546143\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.741885482788085 s\n",
      "Throughout: 2410.5812386964876 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.931600034236908\n",
      "\n",
      "\n",
      "Epoch: 478\n",
      "Train Loss: 1.0785329341888428\n",
      "CE Loss: 0.1021268218755722, Freq(freq) Loss1: 0.9764060974121094\n",
      "Learning Rate: 1.890795677486234e-06\n",
      "Train Accuracy: 0.9800613522529602\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742885330200195 s\n",
      "Throughout: 2410.4650439928664 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9320001006126404\n",
      "\n",
      "\n",
      "Epoch: 479\n",
      "Train Loss: 1.0398434400558472\n",
      "CE Loss: 0.06309588253498077, Freq(freq) Loss1: 0.9767475128173828\n",
      "Learning Rate: 1.839350170064662e-06\n",
      "Train Accuracy: 0.979181170463562\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.705248413085936 s\n",
      "Throughout: 2414.8466612165575 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9324999451637268\n",
      "\n",
      "\n",
      "Epoch: 480\n",
      "Train Loss: 1.0488016605377197\n",
      "CE Loss: 0.07217814773321152, Freq(freq) Loss1: 0.9766234755516052\n",
      "Learning Rate: 1.7894187817618087e-06\n",
      "Train Accuracy: 0.979741632938385\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742843292236326 s\n",
      "Throughout: 2410.4699291014795 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9310999512672424\n",
      "\n",
      "\n",
      "Epoch: 481\n",
      "Train Loss: 1.0186973810195923\n",
      "CE Loss: 0.04215553402900696, Freq(freq) Loss1: 0.9765418171882629\n",
      "Learning Rate: 1.7410034681079127e-06\n",
      "Train Accuracy: 0.9801403284072876\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.761422760009765 s\n",
      "Throughout: 2408.3127913713597 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9316999912261963\n",
      "\n",
      "\n",
      "Epoch: 482\n",
      "Train Loss: 1.0246301889419556\n",
      "CE Loss: 0.04572617635130882, Freq(freq) Loss1: 0.9789040684700012\n",
      "Learning Rate: 1.6941061252571409e-06\n",
      "Train Accuracy: 0.9799425005912781\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.75179734802246 s\n",
      "Throughout: 2409.429851374524 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9305000305175781\n",
      "\n",
      "\n",
      "Epoch: 483\n",
      "Train Loss: 1.0340425968170166\n",
      "CE Loss: 0.05735710635781288, Freq(freq) Loss1: 0.9766855239868164\n",
      "Learning Rate: 1.6487285899133137e-06\n",
      "Train Accuracy: 0.9795616865158081\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753344696044923 s\n",
      "Throughout: 2409.2502067644436 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9309000372886658\n",
      "\n",
      "\n",
      "Epoch: 484\n",
      "Train Loss: 1.0154592990875244\n",
      "CE Loss: 0.03827579319477081, Freq(freq) Loss1: 0.97718346118927\n",
      "Learning Rate: 1.6048726392579891e-06\n",
      "Train Accuracy: 0.9798061847686768\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.753331069946288 s\n",
      "Throughout: 2409.2517886156097 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9312000870704651\n",
      "\n",
      "\n",
      "Epoch: 485\n",
      "Train Loss: 1.034639835357666\n",
      "CE Loss: 0.058228135108947754, Freq(freq) Loss1: 0.9764116406440735\n",
      "Learning Rate: 1.5625399908808491e-06\n",
      "Train Accuracy: 0.9794223308563232\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742259857177736 s\n",
      "Throughout: 2410.537730424672 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9315999746322632\n",
      "\n",
      "\n",
      "Epoch: 486\n",
      "Train Loss: 1.0240635871887207\n",
      "CE Loss: 0.047615956515073776, Freq(freq) Loss1: 0.976447582244873\n",
      "Learning Rate: 1.5217323027124496e-06\n",
      "Train Accuracy: 0.9808516502380371\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747408477783203 s\n",
      "Throughout: 2409.939537920658 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9317999482154846\n",
      "\n",
      "\n",
      "Epoch: 487\n",
      "Train Loss: 1.0246367454528809\n",
      "CE Loss: 0.04828781634569168, Freq(freq) Loss1: 0.976348876953125\n",
      "Learning Rate: 1.4824511729592425e-06\n",
      "Train Accuracy: 0.9793978333473206\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.718352371215822 s\n",
      "Throughout: 2413.3193172959745 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9324999451637268\n",
      "\n",
      "\n",
      "Epoch: 488\n",
      "Train Loss: 1.0469673871994019\n",
      "CE Loss: 0.06997258961200714, Freq(freq) Loss1: 0.9769947528839111\n",
      "Learning Rate: 1.4446981400410622e-06\n",
      "Train Accuracy: 0.9792596697807312\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.752781661987306 s\n",
      "Throughout: 2409.315571010154 samples per second\n",
      "Val Loss: 0.302734375\n",
      "Val Accuracy: 0.9323999881744385\n",
      "\n",
      "\n",
      "Epoch: 489\n",
      "Train Loss: 1.0450366735458374\n",
      "CE Loss: 0.0675666481256485, Freq(freq) Loss1: 0.9774700403213501\n",
      "Learning Rate: 1.4084746825307868e-06\n",
      "Train Accuracy: 0.9795041680335999\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747850524902343 s\n",
      "Throughout: 2409.8881925136357 samples per second\n",
      "Val Loss: 0.3046875\n",
      "Val Accuracy: 0.9316000938415527\n",
      "\n",
      "\n",
      "Epoch: 490\n",
      "Train Loss: 1.0270894765853882\n",
      "CE Loss: 0.05054666846990585, Freq(freq) Loss1: 0.9765427708625793\n",
      "Learning Rate: 1.3737822190964998e-06\n",
      "Train Accuracy: 0.9795451164245605\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74655000305176 s\n",
      "Throughout: 2410.0392591850277 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9325000047683716\n",
      "\n",
      "\n",
      "Epoch: 491\n",
      "Train Loss: 1.029314398765564\n",
      "CE Loss: 0.05334322899580002, Freq(freq) Loss1: 0.9759711623191833\n",
      "Learning Rate: 1.3406221084458782e-06\n",
      "Train Accuracy: 0.9800461530685425\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.758903549194336 s\n",
      "Throughout: 2408.6050538030718 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9325000047683716\n",
      "\n",
      "\n",
      "Epoch: 492\n",
      "Train Loss: 1.0443165302276611\n",
      "CE Loss: 0.06618966907262802, Freq(freq) Loss1: 0.9781268239021301\n",
      "Learning Rate: 1.3089956492730208e-06\n",
      "Train Accuracy: 0.9806287288665771\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.756576461791994 s\n",
      "Throughout: 2408.8750903617615 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9312999844551086\n",
      "\n",
      "\n",
      "Epoch: 493\n",
      "Train Loss: 1.05073881149292\n",
      "CE Loss: 0.07386763393878937, Freq(freq) Loss1: 0.9768711924552917\n",
      "Learning Rate: 1.2789040802075598e-06\n",
      "Train Accuracy: 0.9801250100135803\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747400497436523 s\n",
      "Throughout: 2409.9404648875325 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9316999316215515\n",
      "\n",
      "\n",
      "Epoch: 494\n",
      "Train Loss: 1.035383939743042\n",
      "CE Loss: 0.058604057878255844, Freq(freq) Loss1: 0.9767798781394958\n",
      "Learning Rate: 1.250348579766154e-06\n",
      "Train Accuracy: 0.979360818862915\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74672462463379 s\n",
      "Throughout: 2410.0189743026763 samples per second\n",
      "Val Loss: 0.314453125\n",
      "Val Accuracy: 0.9325999617576599\n",
      "\n",
      "\n",
      "Epoch: 495\n",
      "Train Loss: 1.0170316696166992\n",
      "CE Loss: 0.04102239012718201, Freq(freq) Loss1: 0.9760092496871948\n",
      "Learning Rate: 1.2233302663063503e-06\n",
      "Train Accuracy: 0.980651319026947\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744469268798827 s\n",
      "Throughout: 2410.280993556369 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9321000576019287\n",
      "\n",
      "\n",
      "Epoch: 496\n",
      "Train Loss: 1.027637004852295\n",
      "CE Loss: 0.051230400800704956, Freq(freq) Loss1: 0.9764066338539124\n",
      "Learning Rate: 1.1978501979827516e-06\n",
      "Train Accuracy: 0.9801262021064758\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.742609100341795 s\n",
      "Throughout: 2410.4971442177975 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9326999187469482\n",
      "\n",
      "\n",
      "Epoch: 497\n",
      "Train Loss: 1.028522253036499\n",
      "CE Loss: 0.0515400730073452, Freq(freq) Loss1: 0.9769822359085083\n",
      "Learning Rate: 1.1739093727056149e-06\n",
      "Train Accuracy: 0.9804893136024475\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74394546508789 s\n",
      "Throughout: 2410.341855369323 samples per second\n",
      "Val Loss: 0.30859375\n",
      "Val Accuracy: 0.9320000410079956\n",
      "\n",
      "\n",
      "Epoch: 498\n",
      "Train Loss: 1.036258578300476\n",
      "CE Loss: 0.06003858149051666, Freq(freq) Loss1: 0.9762200117111206\n",
      "Learning Rate: 1.1515087281017242e-06\n",
      "Train Accuracy: 0.9798834919929504\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.747366760253907 s\n",
      "Throughout: 2409.9443836788905 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9321999549865723\n",
      "\n",
      "\n",
      "Epoch: 499\n",
      "Train Loss: 1.0531015396118164\n",
      "CE Loss: 0.07504686713218689, Freq(freq) Loss1: 0.9780547022819519\n",
      "Learning Rate: 1.1306491414777167e-06\n",
      "Train Accuracy: 0.9795262217521667\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745171279907225 s\n",
      "Throughout: 2410.199430285138 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9325999617576599\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "Train Loss: 1.0584592819213867\n",
      "CE Loss: 0.08147943764925003, Freq(freq) Loss1: 0.9769797921180725\n",
      "Learning Rate: 1.1113314297856828e-06\n",
      "Train Accuracy: 0.9798435568809509\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74584851074219 s\n",
      "Throughout: 2410.1207513450236 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9322999715805054\n",
      "\n",
      "\n",
      "Epoch: 501\n",
      "Train Loss: 1.0309276580810547\n",
      "CE Loss: 0.05452130734920502, Freq(freq) Loss1: 0.9764063954353333\n",
      "Learning Rate: 1.093556349591197e-06\n",
      "Train Accuracy: 0.9814359545707703\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746091415405274 s\n",
      "Throughout: 2410.0925325563667 samples per second\n",
      "Val Loss: 0.3203125\n",
      "Val Accuracy: 0.9320999383926392\n",
      "\n",
      "\n",
      "Epoch: 502\n",
      "Train Loss: 1.0486204624176025\n",
      "CE Loss: 0.0718146488070488, Freq(freq) Loss1: 0.9768058061599731\n",
      "Learning Rate: 1.0773245970436726e-06\n",
      "Train Accuracy: 0.9803069233894348\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744606292724608 s\n",
      "Throughout: 2410.2650729763727 samples per second\n",
      "Val Loss: 0.32421875\n",
      "Val Accuracy: 0.9326000213623047\n",
      "\n",
      "\n",
      "Epoch: 503\n",
      "Train Loss: 1.0077550411224365\n",
      "CE Loss: 0.03181568905711174, Freq(freq) Loss1: 0.9759393930435181\n",
      "Learning Rate: 1.0626368078491029e-06\n",
      "Train Accuracy: 0.9793201088905334\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.744433639526367 s\n",
      "Throughout: 2410.285133296201 samples per second\n",
      "Val Loss: 0.310546875\n",
      "Val Accuracy: 0.9314000010490417\n",
      "\n",
      "\n",
      "Epoch: 504\n",
      "Train Loss: 1.032096028327942\n",
      "CE Loss: 0.05495847016572952, Freq(freq) Loss1: 0.9771375060081482\n",
      "Learning Rate: 1.0494935572451647e-06\n",
      "Train Accuracy: 0.980991542339325\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74915579223633 s\n",
      "Throughout: 2409.7365936549763 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9315000772476196\n",
      "\n",
      "\n",
      "Epoch: 505\n",
      "Train Loss: 1.0031052827835083\n",
      "CE Loss: 0.026853114366531372, Freq(freq) Loss1: 0.9762521982192993\n",
      "Learning Rate: 1.0378953599786947e-06\n",
      "Train Accuracy: 0.9800078272819519\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.746262420654297 s\n",
      "Throughout: 2410.0726668829584 samples per second\n",
      "Val Loss: 0.322265625\n",
      "Val Accuracy: 0.9317000508308411\n",
      "\n",
      "\n",
      "Epoch: 506\n",
      "Train Loss: 1.0659517049789429\n",
      "CE Loss: 0.08900522440671921, Freq(freq) Loss1: 0.9769464731216431\n",
      "Learning Rate: 1.0278426702855176e-06\n",
      "Train Accuracy: 0.9796833992004395\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.743652084350586 s\n",
      "Throughout: 2410.375945213667 samples per second\n",
      "Val Loss: 0.328125\n",
      "Val Accuracy: 0.9318999648094177\n",
      "\n",
      "\n",
      "Epoch: 507\n",
      "Train Loss: 1.0439211130142212\n",
      "CE Loss: 0.06633163243532181, Freq(freq) Loss1: 0.97758948802948\n",
      "Learning Rate: 1.0193358818726626e-06\n",
      "Train Accuracy: 0.9806286692619324\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.72931851196289 s\n",
      "Throughout: 2412.0426328123135 samples per second\n",
      "Val Loss: 0.31640625\n",
      "Val Accuracy: 0.9322999715805054\n",
      "\n",
      "\n",
      "Epoch: 508\n",
      "Train Loss: 1.0259499549865723\n",
      "CE Loss: 0.049576789140701294, Freq(freq) Loss1: 0.9763731956481934\n",
      "Learning Rate: 1.0123753279029454e-06\n",
      "Train Accuracy: 0.9813745617866516\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74372573852539 s\n",
      "Throughout: 2410.367386758284 samples per second\n",
      "Val Loss: 0.318359375\n",
      "Val Accuracy: 0.9325000047683716\n",
      "\n",
      "\n",
      "Epoch: 509\n",
      "Train Loss: 1.0308167934417725\n",
      "CE Loss: 0.054448287934064865, Freq(freq) Loss1: 0.9763684868812561\n",
      "Learning Rate: 1.0069612809819246e-06\n",
      "Train Accuracy: 0.9798055291175842\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74420620727539 s\n",
      "Throughout: 2410.3115588228216 samples per second\n",
      "Val Loss: 0.3125\n",
      "Val Accuracy: 0.9316999316215515\n",
      "\n",
      "\n",
      "Epoch: 510\n",
      "Train Loss: 1.0433357954025269\n",
      "CE Loss: 0.06663592904806137, Freq(freq) Loss1: 0.9766998291015625\n",
      "Learning Rate: 1.0030939531472073e-06\n",
      "Train Accuracy: 0.9807881712913513\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.74174264526367 s\n",
      "Throughout: 2410.5978391076696 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9319999814033508\n",
      "\n",
      "\n",
      "Epoch: 511\n",
      "Train Loss: 1.034213900566101\n",
      "CE Loss: 0.05639011412858963, Freq(freq) Loss1: 0.977823793888092\n",
      "Learning Rate: 1.0007734958601682e-06\n",
      "Train Accuracy: 0.9798232913017273\n",
      "Peak Mem Reserved: 24209522688\n",
      "Peak Mem Allocated: 21745843712\n",
      "Current train time: 20.745616638183595 s\n",
      "Throughout: 2410.1476891254174 samples per second\n",
      "Val Loss: 0.306640625\n",
      "Val Accuracy: 0.9318999648094177\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "G_GNS = []\n",
    "G_SNR = []\n",
    "\n",
    "\n",
    "def gradient_noise_scale(grad):\n",
    "    tr_sigma = grad.var(0, unbiased=False).sum()\n",
    "    return tr_sigma / (grad.mean(0).pow(2).sum() + 1e-12)\n",
    "\n",
    "def signal_to_noise_ratio(grad):\n",
    "    mu = grad.mean(0)\n",
    "    tr_sigma = grad.var(0, unbiased=False).sum()\n",
    "    return mu.norm() / (tr_sigma.sqrt() + 1e-12)\n",
    "\n",
    "max_acc = 0.0\n",
    "global_step = 0\n",
    "torch.cuda.synchronize()\n",
    "total_timer_start.record()\n",
    "for i in range(num_epochs):\n",
    "    train_logits = []\n",
    "    train_y = []\n",
    "    \n",
    "\n",
    "    val_logits = []\n",
    "    val_y = []\n",
    "    partile_time = 0\n",
    "    # controller.traced_model.train()\n",
    "    model.train()\n",
    "    # aot_model.train()\n",
    "    G = []\n",
    "    torch.cuda.synchronize()\n",
    "    # k = i % total_graphs\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        # torch.cuda.current_stream().wait_stream(warmup)  \n",
    "        x, y = x.to('cuda', non_blocking=True), y.to('cuda', non_blocking=True)\n",
    "        \n",
    "        e_timer_start.record()\n",
    "        # compute_stream.wait_stream(torch.cuda.current_stream())\n",
    "        # with torch.cuda.stream(compute_stream):\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=True):\n",
    "                # static_x.copy_(x)\n",
    "                # static_y.copy_(y)\n",
    "                # opt.zero_grad(set_to_none=False)\n",
    "\n",
    "                # total_steps = i * len(train_loader) + step\n",
    "                # k = step % total_graphs\n",
    "                # add_smoothout_noise(controller.traced_model)\n",
    "                # assign_theta(controller.traced_model)\n",
    "                # graphs[0].replay()\n",
    "                # remove_smoothout_noise(controller.traced_model)\n",
    "                # opt.step()\n",
    "                # scheduler.step()   \n",
    "                \n",
    "                # train_logits.append(logits.detach().cpu())\n",
    "                # train_y.append(static_y.detach().cpu())  \n",
    "\n",
    "                # for m in controller.traced_model.modules():\n",
    "                #     if hasattr(m, \"qdrop\"):\n",
    "                #         temp = torch.rand(1).item()\n",
    "                #         m.qdrop.copy_(temp)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            # raw_logits = controller.traced_model(x)\n",
    "            raw_logits = model(x)\n",
    "\n",
    "            if isinstance(raw_logits, tuple):\n",
    "                logits = raw_logits[0]\n",
    "                freq_maps = raw_logits[1]\n",
    "            else:\n",
    "                logits = raw_logits\n",
    "                freq_maps = None\n",
    "\n",
    "            CE_loss = criterion(logits, y)\n",
    "\n",
    "            # 'features.8.0' in name or 'features.1.0.block.2.0'\n",
    "            # 'features.8.0' in name or \"features.6.2.block.0.0\" in name or \"features.5.1.block.0.0\"\n",
    "            model_spectrum1 = radial_spectrum_2d(act_cache['blocks.7.mlp.depthconv1'], num_rad_bins=16, num_ang_bins=1, mode='magnitude')\n",
    "            # model_spectrum1 = radial_spectrum_2d(freq_maps[\"freq_token\"], num_rad_bins=16, num_ang_bins=8)\n",
    "            # model_spectrum2 = radial_spectrum_2d(freq_maps[\"patch_token\"], num_rad_bins=16, num_ang_bins=8)\n",
    "            # model_spectrum1 = radial_spectrum_2d(freq_maps, num_bins=8)\n",
    "            # model_spectrum2 = radial_spectrum_2d(act_cache['features.1.0.block.2.0'], num_bins=32)\n",
    "            # model_spectrum3 = radial_spectrum_2d(act_cache['features.5.1.block.0.0'], num_bins=16)\n",
    "            target_spectrum = radial_spectrum_2d(x, num_rad_bins=16, num_ang_bins=1, mode='magnitude')\n",
    "            # target_spectrum2 = radial_spectrum_2d(x, num_rad_bins=32, num_ang_bins=32)\n",
    "            # model_spectrum = radial_spectrum_2d_channelwise_dct(act, num_bins=16)\n",
    "            # target_spectrum = radial_spectrum_2d_channelwise_dct(x, num_bins=16).detach()\n",
    "\n",
    "            freq_loss1 = wasserstein(model_spectrum1, target_spectrum)\n",
    "            # freq_loss2 = wasserstein_1d(model_spectrum2, target_spectrum)\n",
    "            # freq_loss3 = wasserstein_1d(model_spectrum3, target_spectrum)\n",
    "            # freq_loss1 = kl_div_spectrum(target_spectrum, model_spectrum1)\n",
    "            # freq_loss = temp_kl(target_spectrum, model_spectrum)\n",
    "            # freq_loss = vit_spectral_slope_loss(act)\n",
    "            # freq_loss = local_freq_kl_loss(act, x)\n",
    "            # freq_loss = act_freq_loss(act, x, num_bins=8)\n",
    "            # freq_loss1 = freq_maps[\"anchor_loss\"]\n",
    "            # freq_loss1 = freq_maps.get(\"anchor_loss\",0) + freq_maps.get(\"usage_reg\",0)\n",
    "\n",
    "            # freq_loss = polar_wasserstein_rtheta(model_spectrum, target_spectrum)\n",
    "            \n",
    "            # global_step += 1\n",
    "            # w = freq_weight(global_step, warmup_steps=100, max_w=1.0)\n",
    "\n",
    "            # cache = PolarBinCache()\n",
    "\n",
    "            # polar_s = polar_spectrum_2d(\n",
    "            #     act, num_bins=32, num_theta_bins=64, remove_dc=True, power=True, bin_cache=cache\n",
    "            # )\n",
    "            # polar_t = polar_spectrum_2d(\n",
    "            #     x, num_bins=32, num_theta_bins=64, remove_dc=True, power=True, bin_cache=cache\n",
    "            # )\n",
    "\n",
    "            # freq_loss = polar_kl_loss(polar_s, polar_t, T=1.5, k_low=12)       # strong + fast\n",
    "            # freq_loss = lf_hf_logratio_loss(polar_s, polar_t, k_low=12)\n",
    "\n",
    "            w = 1.0\n",
    "            # w = w * (CE_loss.detach() / (freq_loss.detach() + 1e-8))  # keep terms balanced\n",
    "            loss = CE_loss + w * freq_loss1\n",
    "            # freq_loss.backward()\n",
    "            # loss = CE_loss\n",
    "            # loss = freq_loss1\n",
    "            \n",
    "\n",
    "            # debug_check_grads_and_step(controller.traced_model, opt)\n",
    "            # inject_grad_noise_large_batch(controller.traced_model, step, batch_size, len(train_loader))\n",
    "            # inject_grad_noise_large_batch(model, step, batch_size, len(train_loader))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            # scheduler.step()     \n",
    "            \n",
    "            # if step % 20 == 0:\n",
    "            #     temp = torch.nn.utils.parameters_to_vector(p.reshape(-1) for p in controller.traced_model.parameters() if p.grad is not None)\n",
    "            #     # temp = torch.nn.utils.parameters_to_vector(p.reshape(-1) for p in model.parameters() if p.grad is not None)\n",
    "            #     G.append(temp)     \n",
    "                \n",
    "            e_timer_end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            partile_time += e_timer_start.elapsed_time(e_timer_end)\n",
    "\n",
    "            train_logits.append(logits.detach().cpu())\n",
    "            train_y.append(y.detach().cpu())\n",
    "\n",
    "                # print(\"train logits mean:\", logits.mean().item())\n",
    "                # print(\"train logits std:\", logits.std().item())\n",
    "\n",
    "    # partile_time = e_timer_start.elapsed_time(e_timer_end)\n",
    "    # total_time += e_timer_start.elapsed_time(e_timer_end)\n",
    "\n",
    "\n",
    "    train_logits = torch.cat(train_logits)\n",
    "    train_y = torch.cat(train_y)\n",
    "    computed_acc = acc(train_logits, train_y)\n",
    "    throughtout = 50000 / (partile_time / 1000)\n",
    "\n",
    "    # temp_G = torch.cat(G)\n",
    "    # GNS = gradient_noise_scale(temp_G)\n",
    "    # SNR = signal_to_noise_ratio(temp_G)\n",
    "\n",
    "    print(f'Epoch: {i}')\n",
    "    print(f\"Train Loss: {loss}\")\n",
    "    print(f\"CE Loss: {CE_loss.item()}, Freq(freq) Loss1: {freq_loss1.item() * w}\")\n",
    "    # print(f\"CE Loss: {CE_loss.item()}\")\n",
    "    print(f\"Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "    print(f\"Train Accuracy: {computed_acc}\")\n",
    "    print(f'Peak Mem Reserved: {torch.cuda.max_memory_reserved()}')\n",
    "    print(f'Peak Mem Allocated: {torch.cuda.max_memory_allocated()}')\n",
    "    print(f'Current train time: {partile_time / 1000} s')\n",
    "    print(f\"Throughout: {throughtout} samples per second\")\n",
    "    # for name, m in controller.traced_model.named_modules():\n",
    "    #     if isinstance(m, DOBatchNormReLU2d):\n",
    "    #         if not torch.isfinite(m.running_mean).all() or not torch.isfinite(m.running_var).all():\n",
    "    #             print(\"BAD BN:\", name)\n",
    "    #             print(\"mean finite:\", torch.isfinite(m.running_mean).all().item(),\n",
    "    #                 \"var finite:\", torch.isfinite(m.running_var).all().item(),\n",
    "    #                 \"var min:\", m.running_var.min().item())\n",
    "    #             break\n",
    "    # print(f'GNS: {GNS}')\n",
    "    # print(f'SNR: {SNR}')\n",
    "    # G_GNS.append(GNS)\n",
    "    # G_SNR.append(SNR)\n",
    "    scheduler.step()\n",
    "    # update_lr(controller.traced_model, scheduler)\n",
    "\n",
    "    train_logits = []\n",
    "    train_y = []\n",
    "\n",
    "    # controller.traced_model.eval()\n",
    "    model.eval()\n",
    "    # aot_model.eval()\n",
    "    with torch.compiler.set_stance(\"force_eager\"):\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to('cuda'), y_val.to('cuda')\n",
    "\n",
    "                with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=True):\n",
    "                    # raw_y_preds  = controller.traced_model(x_val)\n",
    "                    raw_y_preds = model(x_val)\n",
    "\n",
    "                    if isinstance(raw_y_preds, tuple):\n",
    "                        y_preds = raw_y_preds[0]\n",
    "                    else:\n",
    "                        y_preds = raw_y_preds\n",
    "\n",
    "                val_loss = F.cross_entropy(y_preds, y_val)\n",
    "\n",
    "                val_logits.append(y_preds.detach().cpu())\n",
    "                val_y.append(y_val.detach().cpu())\n",
    "\n",
    "    val_logits = torch.cat(val_logits)\n",
    "    val_y = torch.cat(val_y)\n",
    "    \n",
    "\n",
    "    valid_computed_acc = acc(val_logits, val_y)\n",
    "    # max_acc = checkpoint_save_helper(controller.traced_model, valid_computed_acc, max_acc, opt)\n",
    "    print(f\"Val Loss: {val_loss}\")\n",
    "    print(f\"Val Accuracy: {valid_computed_acc}\\n\\n\")\n",
    "\n",
    "\n",
    "total_timer_end.record()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "full_time = total_timer_start.elapsed_time(total_timer_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198c372c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1577900566.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Train Loss: 2.1261978149414062\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 2.1261978149414062\n",
    "CE Loss: 2.0997085571289062, Freq Loss: 0.0264892578125\n",
    "Learning Rate: 0.0004\n",
    "Train Accuracy: 0.15813705325126648\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 6875020800\n",
    "Current train time: 63.0915924987793 s\n",
    "Throughout: 792.4986201761733 samples per second\n",
    "Val Loss: 2.0625\n",
    "Val Accuracy: 0.23239998519420624\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 2.038616180419922\n",
    "CE Loss: 2.016033172607422, Freq Loss: 0.0225830078125\n",
    "Learning Rate: 0.00041600000000000003\n",
    "Train Accuracy: 0.2195732593536377\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.206503173828125 s\n",
    "Throughout: 1131.0553065776494 samples per second\n",
    "Val Loss: 1.765625\n",
    "Val Accuracy: 0.31839999556541443\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 1.939453125\n",
    "CE Loss: 1.9161376953125, Freq Loss: 0.0233154296875\n",
    "Learning Rate: 0.0004320000000000001\n",
    "Train Accuracy: 0.26298731565475464\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.21969369506836 s\n",
    "Throughout: 1130.7179182377804 samples per second\n",
    "Val Loss: 1.625\n",
    "Val Accuracy: 0.38350003957748413\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.8823909759521484\n",
    "CE Loss: 1.8601741790771484, Freq Loss: 0.022216796875\n",
    "Learning Rate: 0.00044800000000000005\n",
    "Train Accuracy: 0.3026961088180542\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.10707327270508 s\n",
    "Throughout: 1133.6050272676255 samples per second\n",
    "Val Loss: 1.5078125\n",
    "Val Accuracy: 0.4239000082015991\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.8371562957763672\n",
    "CE Loss: 1.8153057098388672, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.0004640000000000001\n",
    "Train Accuracy: 0.3301789462566376\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 45.0461745300293 s\n",
    "Throughout: 1109.9721679288953 samples per second\n",
    "Val Loss: 1.4609375\n",
    "Val Accuracy: 0.45670002698898315\n",
    "\n",
    "\n",
    "Epoch: 5\n",
    "Train Loss: 1.7238731384277344\n",
    "CE Loss: 1.7022666931152344, Freq Loss: 0.0216064453125\n",
    "Learning Rate: 0.0004800000000000001\n",
    "Train Accuracy: 0.361682265996933\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.26400375366211 s\n",
    "Throughout: 1129.5860238549553 samples per second\n",
    "Val Loss: 1.4140625\n",
    "Val Accuracy: 0.49320000410079956\n",
    "\n",
    "\n",
    "Epoch: 6\n",
    "Train Loss: 1.7163701057434082\n",
    "CE Loss: 1.6940312385559082, Freq Loss: 0.0223388671875\n",
    "Learning Rate: 0.0004960000000000001\n",
    "Train Accuracy: 0.388952374458313\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.06972479248047 s\n",
    "Throughout: 1134.5657417976752 samples per second\n",
    "Val Loss: 1.3125\n",
    "Val Accuracy: 0.5007999539375305\n",
    "\n",
    "\n",
    "Epoch: 7\n",
    "Train Loss: 1.7100353240966797\n",
    "CE Loss: 1.6885509490966797, Freq Loss: 0.021484375\n",
    "Learning Rate: 0.0005120000000000001\n",
    "Train Accuracy: 0.42148837447166443\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.114796051025394 s\n",
    "Throughout: 1133.4065772891138 samples per second\n",
    "Val Loss: 1.2734375\n",
    "Val Accuracy: 0.5416999459266663\n",
    "\n",
    "\n",
    "Epoch: 8\n",
    "Train Loss: 1.5519883632659912\n",
    "CE Loss: 1.5305039882659912, Freq Loss: 0.021484375\n",
    "Learning Rate: 0.000528\n",
    "Train Accuracy: 0.44404399394989014\n",
    "Peak Mem Reserved: 10240393216\n",
    "Peak Mem Allocated: 7038803968\n",
    "Current train time: 44.62808120727539 s\n",
    "Throughout: 1120.370821406699 samples per second\n",
    "Val Loss: 1.3203125\n",
    "Val Accuracy: 0.5544000267982483\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3c4e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "controller.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051ca62",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 2.0204086303710938\n",
    "CE Loss: 2.0204086303710938\n",
    "Learning Rate: 3.0000000000000004e-05\n",
    "Train Accuracy: 0.19953462481498718\n",
    "Peak Mem Reserved: 27648851968\n",
    "Peak Mem Allocated: 26464001024\n",
    "Current train time: 34.63649951171875 s\n",
    "Throughout: 1443.5638908338076 samples per second\n",
    "Val Loss: 1.78125\n",
    "Val Accuracy: 0.31870001554489136\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 1.8824348449707031\n",
    "CE Loss: 1.8824348449707031\n",
    "Learning Rate: 0.00012\n",
    "Train Accuracy: 0.2547570466995239\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.778107513427734 s\n",
    "Throughout: 1624.5313321550464 samples per second\n",
    "Val Loss: 1.6953125\n",
    "Val Accuracy: 0.3573000133037567\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 1.8131141662597656\n",
    "CE Loss: 1.8131141662597656\n",
    "Learning Rate: 0.00021\n",
    "Train Accuracy: 0.31078386306762695\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.613320495605468 s\n",
    "Throughout: 1633.2759462397255 samples per second\n",
    "/home/hice1/yyu496/.conda/envs/lib/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
    "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
    "Val Loss: 1.6015625\n",
    "Val Accuracy: 0.3857000172138214\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.6698455810546875\n",
    "CE Loss: 1.6698455810546875\n",
    "Learning Rate: 0.00030000000000000003\n",
    "Train Accuracy: 0.34447360038757324\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.608947814941406 s\n",
    "Throughout: 1633.5092699786653 samples per second\n",
    "Val Loss: 1.390625\n",
    "Val Accuracy: 0.48270002007484436\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.589508056640625\n",
    "CE Loss: 1.589508056640625\n",
    "Learning Rate: 0.00029999723814541575\n",
    "Train Accuracy: 0.3940315246582031\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.61799234008789 s\n",
    "Throughout: 1633.0267329296898 samples per second\n",
    "Val Loss: 1.3046875\n",
    "Val Accuracy: 0.5138000249862671\n",
    "\n",
    "\n",
    "Epoch: 5\n",
    "Train Loss: 1.5945444107055664\n",
    "CE Loss: 1.5945444107055664\n",
    "Learning Rate: 0.0002999889526868746\n",
    "Train Accuracy: 0.41792812943458557\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.601851348876952 s\n",
    "Throughout: 1633.888075266235 samples per second\n",
    "Val Loss: 1.3515625\n",
    "Val Accuracy: 0.5182999968528748\n",
    "\n",
    "\n",
    "Epoch: 6\n",
    "Train Loss: 1.496464729309082\n",
    "CE Loss: 1.496464729309082\n",
    "Learning Rate: 0.0002999751439400074\n",
    "Train Accuracy: 0.4448806643486023\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 31.114970428466798 s\n",
    "Throughout: 1606.9435166248934 samples per second\n",
    "Val Loss: 1.265625\n",
    "Val Accuracy: 0.5572999119758606\n",
    "\n",
    "\n",
    "Epoch: 7\n",
    "Train Loss: 1.44968581199646\n",
    "CE Loss: 1.44968581199646\n",
    "Learning Rate: 0.000299955812430852\n",
    "Train Accuracy: 0.46641361713409424\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.606640563964845 s\n",
    "Throughout: 1633.6324104406349 samples per second\n",
    "Val Loss: 1.1875\n",
    "Val Accuracy: 0.566800057888031\n",
    "\n",
    "\n",
    "Epoch: 8\n",
    "Train Loss: 1.4654741287231445\n",
    "CE Loss: 1.4654741287231445\n",
    "Learning Rate: 0.00029993095889583346\n",
    "Train Accuracy: 0.4787924587726593\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.597997955322267 s\n",
    "Throughout: 1634.0938408129712 samples per second\n",
    "Val Loss: 1.21875\n",
    "Val Accuracy: 0.5699999928474426\n",
    "\n",
    "\n",
    "Epoch: 9\n",
    "Train Loss: 1.3801345825195312\n",
    "CE Loss: 1.3801345825195312\n",
    "Learning Rate: 0.000299900584281736\n",
    "Train Accuracy: 0.4986399710178375\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.598928466796874 s\n",
    "Throughout: 1634.0441481228786 samples per second\n",
    "Val Loss: 1.140625\n",
    "Val Accuracy: 0.5840999484062195\n",
    "\n",
    "\n",
    "Epoch: 10\n",
    "Train Loss: 1.3266618251800537\n",
    "CE Loss: 1.3266618251800537\n",
    "Learning Rate: 0.00029986468974566667\n",
    "Train Accuracy: 0.5131911635398865\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.615754669189453 s\n",
    "Throughout: 1633.1460890075045 samples per second\n",
    "Val Loss: 1.203125\n",
    "Val Accuracy: 0.5795000195503235\n",
    "\n",
    "\n",
    "Epoch: 11\n",
    "Train Loss: 1.4000189304351807\n",
    "CE Loss: 1.4000189304351807\n",
    "Learning Rate: 0.00029982327665501157\n",
    "Train Accuracy: 0.528613805770874\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.606928527832032 s\n",
    "Throughout: 1633.617040485886 samples per second\n",
    "Val Loss: 1.109375\n",
    "Val Accuracy: 0.6019999980926514\n",
    "\n",
    "\n",
    "Epoch: 12\n",
    "Train Loss: 1.2096363306045532\n",
    "CE Loss: 1.2096363306045532\n",
    "Learning Rate: 0.00029977634658738355\n",
    "Train Accuracy: 0.5367401242256165\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.592514007568358 s\n",
    "Throughout: 1634.3867649330937 samples per second\n",
    "Val Loss: 1.1875\n",
    "Val Accuracy: 0.6022999882698059\n",
    "\n",
    "\n",
    "Epoch: 13\n",
    "Train Loss: 1.2830979824066162\n",
    "CE Loss: 1.2830979824066162\n",
    "Learning Rate: 0.0002997239013305623\n",
    "Train Accuracy: 0.5472036600112915\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.602636810302734 s\n",
    "Throughout: 1633.8461391394521 samples per second\n",
    "Val Loss: 0.99609375\n",
    "Val Accuracy: 0.652999997138977\n",
    "\n",
    "\n",
    "Epoch: 14\n",
    "Train Loss: 1.1729369163513184\n",
    "CE Loss: 1.1729369163513184\n",
    "Learning Rate: 0.000299665942882426\n",
    "Train Accuracy: 0.5562751889228821\n",
    "Peak Mem Reserved: 28089253888\n",
    "Peak Mem Allocated: 26627784192\n",
    "Current train time: 30.595804107666016 s\n",
    "Throughout: 1634.2110122045171 samples per second\n",
    "Val Loss: 1.03125\n",
    "Val Accuracy: 0.6360999941825867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505af4d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 1.9045333862304688\n",
    "CE Loss: 1.8829269409179688, Freq Loss: 0.0216064453125\n",
    "Learning Rate: 0.0004\n",
    "Train Accuracy: 0.2390061914920807\n",
    "Peak Mem Reserved: 9544138752\n",
    "Peak Mem Allocated: 6891101696\n",
    "Current train time: 42.02726989746094 s\n",
    "Throughout: 1189.7037357408917 samples per second\n",
    "Val Loss: 1.734375\n",
    "Val Accuracy: 0.36089998483657837\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 1.6597986221313477\n",
    "CE Loss: 1.6379480361938477, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.00041600000000000003\n",
    "Train Accuracy: 0.3497304320335388\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.644499908447266 s\n",
    "Throughout: 1686.6535159782673 samples per second\n",
    "Val Loss: 1.4375\n",
    "Val Accuracy: 0.47850000858306885\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 1.563159465789795\n",
    "CE Loss: 1.540820598602295, Freq Loss: 0.0223388671875\n",
    "Learning Rate: 0.0004320000000000001\n",
    "Train Accuracy: 0.4164164066314697\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 30.015953643798827 s\n",
    "Throughout: 1665.7808242027918 samples per second\n",
    "Val Loss: 1.296875\n",
    "Val Accuracy: 0.5196999907493591\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.47509765625\n",
    "CE Loss: 1.4534912109375, Freq Loss: 0.0216064453125\n",
    "Learning Rate: 0.00044800000000000005\n",
    "Train Accuracy: 0.4653458297252655\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.964562896728516 s\n",
    "Throughout: 1668.6377229103155 samples per second\n",
    "Val Loss: 1.3515625\n",
    "Val Accuracy: 0.5493999719619751\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.3040845394134521\n",
    "CE Loss: 1.2834546566009521, Freq Loss: 0.0206298828125\n",
    "Learning Rate: 0.0004640000000000001\n",
    "Train Accuracy: 0.503715991973877\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.582514770507814 s\n",
    "Throughout: 1690.1876121041382 samples per second\n",
    "Val Loss: 1.125\n",
    "Val Accuracy: 0.6157000064849854\n",
    "\n",
    "\n",
    "Epoch: 5\n",
    "Train Loss: 1.1938207149505615\n",
    "CE Loss: 1.1712377071380615, Freq Loss: 0.0225830078125\n",
    "Learning Rate: 0.0004800000000000001\n",
    "Train Accuracy: 0.5403010249137878\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.67847998046875 s\n",
    "Throughout: 1684.722399290824 samples per second\n",
    "Val Loss: 1.0546875\n",
    "Val Accuracy: 0.6433999538421631\n",
    "\n",
    "\n",
    "Epoch: 6\n",
    "Train Loss: 1.2692553997039795\n",
    "CE Loss: 1.2474048137664795, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.0004960000000000001\n",
    "Train Accuracy: 0.5698992013931274\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.732331970214844 s\n",
    "Throughout: 1681.6709853128518 samples per second\n",
    "Val Loss: 0.9921875\n",
    "Val Accuracy: 0.6561999917030334\n",
    "\n",
    "\n",
    "Epoch: 7\n",
    "Train Loss: 1.1457955837249756\n",
    "CE Loss: 1.1237008571624756, Freq Loss: 0.0220947265625\n",
    "Learning Rate: 0.0005120000000000001\n",
    "Train Accuracy: 0.5942196846008301\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.795576751708985 s\n",
    "Throughout: 1678.101431519769 samples per second\n",
    "Val Loss: 0.87890625\n",
    "Val Accuracy: 0.7031000852584839\n",
    "\n",
    "\n",
    "Epoch: 8\n",
    "Train Loss: 1.0809234380722046\n",
    "CE Loss: 1.0595611333847046, Freq Loss: 0.0213623046875\n",
    "Learning Rate: 0.000528\n",
    "Train Accuracy: 0.6160621643066406\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.909658966064452 s\n",
    "Throughout: 1671.7007725407395 samples per second\n",
    "Val Loss: 0.86328125\n",
    "Val Accuracy: 0.7122999429702759\n",
    "\n",
    "\n",
    "Epoch: 9\n",
    "Train Loss: 1.0484752655029297\n",
    "CE Loss: 1.0272350311279297, Freq Loss: 0.021240234375\n",
    "Learning Rate: 0.000544\n",
    "Train Accuracy: 0.6350563764572144\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 30.036337615966797 s\n",
    "Throughout: 1664.6503524924046 samples per second\n",
    "Val Loss: 0.8515625\n",
    "Val Accuracy: 0.7229999899864197\n",
    "\n",
    "\n",
    "Epoch: 10\n",
    "Train Loss: 1.1214923858642578\n",
    "CE Loss: 1.0984210968017578, Freq Loss: 0.0230712890625\n",
    "Learning Rate: 0.00056\n",
    "Train Accuracy: 0.6488553285598755\n",
    "Peak Mem Reserved: 10194255872\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.445481689453125 s\n",
    "Throughout: 1698.0533898995159 samples per second\n",
    "Val Loss: 0.78125\n",
    "Val Accuracy: 0.7470000386238098\n",
    "\n",
    "\n",
    "Epoch: 11\n",
    "Train Loss: 0.9483517408370972\n",
    "CE Loss: 0.9258908033370972, Freq Loss: 0.0224609375\n",
    "Learning Rate: 0.0005759999999999999\n",
    "Train Accuracy: 0.6640090942382812\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.650903198242187 s\n",
    "Throughout: 1686.2892730688952 samples per second\n",
    "Val Loss: 0.8125\n",
    "Val Accuracy: 0.7394000291824341\n",
    "\n",
    "\n",
    "Epoch: 12\n",
    "Train Loss: 0.9587233662605286\n",
    "CE Loss: 0.9379714131355286, Freq Loss: 0.020751953125\n",
    "Learning Rate: 0.0005919999999999999\n",
    "Train Accuracy: 0.671798050403595\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.906405731201172 s\n",
    "Throughout: 1671.8826210478146 samples per second\n",
    "Val Loss: 0.80078125\n",
    "Val Accuracy: 0.7578000426292419\n",
    "\n",
    "\n",
    "Epoch: 13\n",
    "Train Loss: 0.9989405870437622\n",
    "CE Loss: 0.9780665636062622, Freq Loss: 0.0208740234375\n",
    "Learning Rate: 0.0006079999999999998\n",
    "Train Accuracy: 0.6846007108688354\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.945278594970702 s\n",
    "Throughout: 1669.7123001018758 samples per second\n",
    "Val Loss: 0.65234375\n",
    "Val Accuracy: 0.7644000053405762\n",
    "\n",
    "\n",
    "Epoch: 14\n",
    "Train Loss: 0.9170495271682739\n",
    "CE Loss: 0.8961755037307739, Freq Loss: 0.0208740234375\n",
    "Learning Rate: 0.0006239999999999999\n",
    "Train Accuracy: 0.6935915350914001\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.657180267333985 s\n",
    "Throughout: 1685.9323627294632 samples per second\n",
    "Val Loss: 0.68359375\n",
    "Val Accuracy: 0.776199996471405\n",
    "\n",
    "\n",
    "Epoch: 15\n",
    "Train Loss: 0.9113831520080566\n",
    "CE Loss: 0.8897767066955566, Freq Loss: 0.0216064453125\n",
    "Learning Rate: 0.0006399999999999998\n",
    "Train Accuracy: 0.6990640163421631\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.358371978759767 s\n",
    "Throughout: 1703.0917121758 samples per second\n",
    "Val Loss: 0.6328125\n",
    "Val Accuracy: 0.7851999998092651\n",
    "\n",
    "\n",
    "Epoch: 16\n",
    "Train Loss: 0.7893111109733582\n",
    "CE Loss: 0.7670943140983582, Freq Loss: 0.022216796875\n",
    "Learning Rate: 0.0006559999999999998\n",
    "Train Accuracy: 0.7096731066703796\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 30.126253051757814 s\n",
    "Throughout: 1659.6820027402175 samples per second\n",
    "Val Loss: 0.69921875\n",
    "Val Accuracy: 0.7835999727249146\n",
    "\n",
    "\n",
    "Epoch: 17\n",
    "Train Loss: 0.8384559154510498\n",
    "CE Loss: 0.8168494701385498, Freq Loss: 0.0216064453125\n",
    "Learning Rate: 0.0006719999999999997\n",
    "Train Accuracy: 0.7116010189056396\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 30.51877737426758 s\n",
    "Throughout: 1638.3356183252067 samples per second\n",
    "Val Loss: 0.67578125\n",
    "Val Accuracy: 0.7857000827789307\n",
    "\n",
    "\n",
    "Epoch: 18\n",
    "Train Loss: 0.8948007822036743\n",
    "CE Loss: 0.8728281259536743, Freq Loss: 0.02197265625\n",
    "Learning Rate: 0.0006879999999999997\n",
    "Train Accuracy: 0.717888593673706\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.180453094482424 s\n",
    "Throughout: 1713.47579278864 samples per second\n",
    "Val Loss: 0.56640625\n",
    "Val Accuracy: 0.7947999835014343\n",
    "\n",
    "\n",
    "Epoch: 19\n",
    "Train Loss: 0.8306549787521362\n",
    "CE Loss: 0.8099030256271362, Freq Loss: 0.020751953125\n",
    "Learning Rate: 0.0007039999999999998\n",
    "Train Accuracy: 0.7262073755264282\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.970761840820312 s\n",
    "Throughout: 1668.2925934802156 samples per second\n",
    "Val Loss: 0.59375\n",
    "Val Accuracy: 0.8078001141548157\n",
    "\n",
    "\n",
    "Epoch: 20\n",
    "Train Loss: 0.8981999754905701\n",
    "CE Loss: 0.8763493895530701, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.0007199999999999997\n",
    "Train Accuracy: 0.7332481145858765\n",
    "Peak Mem Reserved: 10236198912\n",
    "Peak Mem Allocated: 7054884864\n",
    "Current train time: 29.82004916381836 s\n",
    "Throughout: 1676.7242644477808 samples per second\n",
    "Val Loss: 0.5703125\n",
    "Val Accuracy: 0.801800012588501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8fc20",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for n, m in controller.traced_model.named_modules():\n",
    "    if isinstance(m, (DOConv2d, DOLinear)):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05598011",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "controller.init_acc_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d64f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 2.0159902572631836\n",
    "CE Loss: 2.0147390365600586, Freq Loss: 0.001251220703125\n",
    "Learning Rate: 0.0004\n",
    "Train Accuracy: 0.2260379195213318\n",
    "Peak Mem Reserved: 26833059840\n",
    "Peak Mem Allocated: 26671563776\n",
    "Current train time: 42.80251544189453 s\n",
    "Throughout: 1168.1556442138601 samples per second\n",
    "Val Loss: 1.6875\n",
    "Val Accuracy: 0.3934999704360962\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 1.8517332077026367\n",
    "CE Loss: 1.851038932800293, Freq Loss: 0.00069427490234375\n",
    "Learning Rate: 0.00041600000000000003\n",
    "Train Accuracy: 0.34172680974006653\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 30.560564727783202 s\n",
    "Throughout: 1636.09542053207 samples per second\n",
    "Val Loss: 1.5\n",
    "Val Accuracy: 0.45990002155303955\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 1.6418410539627075\n",
    "CE Loss: 1.64130699634552, Freq Loss: 0.0005340576171875\n",
    "Learning Rate: 0.0004320000000000001\n",
    "Train Accuracy: 0.4238045811653137\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.61539227294922 s\n",
    "Throughout: 1688.3112517699162 samples per second\n",
    "Val Loss: 1.328125\n",
    "Val Accuracy: 0.5654000043869019\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.5153136253356934\n",
    "CE Loss: 1.51485013961792, Freq Loss: 0.0004634857177734375\n",
    "Learning Rate: 0.00044800000000000005\n",
    "Train Accuracy: 0.4903367757797241\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.604291748046876 s\n",
    "Throughout: 1688.9443066409017 samples per second\n",
    "Val Loss: 1.15625\n",
    "Val Accuracy: 0.614799976348877\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.45391845703125\n",
    "CE Loss: 1.4534492492675781, Freq Loss: 0.000469207763671875\n",
    "Learning Rate: 0.0004640000000000001\n",
    "Train Accuracy: 0.5410183072090149\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.813560211181642 s\n",
    "Throughout: 1677.0892052418278 samples per second\n",
    "Val Loss: 1.0546875\n",
    "Val Accuracy: 0.6564000248908997\n",
    "\n",
    "\n",
    "Epoch: 5\n",
    "Train Loss: 1.4149445295333862\n",
    "CE Loss: 1.414528727531433, Freq Loss: 0.000415802001953125\n",
    "Learning Rate: 0.0004800000000000001\n",
    "Train Accuracy: 0.5802582502365112\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.246568756103514 s\n",
    "Throughout: 1709.602258540685 samples per second\n",
    "Val Loss: 0.96484375\n",
    "Val Accuracy: 0.6853000521659851\n",
    "\n",
    "\n",
    "Epoch: 6\n",
    "Train Loss: 1.3319803476333618\n",
    "CE Loss: 1.3314844369888306, Freq Loss: 0.00049591064453125\n",
    "Learning Rate: 0.0004960000000000001\n",
    "Train Accuracy: 0.6139059662818909\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.415003631591798 s\n",
    "Throughout: 1699.8128107079292 samples per second\n",
    "Val Loss: 0.89453125\n",
    "Val Accuracy: 0.7192999720573425\n",
    "\n",
    "\n",
    "Epoch: 7\n",
    "Train Loss: 1.238694190979004\n",
    "CE Loss: 1.2382097244262695, Freq Loss: 0.000484466552734375\n",
    "Learning Rate: 0.0005120000000000001\n",
    "Train Accuracy: 0.6393776535987854\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.029764465332033 s\n",
    "Throughout: 1722.370157694909 samples per second\n",
    "Val Loss: 0.88671875\n",
    "Val Accuracy: 0.7364000082015991\n",
    "\n",
    "\n",
    "Epoch: 8\n",
    "Train Loss: 1.281731128692627\n",
    "CE Loss: 1.2812199592590332, Freq Loss: 0.00051116943359375\n",
    "Learning Rate: 0.000528\n",
    "Train Accuracy: 0.6619654893875122\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 30.283424713134767 s\n",
    "Throughout: 1651.06821548864 samples per second\n",
    "Val Loss: 0.76171875\n",
    "Val Accuracy: 0.7518000602722168\n",
    "\n",
    "\n",
    "Epoch: 9\n",
    "Train Loss: 1.2240803241729736\n",
    "CE Loss: 1.2235958576202393, Freq Loss: 0.000484466552734375\n",
    "Learning Rate: 0.000544\n",
    "Train Accuracy: 0.6812035441398621\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 29.512437561035156 s\n",
    "Throughout: 1694.2009583787913 samples per second\n",
    "Val Loss: 0.69921875\n",
    "Val Accuracy: 0.7717999815940857\n",
    "\n",
    "\n",
    "Epoch: 10\n",
    "Train Loss: 1.166072130203247\n",
    "CE Loss: 1.1657040119171143, Freq Loss: 0.0003681182861328125\n",
    "Learning Rate: 0.00056\n",
    "Train Accuracy: 0.6928081512451172\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 30.05364080810547 s\n",
    "Throughout: 1663.6919406621441 samples per second\n",
    "Val Loss: 0.7265625\n",
    "Val Accuracy: 0.7827000617980957\n",
    "\n",
    "\n",
    "Epoch: 11\n",
    "Train Loss: 1.183124303817749\n",
    "CE Loss: 1.1826531887054443, Freq Loss: 0.0004711151123046875\n",
    "Learning Rate: 0.0005759999999999999\n",
    "Train Accuracy: 0.7089468836784363\n",
    "Peak Mem Reserved: 27015512064\n",
    "Peak Mem Allocated: 26824751616\n",
    "Current train time: 30.691831298828124 s\n",
    "Throughout: 1629.0979678983542 samples per second\n",
    "Val Loss: 0.66015625\n",
    "Val Accuracy: 0.8001999855041504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2a0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 1.972098469734192\n",
    "CE Loss: 1.947684407234192, Freq Loss: 0.0244140625\n",
    "Learning Rate: 0.0004\n",
    "Train Accuracy: 0.2394513040781021\n",
    "Peak Mem Reserved: 26042433536\n",
    "Peak Mem Allocated: 25853588480\n",
    "Current train time: 39.60026376342773 s\n",
    "Throughout: 1262.6178527168497 samples per second\n",
    "Val Loss: 1.75\n",
    "Val Accuracy: 0.326200008392334\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 1.7997024059295654\n",
    "CE Loss: 1.7756545543670654, Freq Loss: 0.0240478515625\n",
    "Learning Rate: 0.00041600000000000003\n",
    "Train Accuracy: 0.3568476140499115\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 29.502670318603517 s\n",
    "Throughout: 1694.7618456242406 samples per second\n",
    "Val Loss: 1.46875\n",
    "Val Accuracy: 0.4838999807834625\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 1.6860631704330444\n",
    "CE Loss: 1.6638463735580444, Freq Loss: 0.022216796875\n",
    "Learning Rate: 0.0004320000000000001\n",
    "Train Accuracy: 0.4278605282306671\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 28.261893188476563 s\n",
    "Throughout: 1769.166689101595 samples per second\n",
    "Val Loss: 1.3671875\n",
    "Val Accuracy: 0.5310999751091003\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.5963082313537598\n",
    "CE Loss: 1.5745797157287598, Freq Loss: 0.021728515625\n",
    "Learning Rate: 0.00044800000000000005\n",
    "Train Accuracy: 0.4847506284713745\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 29.090908630371093 s\n",
    "Throughout: 1718.7500272095208 samples per second\n",
    "Val Loss: 1.25\n",
    "Val Accuracy: 0.6098999977111816\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.4873754978179932\n",
    "CE Loss: 1.4660131931304932, Freq Loss: 0.0213623046875\n",
    "Learning Rate: 0.0004640000000000001\n",
    "Train Accuracy: 0.5255968570709229\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 29.415791107177736 s\n",
    "Throughout: 1699.7673058604064 samples per second\n",
    "Val Loss: 1.1796875\n",
    "Val Accuracy: 0.6085999608039856\n",
    "\n",
    "\n",
    "Epoch: 5\n",
    "Train Loss: 1.44301438331604\n",
    "CE Loss: 1.42067551612854, Freq Loss: 0.0223388671875\n",
    "Learning Rate: 0.0004800000000000001\n",
    "Train Accuracy: 0.5670493841171265\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 28.817663848876954 s\n",
    "Throughout: 1735.0469580811819 samples per second\n",
    "Val Loss: 1.0390625\n",
    "Val Accuracy: 0.6661999225616455\n",
    "\n",
    "\n",
    "Epoch: 6\n",
    "Train Loss: 1.4052331447601318\n",
    "CE Loss: 1.3835046291351318, Freq Loss: 0.021728515625\n",
    "Learning Rate: 0.0004960000000000001\n",
    "Train Accuracy: 0.5971462726593018\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 28.694834228515624 s\n",
    "Throughout: 1742.473910175521 samples per second\n",
    "Val Loss: 0.9765625\n",
    "Val Accuracy: 0.6917000412940979\n",
    "\n",
    "\n",
    "Epoch: 7\n",
    "Train Loss: 1.3891098499298096\n",
    "CE Loss: 1.3667709827423096, Freq Loss: 0.0223388671875\n",
    "Learning Rate: 0.0005120000000000001\n",
    "Train Accuracy: 0.6229101419448853\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 28.827572143554686 s\n",
    "Throughout: 1734.4506069054823 samples per second\n",
    "Val Loss: 0.91015625\n",
    "Val Accuracy: 0.6922000050544739\n",
    "\n",
    "\n",
    "Epoch: 8\n",
    "Train Loss: 1.3049952983856201\n",
    "CE Loss: 1.2841212749481201, Freq Loss: 0.0208740234375\n",
    "Learning Rate: 0.000528\n",
    "Train Accuracy: 0.6431524157524109\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 28.97141421508789 s\n",
    "Throughout: 1725.8391195125273 samples per second\n",
    "Val Loss: 0.8203125\n",
    "Val Accuracy: 0.7429000735282898\n",
    "\n",
    "\n",
    "Epoch: 9\n",
    "Train Loss: 1.2998377084732056\n",
    "CE Loss: 1.2771326303482056, Freq Loss: 0.022705078125\n",
    "Learning Rate: 0.000544\n",
    "Train Accuracy: 0.6578047275543213\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 29.156133239746094 s\n",
    "Throughout: 1714.9050454961985 samples per second\n",
    "Val Loss: 0.83203125\n",
    "Val Accuracy: 0.73580002784729\n",
    "\n",
    "\n",
    "Epoch: 10\n",
    "Train Loss: 1.2484318017959595\n",
    "CE Loss: 1.2259708642959595, Freq Loss: 0.0224609375\n",
    "Learning Rate: 0.00056\n",
    "Train Accuracy: 0.6726032495498657\n",
    "Peak Mem Reserved: 26185039872\n",
    "Peak Mem Allocated: 26006776320\n",
    "Current train time: 29.73736404418945 s\n",
    "Throughout: 1681.3864176293655 samples per second\n",
    "Val Loss: 0.75\n",
    "Val Accuracy: 0.7583000063896179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e211cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 1.8929107189178467\n",
    "CE Loss: 1.8708159923553467, Freq Loss: 0.0220947265625\n",
    "Learning Rate: 0.0004\n",
    "Train Accuracy: 0.25595182180404663\n",
    "Peak Mem Reserved: 26000490496\n",
    "Peak Mem Allocated: 25810187264\n",
    "Current train time: 40.51330209350586 s\n",
    "Throughout: 1234.1625445538498 samples per second\n",
    "Val Loss: 1.640625\n",
    "Val Accuracy: 0.4020000100135803\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 1.8045774698257446\n",
    "CE Loss: 1.7823606729507446, Freq Loss: 0.022216796875\n",
    "Learning Rate: 0.00041600000000000003\n",
    "Train Accuracy: 0.3834226429462433\n",
    "Peak Mem Reserved: 26140999680\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 28.617461181640625 s\n",
    "Throughout: 1747.1850379263283 samples per second\n",
    "Val Loss: 1.4296875\n",
    "Val Accuracy: 0.49400001764297485\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 1.6234170198440552\n",
    "CE Loss: 1.6009560823440552, Freq Loss: 0.0224609375\n",
    "Learning Rate: 0.0004320000000000001\n",
    "Train Accuracy: 0.45989999175071716\n",
    "Peak Mem Reserved: 26140999680\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 28.550537170410156 s\n",
    "Throughout: 1751.2805346380705 samples per second\n",
    "Val Loss: 1.2109375\n",
    "Val Accuracy: 0.5890999436378479\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.5424914360046387\n",
    "CE Loss: 1.5210070610046387, Freq Loss: 0.021484375\n",
    "Learning Rate: 0.00044800000000000005\n",
    "Train Accuracy: 0.5186222791671753\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.0019514465332 s\n",
    "Throughout: 1724.021919427661 samples per second\n",
    "Val Loss: 1.1640625\n",
    "Val Accuracy: 0.6300000548362732\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.4019957780838013\n",
    "CE Loss: 1.3801451921463013, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.0004640000000000001\n",
    "Train Accuracy: 0.5643259286880493\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.172721282958985 s\n",
    "Throughout: 1713.9299249812223 samples per second\n",
    "Val Loss: 1.0390625\n",
    "Val Accuracy: 0.6618999242782593\n",
    "\n",
    "\n",
    "Epoch: 5\n",
    "Train Loss: 1.4317731857299805\n",
    "CE Loss: 1.4106550216674805, Freq Loss: 0.0211181640625\n",
    "Learning Rate: 0.0004800000000000001\n",
    "Train Accuracy: 0.591052770614624\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.450718688964844 s\n",
    "Throughout: 1697.7514378531941 samples per second\n",
    "Val Loss: 0.9921875\n",
    "Val Accuracy: 0.6907999515533447\n",
    "\n",
    "\n",
    "Epoch: 6\n",
    "Train Loss: 1.3509769439697266\n",
    "CE Loss: 1.3298587799072266, Freq Loss: 0.0211181640625\n",
    "Learning Rate: 0.0004960000000000001\n",
    "Train Accuracy: 0.6162897348403931\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 28.403817779541015 s\n",
    "Throughout: 1760.3267415697371 samples per second\n",
    "Val Loss: 0.92578125\n",
    "Val Accuracy: 0.7064999938011169\n",
    "\n",
    "\n",
    "Epoch: 7\n",
    "Train Loss: 1.2641372680664062\n",
    "CE Loss: 1.2414321899414062, Freq Loss: 0.022705078125\n",
    "Learning Rate: 0.0005120000000000001\n",
    "Train Accuracy: 0.6378638744354248\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.14587338256836 s\n",
    "Throughout: 1715.5087220650635 samples per second\n",
    "Val Loss: 0.83984375\n",
    "Val Accuracy: 0.7432000041007996\n",
    "\n",
    "\n",
    "Epoch: 8\n",
    "Train Loss: 1.2883273363113403\n",
    "CE Loss: 1.2672091722488403, Freq Loss: 0.0211181640625\n",
    "Learning Rate: 0.000528\n",
    "Train Accuracy: 0.6589770317077637\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.544981597900392 s\n",
    "Throughout: 1692.3347822817138 samples per second\n",
    "Val Loss: 0.84375\n",
    "Val Accuracy: 0.7507999539375305\n",
    "\n",
    "\n",
    "Epoch: 9\n",
    "Train Loss: 1.2321743965148926\n",
    "CE Loss: 1.2104458808898926, Freq Loss: 0.021728515625\n",
    "Learning Rate: 0.000544\n",
    "Train Accuracy: 0.6728095412254333\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.4812873840332 s\n",
    "Throughout: 1695.991065406443 samples per second\n",
    "Val Loss: 0.80078125\n",
    "Val Accuracy: 0.7387999892234802\n",
    "\n",
    "\n",
    "Epoch: 10\n",
    "Train Loss: 1.0903221368789673\n",
    "CE Loss: 1.0682274103164673, Freq Loss: 0.0220947265625\n",
    "Learning Rate: 0.00056\n",
    "Train Accuracy: 0.6910027265548706\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.68025408935547 s\n",
    "Throughout: 1684.6216966158659 samples per second\n",
    "Val Loss: 0.7578125\n",
    "Val Accuracy: 0.7802000045776367\n",
    "\n",
    "\n",
    "Epoch: 11\n",
    "Train Loss: 1.209557056427002\n",
    "CE Loss: 1.188560962677002, Freq Loss: 0.02099609375\n",
    "Learning Rate: 0.0005759999999999999\n",
    "Train Accuracy: 0.6994066834449768\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 28.971668426513673 s\n",
    "Throughout: 1725.8239761656966 samples per second\n",
    "Val Loss: 0.75390625\n",
    "Val Accuracy: 0.7738000154495239\n",
    "\n",
    "\n",
    "Epoch: 12\n",
    "Train Loss: 1.156912088394165\n",
    "CE Loss: 1.135061502456665, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.0005919999999999999\n",
    "Train Accuracy: 0.7126305103302002\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.605869201660155 s\n",
    "Throughout: 1688.8543166702987 samples per second\n",
    "Val Loss: 0.75\n",
    "Val Accuracy: 0.7758999466896057\n",
    "\n",
    "\n",
    "Epoch: 13\n",
    "Train Loss: 1.1251931190490723\n",
    "CE Loss: 1.1040749549865723, Freq Loss: 0.0211181640625\n",
    "Learning Rate: 0.0006079999999999998\n",
    "Train Accuracy: 0.7202237248420715\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 30.14190576171875 s\n",
    "Throughout: 1658.8201288686168 samples per second\n",
    "Val Loss: 0.671875\n",
    "Val Accuracy: 0.7989000082015991\n",
    "\n",
    "\n",
    "Epoch: 14\n",
    "Train Loss: 1.1366655826568604\n",
    "CE Loss: 1.1149370670318604, Freq Loss: 0.021728515625\n",
    "Learning Rate: 0.0006239999999999999\n",
    "Train Accuracy: 0.7332989573478699\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.04398254394531 s\n",
    "Throughout: 1721.5269952854076 samples per second\n",
    "Val Loss: 0.6328125\n",
    "Val Accuracy: 0.8105000257492065\n",
    "\n",
    "\n",
    "Epoch: 15\n",
    "Train Loss: 1.1325446367263794\n",
    "CE Loss: 1.1110602617263794, Freq Loss: 0.021484375\n",
    "Learning Rate: 0.0006399999999999998\n",
    "Train Accuracy: 0.7374083399772644\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.372983154296875 s\n",
    "Throughout: 1702.2445332620453 samples per second\n",
    "Val Loss: 0.6328125\n",
    "Val Accuracy: 0.814300000667572\n",
    "\n",
    "\n",
    "Epoch: 16\n",
    "Train Loss: 1.0633924007415771\n",
    "CE Loss: 1.0415418148040771, Freq Loss: 0.0218505859375\n",
    "Learning Rate: 0.0006559999999999998\n",
    "Train Accuracy: 0.7451866865158081\n",
    "Peak Mem Reserved: 26164068352\n",
    "Peak Mem Allocated: 25963375104\n",
    "Current train time: 29.934833374023437 s\n",
    "Throughout: 1670.294916135679 samples per second\n",
    "Val Loss: 0.578125\n",
    "Val Accuracy: 0.8251000642776489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315225a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Epoch: 0\n",
    "Train Loss: 2.171717643737793\n",
    "CE Loss: 2.145960807800293, Freq Loss: 0.0257568359375\n",
    "Learning Rate: 0.0004\n",
    "Train Accuracy: 0.16836054623126984\n",
    "Peak Mem Reserved: 26140999680\n",
    "Peak Mem Allocated: 25960837120\n",
    "Current train time: 38.90633868408203 s\n",
    "Throughout: 1285.1376328674376 samples per second\n",
    "Val Loss: 1.90625\n",
    "Val Accuracy: 0.27300000190734863\n",
    "\n",
    "\n",
    "Epoch: 1\n",
    "Train Loss: 2.0348706245422363\n",
    "CE Loss: 2.0111889839172363, Freq Loss: 0.023681640625\n",
    "Learning Rate: 0.00041600000000000003\n",
    "Train Accuracy: 0.2379419505596161\n",
    "Peak Mem Reserved: 26308771840\n",
    "Peak Mem Allocated: 26124620288\n",
    "Current train time: 29.485845733642577 s\n",
    "Throughout: 1695.728874513893 samples per second\n",
    "Val Loss: 1.828125\n",
    "Val Accuracy: 0.32580000162124634\n",
    "\n",
    "\n",
    "Epoch: 2\n",
    "Train Loss: 2.063933849334717\n",
    "CE Loss: 2.040740489959717, Freq Loss: 0.023193359375\n",
    "Learning Rate: 0.0004320000000000001\n",
    "Train Accuracy: 0.2757069170475006\n",
    "Peak Mem Reserved: 26308771840\n",
    "Peak Mem Allocated: 26124620288\n",
    "Current train time: 29.224626525878907 s\n",
    "Throughout: 1710.8858501826924 samples per second\n",
    "Val Loss: 1.6953125\n",
    "Val Accuracy: 0.3812999725341797\n",
    "\n",
    "\n",
    "Epoch: 3\n",
    "Train Loss: 1.9659230709075928\n",
    "CE Loss: 1.9426076412200928, Freq Loss: 0.0233154296875\n",
    "Learning Rate: 0.00044800000000000005\n",
    "Train Accuracy: 0.29685139656066895\n",
    "Peak Mem Reserved: 26308771840\n",
    "Peak Mem Allocated: 26124620288\n",
    "Current train time: 28.638725494384765 s\n",
    "Throughout: 1745.8877494322703 samples per second\n",
    "Val Loss: 1.6875\n",
    "Val Accuracy: 0.3930000066757202\n",
    "\n",
    "\n",
    "Epoch: 4\n",
    "Train Loss: 1.9245011806488037\n",
    "CE Loss: 1.9013078212738037, Freq Loss: 0.023193359375\n",
    "Learning Rate: 0.0004640000000000001\n",
    "Train Accuracy: 0.3301340937614441\n",
    "Peak Mem Reserved: 26308771840\n",
    "Peak Mem Allocated: 26124620288\n",
    "Current train time: 31.603548645019533 s\n",
    "Throughout: 1582.100812842725 samples per second\n",
    "Val Loss: 1.5078125\n",
    "Val Accuracy: 0.45750001072883606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae0b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x, y = next(iter(check_loder))\n",
    "x, y = x.to('cuda'), y.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91bc6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "# torch.set_rng_state(cached_rng_state['CPU'])\n",
    "# torch.cuda.set_rng_state(cached_rng_state['GPU'])\n",
    "num_classes = 10\n",
    "# model = models.resnet18(weights=None)\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = models.efficientnet_b0(weights=None)\n",
    "# model = models.efficientnet_v2_s(weights=None)\n",
    "# model = models.mobilenet_v2(weights=None)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "# model.apply(lambda m: apply_trunc_init_for_act(m, std=0.02))\n",
    "# model.apply(init_fan_out)\n",
    "# model.apply(lambda m: init_orthogonal_conv(m, gain=math.sqrt(2)))  # ReLU-friendly\n",
    "# model.apply(lambda m: init_orthogonal_conv(m, gain=1.0))           # smoother spectrum\n",
    "# model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=10)\n",
    "\n",
    "disable_act_inplace(model)\n",
    "# model.load_state_dict(baseline)\n",
    "# init(model)\n",
    "# for n, m in model.named_modules():\n",
    "#     if isinstance(m, (nn.Conv1d, nn.Conv2d)):\n",
    "#             cahced_init(m.weight)\n",
    "\n",
    "# for n, m in model.named_modules():\n",
    "#     init_orthogonal_conv(n, m, gain=1.0)\n",
    "\n",
    "# for m in model.modules():\n",
    "#     if isinstance(m, nn.Conv2d) and m.kernel_size == (1, 1):\n",
    "#         spectral_norm(m)\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec11ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/hice1/yyu496/scratch/Model_Checkpoint/ResNet18_bs_8192_acc_89\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57026e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "activation_cache.clear()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bac2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "activation_cache = {}\n",
    "low_frequency_energy_ratio_grad = {}\n",
    "low_frequency_energy_ratio_act = {}\n",
    "\n",
    "\n",
    "def forward_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        activation_cache[name] = output.detach().cpu()\n",
    "    return hook\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_lfer_act(x, k=4):\n",
    "    if x.ndim == 4:\n",
    "        H, W = x.shape[-2:]\n",
    "        k = min(k, H, W)\n",
    "        x_lp = F.interpolate(F.avg_pool2d(x, kernel_size=k, stride=k, padding=0), size=x.shape[-2:], mode='nearest')\n",
    "        return (x_lp.square().sum() / (x.square().sum() + 1e-7)).item()\n",
    "    else:\n",
    "        feature_dim = x.shape[-1]\n",
    "        k = min(k, feature_dim)\n",
    "        if x.ndim != 2:\n",
    "            pooled = F.avg_pool1d(x, kernel_size=k, stride=k, padding=0)\n",
    "            x_lp = F.interpolate(pooled, size=feature_dim, mode='nearest')\n",
    "        else:\n",
    "            x_lp = x.mean(dim=-1, keepdim=True).expand_as(x)\n",
    "        return (x_lp.square().sum() / (x.square().sum() + 1e-7)).item().detach().cpu()\n",
    "\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Conv1d, nn.Conv2d)):\n",
    "        module.register_forward_hook(forward_hook(name))\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b6a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "activation_cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659fba53",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def radial_spectrum_2d_per_sample(x, num_bins=64, eps=1e-8, out_dtype=None,\n",
    "                                  *, vit_grid=None, num_prefix_tokens=None, max_prefix_tokens=16,\n",
    "                                  log_power=True):\n",
    "    if out_dtype is None:\n",
    "        out_dtype = x.dtype\n",
    "\n",
    "    # --- your ViT token -> [B,C,H,W] conversion stays the same ---\n",
    "    if x.dim() == 3:\n",
    "        import math\n",
    "        B, N, D = x.shape\n",
    "        if vit_grid is not None:\n",
    "            H, W = vit_grid\n",
    "            needed = H * W\n",
    "            if num_prefix_tokens is None:\n",
    "                num_prefix_tokens = N - needed\n",
    "            if N - num_prefix_tokens != needed:\n",
    "                raise ValueError(\"grid mismatch\")\n",
    "        else:\n",
    "            if num_prefix_tokens is None:\n",
    "                found = None\n",
    "                for k in range(0, max_prefix_tokens + 1):\n",
    "                    m = N - k\n",
    "                    if m <= 0: break\n",
    "                    s = int(math.isqrt(m))\n",
    "                    if s * s == m:\n",
    "                        found = k\n",
    "                        H = W = s\n",
    "                        break\n",
    "                if found is None:\n",
    "                    raise ValueError(\"cannot infer grid\")\n",
    "                num_prefix_tokens = found\n",
    "            else:\n",
    "                m = N - num_prefix_tokens\n",
    "                s = int(math.isqrt(m))\n",
    "                if s * s != m:\n",
    "                    raise ValueError(\"not square\")\n",
    "                H = W = s\n",
    "\n",
    "        if num_prefix_tokens > 0:\n",
    "            x = x[:, num_prefix_tokens:, :].contiguous()\n",
    "        x = x.view(B, H, W, D).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    elif x.dim() != 4:\n",
    "        raise ValueError(f\"Expected dim 3 or 4, got {x.dim()}\")\n",
    "\n",
    "    # x: [B,C,H,W]\n",
    "    x = x.mean(dim=1)  # [B,H,W]\n",
    "\n",
    "    x_fft = x.to(torch.float32)\n",
    "    F = torch.fft.fft2(x_fft)\n",
    "    F = torch.fft.fftshift(F, dim=(-2, -1))\n",
    "    P = (F.real * F.real + F.imag * F.imag)  # [B,H,W]\n",
    "    if log_power:\n",
    "        P = torch.log1p(P)\n",
    "\n",
    "    B, H, W = P.shape\n",
    "    yy, xx = torch.meshgrid(torch.arange(H, device=P.device),\n",
    "                            torch.arange(W, device=P.device), indexing=\"ij\")\n",
    "    cy, cx = (H - 1) / 2.0, (W - 1) / 2.0\n",
    "    r = torch.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    r = (r / (r.max() + 1e-12) * (num_bins - 1)).to(torch.long)  # [H,W]\n",
    "    r_flat = r.flatten()  # [HW]\n",
    "\n",
    "    vals = P.reshape(B, -1)  # [B,HW]\n",
    "\n",
    "    # per-sample scatter_add\n",
    "    spec = torch.zeros((B, num_bins), device=P.device, dtype=torch.float32)\n",
    "    spec.scatter_add_(1, r_flat[None, :].expand(B, -1), vals)\n",
    "\n",
    "    spec = spec / (spec.sum(dim=1, keepdim=True) + eps)\n",
    "    return spec.to(out_dtype)\n",
    "\n",
    "\n",
    "def vit_spectral_slope_loss(tokens, num_bins=64, alpha=2.0, num_prefix_tokens=1):\n",
    "    spec = radial_spectrum_2d_per_sample(\n",
    "        tokens, num_bins=num_bins,\n",
    "        num_prefix_tokens=num_prefix_tokens,\n",
    "        log_power=True\n",
    "    )  # [B,K]\n",
    "\n",
    "    K = spec.shape[1]\n",
    "    k = torch.arange(K, device=spec.device, dtype=spec.dtype)\n",
    "    target = 1.0 / (k + 1.0) ** alpha\n",
    "    target = target / target.sum()\n",
    "\n",
    "    # compare each sample spectrum to 1/f^alpha\n",
    "    return torch.mean(torch.sum(torch.abs(spec - target[None, :]), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471eab9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def _infer_vit_grid(N, num_prefix_tokens=None, max_prefix_tokens=16):\n",
    "    if num_prefix_tokens is not None:\n",
    "        M = N - num_prefix_tokens\n",
    "        s = int(math.isqrt(M))\n",
    "        if s * s != M:\n",
    "            raise ValueError(f\"N - num_prefix_tokens = {M} not square\")\n",
    "        return s, s, num_prefix_tokens\n",
    "\n",
    "    # auto infer\n",
    "    for k in range(0, max_prefix_tokens + 1):\n",
    "        M = N - k\n",
    "        if M <= 0:\n",
    "            break\n",
    "        s = int(math.isqrt(M))\n",
    "        if s * s == M:\n",
    "            return s, s, k\n",
    "    raise ValueError(f\"Cannot infer vit grid from N={N}\")\n",
    "\n",
    "\n",
    "def _radial_bins(H, W, num_bins, device):\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(H, device=device),\n",
    "        torch.arange(W, device=device),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    cy, cx = (H - 1) / 2.0, (W - 1) / 2.0\n",
    "    r = torch.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    r = (r / (r.max() + 1e-12) * (num_bins - 1)).to(torch.long)  # [H,W]\n",
    "    return r\n",
    "\n",
    "\n",
    "def local_radial_spectrum_2d(\n",
    "    x,                      # [B,1,H,W] or [B,H,W]\n",
    "    window=8,\n",
    "    num_bins=32,\n",
    "    eps=1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns local spectra per window:\n",
    "      spectra: [B, nwin, num_bins] each normalized to sum=1\n",
    "    \"\"\"\n",
    "    if x.dim() == 4:\n",
    "        x = x.squeeze(1)\n",
    "    assert x.dim() == 3\n",
    "    B, H, W = x.shape\n",
    "\n",
    "    # crop to divisible by window\n",
    "    Hc = (H // window) * window\n",
    "    Wc = (W // window) * window\n",
    "    x = x[:, :Hc, :Wc]\n",
    "\n",
    "    # unfold into windows: [B, nH, nW, window, window]\n",
    "    nH = Hc // window\n",
    "    nW = Wc // window\n",
    "    xw = x.view(B, nH, window, nW, window).permute(0, 1, 3, 2, 4).contiguous()\n",
    "    xw = xw.view(B, nH * nW, window, window)  # [B, nwin, w, w]\n",
    "\n",
    "    # FFT per window (fp32)\n",
    "    X = xw.to(torch.float32)\n",
    "    Fw = torch.fft.fft2(X)                      # complex64\n",
    "    Fw = torch.fft.fftshift(Fw, dim=(-2, -1))\n",
    "    Pw = (Fw.real * Fw.real + Fw.imag * Fw.imag)  # [B,nwin,w,w]\n",
    "\n",
    "    # build radial bins for (window, window)\n",
    "    r = _radial_bins(window, window, num_bins, device=Pw.device)  # [w,w]\n",
    "    r_flat = r.flatten()  # [w*w]\n",
    "\n",
    "    # scatter-add radial power\n",
    "    spectra = torch.zeros((B, nH * nW, num_bins), device=Pw.device, dtype=torch.float32)\n",
    "    vals = Pw.reshape(B, nH * nW, -1)  # [B,nwin,w*w]\n",
    "\n",
    "    # vectorized scatter: flatten over B*nwin\n",
    "    BN = B * (nH * nW)\n",
    "    spectra2 = torch.zeros((BN, num_bins), device=Pw.device, dtype=torch.float32)\n",
    "    idx = r_flat[None, :].expand(BN, -1)  # [BN,w*w]\n",
    "    spectra2.scatter_add_(1, idx, vals.reshape(BN, -1))\n",
    "\n",
    "    spectra = spectra2.view(B, nH * nW, num_bins)\n",
    "    spectra = spectra / (spectra.sum(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "    return spectra  # [B,nwin,K]\n",
    "\n",
    "\n",
    "def local_freq_kl_loss(\n",
    "    vit_tokens,             # [B,N,D] tokens (output of some block or final tokens)\n",
    "    images,                 # [B,3,H_img,W_img] input image tensor\n",
    "    *,\n",
    "    vit_grid=None,          # (H,W) patch grid override\n",
    "    num_prefix_tokens=None, # if known\n",
    "    max_prefix_tokens=16,\n",
    "    window=7,\n",
    "    num_bins=32,\n",
    "    low_freq_bins=16,       # only match first few bins\n",
    "    eps=1e-8,\n",
    "    detach_target=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Local spectrum KL loss:\n",
    "      KL( target || model )\n",
    "\n",
    "    Returns scalar loss.\n",
    "    \"\"\"\n",
    "    assert vit_tokens.dim() == 3\n",
    "    B, N, D = vit_tokens.shape\n",
    "\n",
    "    # infer token grid\n",
    "    if vit_grid is not None:\n",
    "        Ht, Wt = vit_grid\n",
    "        needed = Ht * Wt\n",
    "        if num_prefix_tokens is None:\n",
    "            num_prefix_tokens = N - needed\n",
    "        assert N - num_prefix_tokens == needed\n",
    "    else:\n",
    "        Ht, Wt, num_prefix_tokens = _infer_vit_grid(N, num_prefix_tokens, max_prefix_tokens)\n",
    "\n",
    "    # patch tokens only\n",
    "    x = vit_tokens[:, num_prefix_tokens:, :]  # [B, Ht*Wt, D]\n",
    "    x = x.view(B, Ht, Wt, D).permute(0, 3, 1, 2).contiguous()  # [B,D,Ht,Wt]\n",
    "\n",
    "    # make it 1-channel \"activation image\"\n",
    "    x_map = x.mean(dim=1, keepdim=True)  # [B,1,Ht,Wt]\n",
    "\n",
    "    # downsample input image to patch grid resolution\n",
    "    img = images\n",
    "    img_gray = img.mean(dim=1, keepdim=True)  # [B,1,H_img,W_img]\n",
    "    img_ds = F.interpolate(img_gray, size=(Ht, Wt), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    if detach_target:\n",
    "        img_ds = img_ds.detach()\n",
    "\n",
    "    # compute local spectra\n",
    "    spec_model = local_radial_spectrum_2d(x_map, window=window, num_bins=num_bins, eps=eps)  # [B,nwin,K]\n",
    "    spec_tgt   = local_radial_spectrum_2d(img_ds, window=window, num_bins=num_bins, eps=eps) # [B,nwin,K]\n",
    "\n",
    "    # use only low-freq bins\n",
    "    K = min(low_freq_bins, num_bins)\n",
    "    pm = spec_model[..., :K].clamp_min(eps)\n",
    "    pt = spec_tgt[..., :K].clamp_min(eps)\n",
    "\n",
    "    # renormalize after truncation\n",
    "    pm = pm / pm.sum(dim=-1, keepdim=True)\n",
    "    pt = pt / pt.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    # KL(target || model)\n",
    "    loss = (pt * (pt.log() - pm.log())).sum(dim=-1)  # [B,nwin]\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5305af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def radial_spectrum_2d(\n",
    "    x,\n",
    "    num_bins=128,\n",
    "    eps=1e-8,\n",
    "    out_dtype=None,\n",
    "    *,\n",
    "    vit_grid=None,\n",
    "    num_prefix_tokens=None,\n",
    "    max_prefix_tokens=16,\n",
    "    use_cls_token=True,\n",
    "    # ---- NEW ----\n",
    "    num_theta_bins=360,\n",
    "    remove_dc=True,\n",
    "    power=True,\n",
    "    theta_offset=0.0,\n",
    "    return_marginal_r=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      polar spectrum [num_bins, num_theta_bins] (distribution), differentiable\n",
    "    \"\"\"\n",
    "    if out_dtype is None:\n",
    "        out_dtype = x.dtype\n",
    "\n",
    "    # ---------------------------\n",
    "    # ViT tokens -> [B,C,H,W]\n",
    "    # ---------------------------\n",
    "    if x.dim() == 3:\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        if vit_grid is not None:\n",
    "            H, W = vit_grid\n",
    "            needed = H * W\n",
    "            if num_prefix_tokens is None:\n",
    "                num_prefix_tokens = N - needed\n",
    "            if N - num_prefix_tokens != needed:\n",
    "                raise ValueError(\n",
    "                    f\"vit_grid={vit_grid} implies {needed} patch tokens, but got N={N} \"\n",
    "                    f\"with num_prefix_tokens={num_prefix_tokens} => {N - num_prefix_tokens} tokens.\"\n",
    "                )\n",
    "        else:\n",
    "            if num_prefix_tokens is None:\n",
    "                found = None\n",
    "                for k in range(0, max_prefix_tokens + 1):\n",
    "                    m = N - k\n",
    "                    if m <= 0:\n",
    "                        break\n",
    "                    s = int(math.isqrt(m))\n",
    "                    if s * s == m:\n",
    "                        found = k\n",
    "                        H = W = s\n",
    "                        break\n",
    "                if found is None:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot infer square token grid from N={N}. \"\n",
    "                        f\"Pass vit_grid=(H,W) or num_prefix_tokens explicitly.\"\n",
    "                    )\n",
    "                num_prefix_tokens = found\n",
    "            else:\n",
    "                m = N - num_prefix_tokens\n",
    "                s = int(math.isqrt(m))\n",
    "                if s * s != m:\n",
    "                    raise ValueError(\n",
    "                        f\"N - num_prefix_tokens = {m} is not a perfect square. \"\n",
    "                        f\"Pass vit_grid=(H,W) instead.\"\n",
    "                    )\n",
    "                H = W = s\n",
    "\n",
    "        if use_cls_token:\n",
    "            cls = x[:, 0, :]  # [B,D]\n",
    "            HW = H * W\n",
    "            if D < HW:\n",
    "                cls = F.pad(cls, (0, HW - D), value=0.0)\n",
    "            elif D > HW:\n",
    "                cls = cls[:, :HW]\n",
    "            x = cls.view(B, 1, H, W).contiguous()\n",
    "        else:\n",
    "            tok = x[:, num_prefix_tokens:, :] if num_prefix_tokens > 0 else x\n",
    "            tok = tok.contiguous()\n",
    "            tok = tok.view(B, H, W, D).permute(0, 3, 1, 2).contiguous()\n",
    "            x = tok\n",
    "\n",
    "    elif x.dim() != 4:\n",
    "        raise ValueError(f\"Expected x dim 3 or 4, got {x.dim()}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    # x: [B,C,H,W]\n",
    "    # ---------------------------\n",
    "    x = x.mean(dim=1)  # [B,H,W]\n",
    "\n",
    "    X = torch.fft.fft2(x.to(torch.float32), dim=(-2, -1))\n",
    "    X = torch.fft.fftshift(X, dim=(-2, -1))\n",
    "    mag = X.abs()\n",
    "    P = mag * mag if power else mag  # [B,H,W]\n",
    "\n",
    "    B, H, W = P.shape\n",
    "\n",
    "    if remove_dc:\n",
    "        P[:, H // 2, W // 2] = 0.0\n",
    "\n",
    "    # (r, theta) bin maps (NOT dependent on x, safe to compute)\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(H, device=P.device),\n",
    "        torch.arange(W, device=P.device),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    cy, cx = (H - 1) / 2.0, (W - 1) / 2.0\n",
    "    dy = yy - cy\n",
    "    dx = xx - cx\n",
    "\n",
    "    # radius bins\n",
    "    r = torch.sqrt(dx * dx + dy * dy)\n",
    "    r = r / (r.max() + 1e-12)\n",
    "    r_bin = torch.clamp((r * (num_bins - 1)).long(), 0, num_bins - 1)\n",
    "\n",
    "    # theta bins\n",
    "    theta = torch.atan2(dy, dx) + theta_offset\n",
    "    theta = (theta + math.pi) / (2.0 * math.pi)   # [0,1) (wrapped)\n",
    "    theta = theta - torch.floor(theta)\n",
    "    t_bin = torch.clamp((theta * num_theta_bins).long(), 0, num_theta_bins - 1)\n",
    "\n",
    "    # Flatten indexing: joint bin id in [0, num_bins*num_theta_bins)\n",
    "    joint = (r_bin * num_theta_bins + t_bin).reshape(-1)  # [HW]\n",
    "    K = num_bins * num_theta_bins\n",
    "\n",
    "    # Differentiable accumulation:\n",
    "    # hist[k] = sum_{b,pixel where joint==k} P[b,pixel]\n",
    "    # Use index_add_ (supports autograd w.r.t. P)\n",
    "    hist = torch.zeros(K, device=P.device, dtype=P.dtype)\n",
    "\n",
    "    # flatten P -> [B*HW]\n",
    "    P_flat = P.reshape(-1)  # differentiable\n",
    "    joint_flat = joint.repeat(B)  # [B*HW], integer indices\n",
    "\n",
    "    hist.index_add_(0, joint_flat, P_flat)\n",
    "\n",
    "    polar = hist.view(num_bins, num_theta_bins).to(torch.float32)\n",
    "\n",
    "    polar = polar / (polar.sum() + eps)\n",
    "\n",
    "    if return_marginal_r:\n",
    "        spectrum_r = polar.sum(dim=1)\n",
    "        spectrum_r = spectrum_r / (spectrum_r.sum() + eps)\n",
    "        return polar.to(out_dtype), spectrum_r.to(out_dtype)\n",
    "\n",
    "    return polar.to(out_dtype)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def polar_kl_loss(polar_s, polar_t, eps=1e-8, T=1.0, reduction=\"sum\"):\n",
    "    \"\"\"\n",
    "    polar_s, polar_t: [R,Theta] distributions (NOT raw energies)\n",
    "    returns scalar\n",
    "    \"\"\"\n",
    "    ps = polar_s.to(torch.float32).clamp_min(eps)\n",
    "    pt = polar_t.to(torch.float32).clamp_min(eps)\n",
    "\n",
    "    # re-normalize (safe)\n",
    "    ps = ps / (ps.sum() + eps)\n",
    "    pt = pt / (pt.sum() + eps)\n",
    "\n",
    "    log_ps = torch.log(ps)\n",
    "    log_pt = torch.log(pt)\n",
    "\n",
    "    # temperature smoothing along theta dimension (can also use flatten)\n",
    "    psT = F.softmax(log_ps.view(-1) / T, dim=0)\n",
    "    ptT = F.softmax(log_pt.view(-1) / T, dim=0)\n",
    "\n",
    "    kl = (psT * (torch.log(psT.clamp_min(eps)) - torch.log(ptT.clamp_min(eps)))).sum()\n",
    "\n",
    "    if reduction == \"mean\":\n",
    "        kl = kl / ps.numel()\n",
    "\n",
    "    return (T * T) * kl\n",
    "\n",
    "\n",
    "def wasserstein_1d(p, q, eps=1e-8):\n",
    "    \"\"\"\n",
    "    p,q: [K] distributions\n",
    "    \"\"\"\n",
    "    p32 = p.to(torch.float32)\n",
    "    q32 = q.to(torch.float32)\n",
    "    p32 = p32 / (p32.sum() + eps)\n",
    "    q32 = q32 / (q32.sum() + eps)\n",
    "    cdf_p = torch.cumsum(p32, dim=0)\n",
    "    cdf_q = torch.cumsum(q32, dim=0)\n",
    "    return torch.sum(torch.abs(cdf_p - cdf_q))\n",
    "\n",
    "\n",
    "def polar_wasserstein_rtheta(polar_s, polar_t, eps=1e-8):\n",
    "    \"\"\"\n",
    "    polar_s, polar_t: [R,Theta] distributions\n",
    "    returns scalar\n",
    "    \"\"\"\n",
    "    ps = polar_s.to(torch.float32).clamp_min(eps)\n",
    "    pt = polar_t.to(torch.float32).clamp_min(eps)\n",
    "\n",
    "    ps = ps / (ps.sum() + eps)\n",
    "    pt = pt / (pt.sum() + eps)\n",
    "\n",
    "    # 1) Wasserstein on radial marginal\n",
    "    ps_r = ps.sum(dim=1)  # [R]\n",
    "    pt_r = pt.sum(dim=1)\n",
    "    wr = wasserstein_1d(ps_r, pt_r, eps=eps)\n",
    "\n",
    "    # 2) Wasserstein on angular bins per radius\n",
    "    # weight by average mass in that radius\n",
    "    weights = 0.5 * (ps_r + pt_r)  # [R]\n",
    "    wa = 0.0\n",
    "    R = ps.shape[0]\n",
    "    for r in range(R):\n",
    "        wa = wa + weights[r] * wasserstein_1d(ps[r], pt[r], eps=eps)\n",
    "\n",
    "    return wr + wa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437399cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# polar_spectrum.py\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Bin-cache (critical for speed)\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class _BinKey:\n",
    "    H: int\n",
    "    W: int\n",
    "    num_r: int\n",
    "    num_t: int\n",
    "    theta_offset: float\n",
    "\n",
    "class PolarBinCache:\n",
    "    \"\"\"\n",
    "    Caches joint bin indices for (H,W,num_r,num_t,theta_offset,device).\n",
    "    This avoids recomputing meshgrid/atan2 every forward.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._cache: Dict[Tuple, torch.Tensor] = {}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_joint(\n",
    "        self,\n",
    "        H: int,\n",
    "        W: int,\n",
    "        num_bins: int,\n",
    "        num_theta_bins: int,\n",
    "        theta_offset: float,\n",
    "        device: torch.device,\n",
    "    ) -> torch.Tensor:\n",
    "        key = (H, W, num_bins, num_theta_bins, float(theta_offset), str(device))\n",
    "        if key in self._cache:\n",
    "            return self._cache[key]\n",
    "\n",
    "        yy, xx = torch.meshgrid(\n",
    "            torch.arange(H, device=device, dtype=torch.float32),\n",
    "            torch.arange(W, device=device, dtype=torch.float32),\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "        cy, cx = (H - 1) / 2.0, (W - 1) / 2.0\n",
    "        dy = yy - cy\n",
    "        dx = xx - cx\n",
    "\n",
    "        # radius bins in [0, num_bins-1]\n",
    "        r = torch.sqrt(dx * dx + dy * dy)\n",
    "        r = r / (r.max().clamp_min(1e-12))\n",
    "        r_bin = torch.clamp((r * (num_bins - 1)).to(torch.int64), 0, num_bins - 1)\n",
    "\n",
    "        # theta bins in [0, num_theta_bins-1]\n",
    "        theta = torch.atan2(dy, dx) + float(theta_offset)\n",
    "        theta = (theta + math.pi) / (2.0 * math.pi)  # [0,1) with wrapping\n",
    "        theta = theta - torch.floor(theta)\n",
    "        t_bin = torch.clamp((theta * num_theta_bins).to(torch.int64), 0, num_theta_bins - 1)\n",
    "\n",
    "        joint = (r_bin * num_theta_bins + t_bin).reshape(-1).contiguous()  # [H*W]\n",
    "        self._cache[key] = joint\n",
    "        return joint\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ViT token grid inference\n",
    "# -------------------------\n",
    "def _infer_vit_grid(\n",
    "    N: int,\n",
    "    vit_grid: Optional[Tuple[int, int]],\n",
    "    num_prefix_tokens: Optional[int],\n",
    "    max_prefix_tokens: int,\n",
    ") -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Returns (H, W, num_prefix_tokens).\n",
    "    \"\"\"\n",
    "    if vit_grid is not None:\n",
    "        H, W = vit_grid\n",
    "        needed = H * W\n",
    "        if num_prefix_tokens is None:\n",
    "            num_prefix_tokens = N - needed\n",
    "        if N - num_prefix_tokens != needed:\n",
    "            raise ValueError(\n",
    "                f\"vit_grid={vit_grid} implies {needed} patch tokens, but got N={N} \"\n",
    "                f\"with num_prefix_tokens={num_prefix_tokens} => {N - num_prefix_tokens} tokens.\"\n",
    "            )\n",
    "        return H, W, num_prefix_tokens\n",
    "\n",
    "    # infer square grid\n",
    "    if num_prefix_tokens is None:\n",
    "        found = None\n",
    "        for k in range(0, max_prefix_tokens + 1):\n",
    "            m = N - k\n",
    "            if m <= 0:\n",
    "                break\n",
    "            s = int(math.isqrt(m))\n",
    "            if s * s == m:\n",
    "                found = k\n",
    "                H = W = s\n",
    "                break\n",
    "        if found is None:\n",
    "            raise ValueError(\n",
    "                f\"Cannot infer square token grid from N={N}. \"\n",
    "                f\"Pass vit_grid=(H,W) or num_prefix_tokens explicitly.\"\n",
    "            )\n",
    "        return H, W, found\n",
    "\n",
    "    m = N - num_prefix_tokens\n",
    "    s = int(math.isqrt(m))\n",
    "    if s * s != m:\n",
    "        raise ValueError(\n",
    "            f\"N - num_prefix_tokens = {m} is not a perfect square. \"\n",
    "            f\"Pass vit_grid=(H,W) instead.\"\n",
    "        )\n",
    "    return s, s, num_prefix_tokens\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Differentiable polar spectrum (per-sample, not merged across batch)\n",
    "# -------------------------\n",
    "def polar_spectrum_2d(\n",
    "    x: torch.Tensor,\n",
    "    *,\n",
    "    num_bins: int = 32,\n",
    "    num_theta_bins: int = 64,\n",
    "    eps: float = 1e-8,\n",
    "    out_dtype=None,\n",
    "    # ViT handling\n",
    "    vit_grid: Optional[Tuple[int, int]] = None,\n",
    "    num_prefix_tokens: Optional[int] = None,\n",
    "    max_prefix_tokens: int = 16,\n",
    "    use_cls_token: bool = True,\n",
    "    # FFT/polar params\n",
    "    remove_dc: bool = True,\n",
    "    power: bool = True,\n",
    "    theta_offset: float = 0.0,\n",
    "    # output\n",
    "    return_marginal_r: bool = False,\n",
    "    # caching\n",
    "    bin_cache: Optional[PolarBinCache] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - CNN map: x [B,C,H,W]\n",
    "      - ViT tokens: x [B,N,D]\n",
    "        * if use_cls_token=True: build 1-channel HxW map from CLS embedding by pad/truncation\n",
    "        * else: reshape patch tokens to [B,D,H,W]\n",
    "\n",
    "    Returns:\n",
    "      polar: [B, R, Theta] distribution (sums to 1 per sample), differentiable wrt x\n",
    "      optionally also returns marginal_r: [B, R]\n",
    "    \"\"\"\n",
    "    if out_dtype is None:\n",
    "        out_dtype = x.dtype\n",
    "\n",
    "    # ---- convert ViT tokens -> [B,C,H,W] ----\n",
    "    if x.dim() == 3:\n",
    "        B, N, D = x.shape\n",
    "        H, W, num_prefix_tokens = _infer_vit_grid(N, vit_grid, num_prefix_tokens, max_prefix_tokens)\n",
    "\n",
    "        if use_cls_token:\n",
    "            cls = x[:, 0, :]  # [B,D]\n",
    "            HW = H * W\n",
    "            if D < HW:\n",
    "                cls = F.pad(cls, (0, HW - D), value=0.0)\n",
    "            elif D > HW:\n",
    "                cls = cls[:, :HW]\n",
    "            x = cls.view(B, 1, H, W).contiguous()  # [B,1,H,W]\n",
    "        else:\n",
    "            tok = x[:, num_prefix_tokens:, :] if num_prefix_tokens > 0 else x\n",
    "            tok = tok.contiguous().view(B, H, W, D).permute(0, 3, 1, 2).contiguous()  # [B,D,H,W]\n",
    "            x = tok\n",
    "    elif x.dim() != 4:\n",
    "        raise ValueError(f\"Expected x dim 3 or 4, got {x.dim()}\")\n",
    "\n",
    "    # ---- x: [B,C,H,W] -> grayscale [B,H,W] ----\n",
    "    x = x.mean(dim=1)  # [B,H,W]\n",
    "    B, H, W = x.shape\n",
    "\n",
    "    # ---- FFT power spectrum ----\n",
    "    X = torch.fft.fft2(x.to(torch.float32), dim=(-2, -1))\n",
    "    X = torch.fft.fftshift(X, dim=(-2, -1))\n",
    "    mag = X.abs()\n",
    "    P = mag * mag if power else mag  # [B,H,W]\n",
    "\n",
    "    if remove_dc:\n",
    "        # avoid in-place on a view; use a multiplicative mask\n",
    "        mask = torch.ones((H, W), device=P.device, dtype=P.dtype)\n",
    "        mask[H // 2, W // 2] = 0.0\n",
    "        P = P * mask\n",
    "\n",
    "    # ---- joint bin indices ----\n",
    "    if bin_cache is None:\n",
    "        bin_cache = PolarBinCache()\n",
    "    joint = bin_cache.get_joint(H, W, num_bins, num_theta_bins, theta_offset, P.device)  # [H*W]\n",
    "    K = num_bins * num_theta_bins\n",
    "\n",
    "    # ---- differentiable histogram per sample: histB [B,K] ----\n",
    "    P_flat = P.reshape(B, -1)  # [B,HW]\n",
    "    idx = joint.view(1, -1).expand(B, -1)  # view expand, no big allocation\n",
    "    histB = torch.zeros((B, K), device=P.device, dtype=P.dtype)\n",
    "    histB.scatter_add_(1, idx, P_flat)\n",
    "\n",
    "    polar = histB.view(B, num_bins, num_theta_bins).to(torch.float32)\n",
    "    polar = polar / (polar.sum(dim=(1, 2), keepdim=True) + eps)  # per-sample normalize\n",
    "\n",
    "    if return_marginal_r:\n",
    "        spectrum_r = polar.sum(dim=2)  # [B,R]\n",
    "        spectrum_r = spectrum_r / (spectrum_r.sum(dim=1, keepdim=True) + eps)\n",
    "        return polar.to(out_dtype), spectrum_r.to(out_dtype)\n",
    "\n",
    "    return polar.to(out_dtype)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Losses (fast + strong gradients)\n",
    "# -------------------------\n",
    "def _power_temperature(p: torch.Tensor, T: float = 1.0, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Temperature for probability distributions: p^(1/T) / Z\n",
    "    (Much better behaved than softmax(log(p)/T) for your use case.)\n",
    "    \"\"\"\n",
    "    p = p.to(torch.float32).clamp_min(eps)\n",
    "    if T != 1.0:\n",
    "        p = p.pow(1.0 / float(T))\n",
    "    return p / (p.sum(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "\n",
    "def polar_kl_loss(\n",
    "    polar_s: torch.Tensor,\n",
    "    polar_t: torch.Tensor,\n",
    "    *,\n",
    "    T: float = 1.0,\n",
    "    k_low: Optional[int] = 12,      # constrain only low radius bins (stronger + faster)\n",
    "    eps: float = 1e-8,\n",
    "    reduction: str = \"mean\",\n",
    "    direction: str = \"t||s\",        # \"t||s\" => KL(target || student) (recommended)\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    polar_s: [B,R,Theta] or [R,Theta]\n",
    "    polar_t: [B,R,Theta] or [R,Theta]\n",
    "    Returns scalar.\n",
    "\n",
    "    k_low:\n",
    "      - if not None, only match polar[:, :k_low, :]\n",
    "      - this massively speeds convergence\n",
    "    \"\"\"\n",
    "    if polar_s.dim() == 2:\n",
    "        polar_s = polar_s.unsqueeze(0)\n",
    "    if polar_t.dim() == 2:\n",
    "        polar_t = polar_t.unsqueeze(0)\n",
    "\n",
    "    Bs = polar_s.shape[0]\n",
    "    Bt = polar_t.shape[0]\n",
    "    if Bt == 1 and Bs > 1:\n",
    "        polar_t = polar_t.expand(Bs, -1, -1)\n",
    "    elif Bt != Bs:\n",
    "        raise ValueError(f\"Batch mismatch: polar_s B={Bs}, polar_t B={Bt}\")\n",
    "\n",
    "    if k_low is not None:\n",
    "        polar_s = polar_s[:, :k_low, :]\n",
    "        polar_t = polar_t[:, :k_low, :]\n",
    "\n",
    "    ps = polar_s.reshape(polar_s.shape[0], -1)\n",
    "    pt = polar_t.reshape(polar_t.shape[0], -1)\n",
    "\n",
    "    ps = ps / (ps.sum(dim=1, keepdim=True) + eps)\n",
    "    pt = pt / (pt.sum(dim=1, keepdim=True) + eps)\n",
    "\n",
    "    psT = _power_temperature(ps, T=T, eps=eps)\n",
    "    ptT = _power_temperature(pt, T=T, eps=eps)\n",
    "\n",
    "    if direction == \"t||s\":\n",
    "        # KL(pt || ps)\n",
    "        kl = (ptT * (ptT.clamp_min(eps).log() - psT.clamp_min(eps).log())).sum(dim=1)\n",
    "    elif direction == \"s||t\":\n",
    "        kl = (psT * (psT.clamp_min(eps).log() - ptT.clamp_min(eps).log())).sum(dim=1)\n",
    "    else:\n",
    "        raise ValueError('direction must be \"t||s\" or \"s||t\"')\n",
    "\n",
    "    kl = (T * T) * kl\n",
    "    if reduction == \"mean\":\n",
    "        return kl.mean()\n",
    "    if reduction == \"sum\":\n",
    "        return kl.sum()\n",
    "    return kl  # [B]\n",
    "\n",
    "\n",
    "def lowfreq_profile_loss(\n",
    "    polar_s,\n",
    "    polar_t,\n",
    "    *,\n",
    "    k_low=12,\n",
    "    eps=1e-8,\n",
    "):\n",
    "    ps_r = polar_s.sum(dim=2)[:, :k_low]\n",
    "    pt_r = polar_t.sum(dim=2)[:, :k_low]\n",
    "\n",
    "    ps_r = ps_r / (ps_r.sum(dim=1, keepdim=True) + eps)\n",
    "    pt_r = pt_r / (pt_r.sum(dim=1, keepdim=True) + eps)\n",
    "\n",
    "    return F.mse_loss(torch.log(ps_r + eps), torch.log(pt_r + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96473ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Orthonormal DCT-II helpers\n",
    "# ---------------------------\n",
    "\n",
    "def _dct_1d_ortho(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    DCT-II (ortho) along last dim.\n",
    "    x: [..., N] real\n",
    "    returns: [..., N] real\n",
    "    \"\"\"\n",
    "    N = x.shape[-1]\n",
    "\n",
    "    # even extension: [x0..xN-1, xN-1..x0]\n",
    "    x_ext = torch.cat([x, x.flip(-1)], dim=-1)\n",
    "\n",
    "    # FFT of even-extended signal\n",
    "    X = torch.fft.fft(x_ext, dim=-1)  # complex\n",
    "\n",
    "    k = torch.arange(N, device=x.device, dtype=torch.float32)\n",
    "    W = torch.exp(-1j * math.pi * k / (2.0 * N))  # complex\n",
    "\n",
    "    # DCT-II from FFT\n",
    "    y = (X[..., :N] * W).real * 2.0\n",
    "\n",
    "    # Orthonormal scaling\n",
    "    y[..., 0] *= (1.0 / math.sqrt(4.0 * N))\n",
    "    y[..., 1:] *= (1.0 / math.sqrt(2.0 * N))\n",
    "    return y\n",
    "\n",
    "\n",
    "def _dct_2d_ortho(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Separable 2D DCT-II (ortho).\n",
    "    x: [*, H, W]\n",
    "    returns: [*, H, W]\n",
    "    \"\"\"\n",
    "    x = _dct_1d_ortho(x)  # along W\n",
    "    x = _dct_1d_ortho(x.transpose(-1, -2)).transpose(-1, -2)  # along H\n",
    "    return x\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Channelwise radial spectrum\n",
    "# ---------------------------\n",
    "\n",
    "def radial_spectrum_2d_channelwise_dct(\n",
    "    x: torch.Tensor,\n",
    "    num_bins: int = 16,\n",
    "    eps: float = 1e-8,\n",
    "    out_dtype=None,\n",
    "    *,\n",
    "    vit_grid=None,              # (H, W) explicit patch grid\n",
    "    num_prefix_tokens=None,      # number of prefix tokens total\n",
    "    max_prefix_tokens: int = 16,\n",
    "    use_cls_token: bool = True,  # if True, build spectrum from CLS token only\n",
    "    reduce: str = \"mean\",        # \"mean\" or \"sum\" across channels (and batch)\n",
    "    use_log_power: bool = False, # log1p(power) to compress dynamic range\n",
    "):\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "      - CNN feature maps: x [B, C, H, W]\n",
    "      - ViT tokens:       x [B, N, D]\n",
    "\n",
    "    Returns:\n",
    "      spectrum [num_bins], normalized to sum=1 (aggregated across batch and channels).\n",
    "      (If you want per-channel spectra, see note at bottom.)\n",
    "    \"\"\"\n",
    "    if out_dtype is None:\n",
    "        out_dtype = x.dtype\n",
    "\n",
    "    # ---------------- ViT handling (same spirit as your version) ----------------\n",
    "    if x.dim() == 3:\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        # Determine grid size and prefix tokens\n",
    "        if vit_grid is not None:\n",
    "            H, W = vit_grid\n",
    "            needed = H * W\n",
    "            if num_prefix_tokens is None:\n",
    "                num_prefix_tokens = N - needed\n",
    "            if N - num_prefix_tokens != needed:\n",
    "                raise ValueError(\n",
    "                    f\"vit_grid={vit_grid} implies {needed} patch tokens, but got N={N} \"\n",
    "                    f\"with num_prefix_tokens={num_prefix_tokens} => {N - num_prefix_tokens} tokens.\"\n",
    "                )\n",
    "        else:\n",
    "            if num_prefix_tokens is None:\n",
    "                found = None\n",
    "                for k in range(0, max_prefix_tokens + 1):\n",
    "                    m = N - k\n",
    "                    if m <= 0:\n",
    "                        break\n",
    "                    s = int(math.isqrt(m))\n",
    "                    if s * s == m:\n",
    "                        found = k\n",
    "                        H = W = s\n",
    "                        break\n",
    "                if found is None:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot infer square token grid from N={N}. \"\n",
    "                        f\"Pass vit_grid=(H,W) or num_prefix_tokens explicitly.\"\n",
    "                    )\n",
    "                num_prefix_tokens = found\n",
    "            else:\n",
    "                m = N - num_prefix_tokens\n",
    "                s = int(math.isqrt(m))\n",
    "                if s * s != m:\n",
    "                    raise ValueError(\n",
    "                        f\"N - num_prefix_tokens = {m} is not a perfect square. \"\n",
    "                        f\"Pass vit_grid=(H,W) instead.\"\n",
    "                    )\n",
    "                H = W = s\n",
    "\n",
    "        if use_cls_token:\n",
    "            # CLS assumed token 0: [B, D]\n",
    "            cls = x[:, 0, :]\n",
    "            HW = H * W\n",
    "            if D < HW:\n",
    "                cls = F.pad(cls, (0, HW - D), mode=\"constant\", value=0.0)\n",
    "            elif D > HW:\n",
    "                cls = cls[:, :HW]\n",
    "            # [B, H, W] -> [B, 1, H, W]\n",
    "            x = cls.view(B, H, W).unsqueeze(1).contiguous()\n",
    "        else:\n",
    "            # Patch tokens as channels (D channels over HxW)\n",
    "            if num_prefix_tokens > 0:\n",
    "                x = x[:, num_prefix_tokens:, :].contiguous()  # [B, H*W, D]\n",
    "            else:\n",
    "                x = x.contiguous()\n",
    "            x = x.view(B, H, W, D).permute(0, 3, 1, 2).contiguous()  # [B, D, H, W]\n",
    "\n",
    "    elif x.dim() != 4:\n",
    "        raise ValueError(f\"Expected x dim 3 or 4, got {x.dim()}\")\n",
    "\n",
    "    # x is now [B, C, H, W]\n",
    "    B, C, H, W = x.shape\n",
    "\n",
    "    # ---------------- DCT power (channelwise) ----------------\n",
    "    # do DCT in fp32 for stability\n",
    "    xf = x.to(torch.float32)\n",
    "\n",
    "    # compute 2D DCT for each (B,C) map: reshape to [B*C, H, W]\n",
    "    X = xf.reshape(B * C, H, W)\n",
    "    DCT = _dct_2d_ortho(X)  # [B*C, H, W]\n",
    "\n",
    "    P = DCT * DCT  # power, [B*C, H, W]\n",
    "    if use_log_power:\n",
    "        P = torch.log1p(P)\n",
    "\n",
    "    # ---------------- Radial bins (DCT: DC at (0,0), HF grows with radius) ----------------\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(H, device=P.device),\n",
    "        torch.arange(W, device=P.device),\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "    r = torch.sqrt(yy.to(torch.float32) ** 2 + xx.to(torch.float32) ** 2)  # [H,W]\n",
    "    r = r / (r.max() + 1e-12)\n",
    "    rbin = (r * (num_bins - 1)).to(torch.long)  # [H,W] in [0, num_bins-1]\n",
    "\n",
    "    # ---------------- Accumulate spectrum ----------------\n",
    "    # Flatten spatial dims and scatter-add across all (B*C) maps.\n",
    "    idx = rbin.flatten().unsqueeze(0).expand(B * C, -1)  # [BC, HW]\n",
    "    vals = P.reshape(B * C, -1)                          # [BC, HW]\n",
    "\n",
    "    spec = torch.zeros(num_bins, device=P.device, dtype=torch.float32)\n",
    "    spec.scatter_add_(0, idx.reshape(-1), vals.reshape(-1))\n",
    "\n",
    "    # Optional: if you want to reduce per (B,C) first, you can do it differently,\n",
    "    # but this global accumulation is fastest and matches your original behavior.\n",
    "\n",
    "    if reduce not in (\"mean\", \"sum\"):\n",
    "        raise ValueError(f\"reduce must be 'mean' or 'sum', got {reduce}\")\n",
    "\n",
    "    if reduce == \"mean\":\n",
    "        spec = spec / float(B * C)\n",
    "\n",
    "    spec = spec / (spec.sum() + eps)\n",
    "    return spec.to(out_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4190348",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "def radial_spectrum_2d(\n",
    "    x,\n",
    "    num_bins=16,\n",
    "    eps=1e-8,\n",
    "    out_dtype=None,\n",
    "\n",
    "    *,\n",
    "    vit_grid=None,              # (H, W) explicit patch grid\n",
    "    num_prefix_tokens=None,      # number of prefix tokens total\n",
    "    max_prefix_tokens=16,\n",
    "    use_cls_token=True,         # NEW: if True, build spectrum from CLS token only\n",
    "):\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "      - CNN feature maps: x [B, C, H, W]\n",
    "      - ViT tokens:       x [B, N, D]  (tokens, embed dim)\n",
    "\n",
    "    Returns:\n",
    "      spectrum [num_bins], normalized to sum=1 (aggregated across batch).\n",
    "    \"\"\"\n",
    "\n",
    "    if out_dtype is None:\n",
    "        out_dtype = x.dtype\n",
    "\n",
    "    if x.dim() == 3:\n",
    "        # ViT tokens: [B, N, D]\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        # Determine grid size and how many prefix tokens exist.\n",
    "        if vit_grid is not None:\n",
    "            H, W = vit_grid\n",
    "            needed = H * W\n",
    "            if num_prefix_tokens is None:\n",
    "                num_prefix_tokens = N - needed\n",
    "            if N - num_prefix_tokens != needed:\n",
    "                raise ValueError(\n",
    "                    f\"vit_grid={vit_grid} implies {needed} patch tokens, but got N={N} \"\n",
    "                    f\"with num_prefix_tokens={num_prefix_tokens} => {N - num_prefix_tokens} tokens.\"\n",
    "                )\n",
    "        else:\n",
    "            # Auto-infer num_prefix_tokens by finding N-k that is a perfect square\n",
    "            if num_prefix_tokens is None:\n",
    "                found = None\n",
    "                for k in range(0, max_prefix_tokens + 1):\n",
    "                    m = N - k\n",
    "                    if m <= 0:\n",
    "                        break\n",
    "                    s = int(math.isqrt(m))\n",
    "                    if s * s == m:\n",
    "                        found = k\n",
    "                        H = W = s\n",
    "                        break\n",
    "                if found is None:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot infer square token grid from N={N}. \"\n",
    "                        f\"Pass vit_grid=(H,W) or num_prefix_tokens explicitly.\"\n",
    "                    )\n",
    "                num_prefix_tokens = found\n",
    "            else:\n",
    "                m = N - num_prefix_tokens\n",
    "                s = int(math.isqrt(m))\n",
    "                if s * s != m:\n",
    "                    raise ValueError(\n",
    "                        f\"N - num_prefix_tokens = {m} is not a perfect square. \"\n",
    "                        f\"Pass vit_grid=(H,W) instead.\"\n",
    "                    )\n",
    "                H = W = s\n",
    "\n",
    "        # =========================\n",
    "        # NEW: CLS-token spectrum\n",
    "        # =========================\n",
    "        if use_cls_token:\n",
    "            # CLS assumed to be token 0\n",
    "            cls = x[:, 0, :]  # [B, D]\n",
    "\n",
    "            # Turn CLS embedding into a 2D \"image\" so FFT makes sense.\n",
    "            # We reshape D -> H*W (requires D == H*W).\n",
    "            # If not equal, we crop or pad.\n",
    "            HW = H * W\n",
    "            if D < HW:\n",
    "                pad = HW - D\n",
    "                cls = torch.nn.functional.pad(cls, (0, pad), mode=\"constant\", value=0.0)\n",
    "            elif D > HW:\n",
    "                cls = cls[:, :HW]\n",
    "\n",
    "            # [B, HW] -> [B, H, W] -> [B, 1, H, W]\n",
    "            x = cls.view(B, H, W).unsqueeze(1).contiguous()\n",
    "\n",
    "        else:\n",
    "            # Default: patch-token spectrum (original behavior)\n",
    "            if num_prefix_tokens > 0:\n",
    "                x = x[:, num_prefix_tokens:, :].contiguous()  # [B, H*W, D]\n",
    "            else:\n",
    "                x = x.contiguous()\n",
    "\n",
    "            # [B, H*W, D] -> [B, H, W, D] -> [B, D, H, W]\n",
    "            x = x.view(B, H, W, D).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    elif x.dim() != 4:\n",
    "        raise ValueError(f\"Expected x dim 3 or 4, got {x.dim()}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # CNN path (or converted ViT path): x [B, C, H, W]\n",
    "    x = x.mean(dim=1)                 # [B, H, W]\n",
    "\n",
    "    # FFT in fp32 for safety/stability\n",
    "    x_fft = x.to(torch.float32)\n",
    "    F = torch.fft.fft2(x_fft)         # complex64\n",
    "    F = torch.fft.fftshift(F)  # shift only spatial dims\n",
    "\n",
    "    P = (F.real * F.real + F.imag * F.imag)  # [B, H, W] float32\n",
    "\n",
    "    B, H, W = P.shape\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(H, device=P.device),\n",
    "        torch.arange(W, device=P.device),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    cy, cx = (H - 1) / 2.0, (W - 1) / 2.0\n",
    "    r = torch.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    r = (r / (r.max() + 1e-12) * (num_bins - 1)).to(torch.long)  # [H, W]\n",
    "\n",
    "    spectrum = torch.zeros(num_bins, device=P.device, dtype=torch.float32)\n",
    "    idx = r.flatten().expand(B, -1)     # [B, HW]\n",
    "    vals = P.reshape(B, -1)            # [B, HW]\n",
    "    spectrum.scatter_add_(0, idx.reshape(-1), vals.reshape(-1))\n",
    "\n",
    "    return spectrum.to(out_dtype)\n",
    "\n",
    "\n",
    "\n",
    "@torch.compile(fullgraph=True)\n",
    "def wasserstein_1d(p, q, eps=1e-8):\n",
    "    \"\"\"\n",
    "    p, q : tensors [K]\n",
    "    \"\"\"\n",
    "    p32 = p.to(torch.float32)\n",
    "    q32 = q.to(torch.float32)\n",
    "\n",
    "    p32 = p32 / (p32.sum() + eps)\n",
    "    q32 = q32 / (q32.sum() + eps)\n",
    "\n",
    "    cdf_p = torch.cumsum(p32, dim=0)\n",
    "    cdf_q = torch.cumsum(q32, dim=0)\n",
    "\n",
    "    return torch.abs(cdf_p - cdf_q).to(p.dtype)\n",
    "\n",
    "\n",
    "def act_freq_loss(model_act, target_image, num_bins=16):\n",
    "    model_spec = radial_spectrum_2d(model_act, num_bins=num_bins)\n",
    "    target_spec = radial_spectrum_2d(target_image, num_bins=num_bins)\n",
    "\n",
    "    delta = wasserstein_1d(model_spec, target_spec)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    gamma = 1.5\n",
    "    z = delta / (delta.mean() + 1e-6)\n",
    "    w = z.pow(gamma).clamp(0.2, 10.0)   # gamma=1.5~2\n",
    "    # w = torch.softmax(delta / 1.0, dim=0)\n",
    "\n",
    "\n",
    "    return (w * delta).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c4bd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "def radial_spectrum_2d(\n",
    "    x,\n",
    "    num_bins=16,\n",
    "    eps=1e-8,\n",
    "    out_dtype=None,\n",
    "\n",
    "    *,\n",
    "    vit_grid=None,              # (H, W) explicit patch grid\n",
    "    num_prefix_tokens=None,      # number of prefix tokens total\n",
    "    max_prefix_tokens=16,\n",
    "    use_cls_token=True,         # NEW: if True, build spectrum from CLS token only\n",
    "):\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "      - CNN feature maps: x [B, C, H, W]\n",
    "      - ViT tokens:       x [B, N, D]  (tokens, embed dim)\n",
    "\n",
    "    Returns:\n",
    "      spectrum [num_bins], normalized to sum=1 (aggregated across batch).\n",
    "    \"\"\"\n",
    "\n",
    "    if out_dtype is None:\n",
    "        out_dtype = x.dtype\n",
    "\n",
    "    if x.dim() == 3:\n",
    "        # ViT tokens: [B, N, D]\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        # Determine grid size and how many prefix tokens exist.\n",
    "        if vit_grid is not None:\n",
    "            H, W = vit_grid\n",
    "            needed = H * W\n",
    "            if num_prefix_tokens is None:\n",
    "                num_prefix_tokens = N - needed\n",
    "            if N - num_prefix_tokens != needed:\n",
    "                raise ValueError(\n",
    "                    f\"vit_grid={vit_grid} implies {needed} patch tokens, but got N={N} \"\n",
    "                    f\"with num_prefix_tokens={num_prefix_tokens} => {N - num_prefix_tokens} tokens.\"\n",
    "                )\n",
    "        else:\n",
    "            # Auto-infer num_prefix_tokens by finding N-k that is a perfect square\n",
    "            if num_prefix_tokens is None:\n",
    "                found = None\n",
    "                for k in range(0, max_prefix_tokens + 1):\n",
    "                    m = N - k\n",
    "                    if m <= 0:\n",
    "                        break\n",
    "                    s = int(math.isqrt(m))\n",
    "                    if s * s == m:\n",
    "                        found = k\n",
    "                        H = W = s\n",
    "                        break\n",
    "                if found is None:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot infer square token grid from N={N}. \"\n",
    "                        f\"Pass vit_grid=(H,W) or num_prefix_tokens explicitly.\"\n",
    "                    )\n",
    "                num_prefix_tokens = found\n",
    "            else:\n",
    "                m = N - num_prefix_tokens\n",
    "                s = int(math.isqrt(m))\n",
    "                if s * s != m:\n",
    "                    raise ValueError(\n",
    "                        f\"N - num_prefix_tokens = {m} is not a perfect square. \"\n",
    "                        f\"Pass vit_grid=(H,W) instead.\"\n",
    "                    )\n",
    "                H = W = s\n",
    "\n",
    "        # =========================\n",
    "        # NEW: CLS-token spectrum\n",
    "        # =========================\n",
    "        if use_cls_token:\n",
    "            # CLS assumed to be token 0\n",
    "            cls = x[:, 0, :]  # [B, D]\n",
    "\n",
    "            # Turn CLS embedding into a 2D \"image\" so FFT makes sense.\n",
    "            # We reshape D -> H*W (requires D == H*W).\n",
    "            # If not equal, we crop or pad.\n",
    "            HW = H * W\n",
    "            if D < HW:\n",
    "                pad = HW - D\n",
    "                cls = torch.nn.functional.pad(cls, (0, pad), mode=\"constant\", value=0.0)\n",
    "            elif D > HW:\n",
    "                cls = cls[:, :HW]\n",
    "\n",
    "            # [B, HW] -> [B, H, W] -> [B, 1, H, W]\n",
    "            x = cls.view(B, H, W).unsqueeze(1).contiguous()\n",
    "\n",
    "        else:\n",
    "            # Default: patch-token spectrum (original behavior)\n",
    "            if num_prefix_tokens > 0:\n",
    "                x = x[:, num_prefix_tokens:, :].contiguous()  # [B, H*W, D]\n",
    "            else:\n",
    "                x = x.contiguous()\n",
    "\n",
    "            # [B, H*W, D] -> [B, H, W, D] -> [B, D, H, W]\n",
    "            x = x.view(B, H, W, D).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    elif x.dim() != 4:\n",
    "        raise ValueError(f\"Expected x dim 3 or 4, got {x.dim()}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # CNN path (or converted ViT path): x [B, C, H, W]\n",
    "    x = x.mean(dim=1)                 # [B, H, W]\n",
    "\n",
    "    # FFT in fp32 for safety/stability\n",
    "    x_fft = x.to(torch.float32)\n",
    "    F = torch.fft.fft2(x_fft)         # complex64\n",
    "    F = torch.fft.fftshift(F)  # shift only spatial dims\n",
    "\n",
    "    P = (F.real * F.real + F.imag * F.imag)  # [B, H, W] float32\n",
    "\n",
    "    B, H, W = P.shape\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(H, device=P.device),\n",
    "        torch.arange(W, device=P.device),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    cy, cx = (H - 1) / 2.0, (W - 1) / 2.0\n",
    "    r = torch.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    r = (r / (r.max() + 1e-12) * (num_bins - 1)).to(torch.long)  # [H, W]\n",
    "\n",
    "    spectrum = torch.zeros(num_bins, device=P.device, dtype=torch.float32)\n",
    "    idx = r.flatten().expand(B, -1)     # [B, HW]\n",
    "    vals = P.reshape(B, -1)            # [B, HW]\n",
    "    spectrum.scatter_add_(0, idx.reshape(-1), vals.reshape(-1))\n",
    "\n",
    "    spectrum = spectrum / (spectrum.sum() + eps)\n",
    "    return spectrum.to(out_dtype)\n",
    "# import torch\n",
    "# import math\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "# # DCT-II (orthonormal), separable 2D implementation\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# def dct_1d(x, norm=\"ortho\"):\n",
    "#     \"\"\"\n",
    "#     x: [..., N]\n",
    "#     returns DCT-II along last dim\n",
    "#     \"\"\"\n",
    "#     N = x.shape[-1]\n",
    "\n",
    "#     # Even-symmetric extension\n",
    "#     x_ext = torch.cat([x, x.flip(-1)], dim=-1)\n",
    "\n",
    "#     # FFT\n",
    "#     X = torch.fft.fft(x_ext, dim=-1)\n",
    "\n",
    "#     # Take real cosine part\n",
    "#     k = torch.arange(N, device=x.device)\n",
    "#     W = torch.exp(-1j * math.pi * k / (2 * N))\n",
    "\n",
    "#     out = (X[..., :N] * W).real * 2\n",
    "\n",
    "#     if norm == \"ortho\":\n",
    "#         out[..., 0] /= math.sqrt(4 * N)\n",
    "#         out[..., 1:] /= math.sqrt(2 * N)\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def dct_2d(x):\n",
    "#     \"\"\"\n",
    "#     x: [B,H,W]\n",
    "#     \"\"\"\n",
    "#     x = dct_1d(x, norm=\"ortho\")\n",
    "#     x = dct_1d(x.transpose(-1, -2), norm=\"ortho\").transpose(-1, -2)\n",
    "#     return x\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "# # Radial DCT spectrum (your main function)\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# def radial_spectrum_2d(\n",
    "#     x,\n",
    "#     num_bins=16,\n",
    "#     eps=1e-8,\n",
    "#     out_dtype=None,\n",
    "\n",
    "#     *,\n",
    "#     vit_grid=None,\n",
    "#     num_prefix_tokens=None,\n",
    "#     max_prefix_tokens=16,\n",
    "#     use_cls_token=True,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Supports:\n",
    "#       - CNN feature maps: x [B,C,H,W]\n",
    "#       - ViT tokens:       x [B,N,D]\n",
    "\n",
    "#     Returns:\n",
    "#       spectrum [num_bins], normalized to sum=1\n",
    "#     \"\"\"\n",
    "\n",
    "#     if out_dtype is None:\n",
    "#         out_dtype = x.dtype\n",
    "\n",
    "#     # ---------------- ViT handling ----------------\n",
    "\n",
    "#     if x.dim() == 3:\n",
    "#         B, N, D = x.shape\n",
    "\n",
    "#         if vit_grid is not None:\n",
    "#             H, W = vit_grid\n",
    "#             needed = H * W\n",
    "#             if num_prefix_tokens is None:\n",
    "#                 num_prefix_tokens = N - needed\n",
    "#         else:\n",
    "#             if num_prefix_tokens is None:\n",
    "#                 for k in range(max_prefix_tokens + 1):\n",
    "#                     m = N - k\n",
    "#                     s = int(math.isqrt(m))\n",
    "#                     if s * s == m:\n",
    "#                         num_prefix_tokens = k\n",
    "#                         H = W = s\n",
    "#                         break\n",
    "#             else:\n",
    "#                 m = N - num_prefix_tokens\n",
    "#                 s = int(math.isqrt(m))\n",
    "#                 H = W = s\n",
    "\n",
    "#         if use_cls_token:\n",
    "#             cls = x[:, 0, :]  # [B,D]\n",
    "#             HW = H * W\n",
    "#             if D < HW:\n",
    "#                 cls = F.pad(cls, (0, HW - D))\n",
    "#             elif D > HW:\n",
    "#                 cls = cls[:, :HW]\n",
    "\n",
    "#             x = cls.view(B, H, W).unsqueeze(1)\n",
    "\n",
    "#         else:\n",
    "#             if num_prefix_tokens > 0:\n",
    "#                 x = x[:, num_prefix_tokens:, :]\n",
    "#             x = x.view(B, H, W, D).permute(0, 3, 1, 2)\n",
    "\n",
    "#     elif x.dim() != 4:\n",
    "#         raise ValueError(f\"Expected x dim 3 or 4, got {x.dim()}\")\n",
    "\n",
    "#     # ------------------------------------------------\n",
    "#     # CNN path: x [B,C,H,W] → spatial mean\n",
    "#     # ------------------------------------------------\n",
    "\n",
    "#     x = x.mean(dim=1)   # [B,H,W]\n",
    "\n",
    "#     # ------------------------------------------------\n",
    "#     # DCT (fp32 for stability)\n",
    "#     # ------------------------------------------------\n",
    "\n",
    "#     x = x.float()\n",
    "#     F = dct_2d(x)\n",
    "#     P = F.pow(2)        # power spectrum [B,H,W]\n",
    "\n",
    "#     B, H, W = P.shape\n",
    "\n",
    "#     # ------------------------------------------------\n",
    "#     # Radial bins\n",
    "#     # ------------------------------------------------\n",
    "\n",
    "#     yy, xx = torch.meshgrid(\n",
    "#         torch.arange(H, device=P.device),\n",
    "#         torch.arange(W, device=P.device),\n",
    "#         indexing=\"ij\"\n",
    "#     )\n",
    "\n",
    "#     r = torch.sqrt(yy.float() ** 2 + xx.float() ** 2)\n",
    "#     r = r / (r.max() + 1e-12)\n",
    "#     r = (r * (num_bins - 1)).long()\n",
    "\n",
    "#     spectrum = torch.zeros(num_bins, device=P.device)\n",
    "\n",
    "#     idx = r.flatten().expand(B, -1)\n",
    "#     vals = P.reshape(B, -1)\n",
    "\n",
    "#     spectrum.scatter_add_(0, idx.reshape(-1), vals.reshape(-1))\n",
    "\n",
    "#     spectrum = spectrum / (spectrum.sum() + eps)\n",
    "\n",
    "#     return spectrum.to(out_dtype)\n",
    "\n",
    "\n",
    "@torch.compile(fullgraph=True)\n",
    "def wasserstein_1d(p, q, eps=1e-8):\n",
    "    \"\"\"\n",
    "    p, q : tensors [K]\n",
    "    \"\"\"\n",
    "    p32 = p.to(torch.float32)\n",
    "    q32 = q.to(torch.float32)\n",
    "\n",
    "    p32 = p32 / (p32.sum() + eps)\n",
    "    q32 = q32 / (q32.sum() + eps)\n",
    "\n",
    "    cdf_p = torch.cumsum(p32, dim=0)\n",
    "    cdf_q = torch.cumsum(q32, dim=0)\n",
    "\n",
    "    return torch.sum(torch.abs(cdf_p - cdf_q)).to(p.dtype)\n",
    "\n",
    "@torch.compile(fullgraph=True)\n",
    "def kl_div_spectrum(q, p, eps=1e-8):\n",
    "    # q, p: [B,K], each row sums to 1\n",
    "    q = q.clamp_min(eps)\n",
    "    p = p.clamp_min(eps)\n",
    "    return (q * (q.log() - p.log())).sum(dim=-1).mean()\n",
    "\n",
    "\n",
    "@torch.compile(fullgraph=True)\n",
    "def temp_kl(p, q, T=2.0, eps=1e-8):\n",
    "    \"\"\"\n",
    "    p, q: [B, K] distributions (sum=1)\n",
    "    Applies temperature to log-prob space:\n",
    "      softmax(log(p)/T)\n",
    "    \"\"\"\n",
    "    logp = torch.log(p.clamp_min(eps))\n",
    "    logq = torch.log(q.clamp_min(eps))\n",
    "\n",
    "    pT = F.softmax(logp / T, dim=-1)\n",
    "    qT = F.softmax(logq / T, dim=-1)\n",
    "\n",
    "    # KL(p||q) = sum p * (log p - log q)\n",
    "    kl = (pT * (torch.log(pT.clamp_min(eps)) - torch.log(qT.clamp_min(eps)))).sum(dim=-1).mean()\n",
    "\n",
    "    return (T * T) * kl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a892a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "activation_cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae658a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_spectrum = radial_spectrum_2d(activation_cache['layer4.1.conv2'].to(torch.float32))\n",
    "target_spectrum = radial_spectrum_2d(x.to(torch.float32)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486adee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "wasserstein_1d(model_spectrum, target_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0e76e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, (nn.Linear, nn.Conv1d, nn.Conv2d)):\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590962e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "activation_cache = {}\n",
    "low_frequency_energy_ratio_grad = {}\n",
    "low_frequency_energy_ratio_act = {}\n",
    "baseline = copy.deepcopy(model.state_dict())\n",
    "\n",
    "hook_handles = {}\n",
    "cahced_init = None\n",
    "cached_rng_state = None\n",
    "\n",
    "def kaiming_normal_fan_in(w):\n",
    "    return nn.init.kaiming_normal_(w, mode='fan_in', nonlinearity='relu')\n",
    "def kaiming_normal_fan_out(w):\n",
    "    return nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\n",
    "def kaiming_uniform_fan_in(w):\n",
    "    return nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n",
    "def kaiming_uniform_fan_out(w):\n",
    "    return nn.init.kaiming_uniform_(w, mode='fan_out', nonlinearity='relu')\n",
    "def trunc_normal(w):\n",
    "    return trunc_normal_(w, std=0.02)\n",
    "def trunc_normal_small(w):\n",
    "    return trunc_normal_(w, std=0.01)\n",
    "def orthogonal(w):\n",
    "    return nn.init.orthogonal_(w, gain=1.0)\n",
    "def orthogonal2(w):\n",
    "    return nn.init.orthogonal_(w, gain=math.sqrt(2))\n",
    "def xavier_normal(w):\n",
    "    return nn.init.xavier_normal_(w)\n",
    "def xavier_uniform(w):\n",
    "    return nn.init.xavier_uniform_(w)\n",
    "def lecun_normal(w):\n",
    "    return nn.init.normal_(w, std=1.0 / math.sqrt(w.shape[1]))\n",
    "def kaiming_low_std(w):\n",
    "    fan_in = nn.init._calculate_correct_fan(w, \"fan_in\")\n",
    "    std = math.sqrt(2.0 / fan_in) * 0.5\n",
    "    return nn.init.normal_(w, std=std)\n",
    "\n",
    "\n",
    "def forward_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        activation_cache[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "\n",
    "min_score = 100\n",
    "for init in [\n",
    "    kaiming_normal_fan_in,\n",
    "    kaiming_normal_fan_out,\n",
    "    kaiming_uniform_fan_in,\n",
    "    kaiming_uniform_fan_out,\n",
    "    kaiming_low_std,\n",
    "    trunc_normal,\n",
    "    trunc_normal_small,\n",
    "    orthogonal,\n",
    "    orthogonal2,\n",
    "    xavier_normal,\n",
    "    xavier_uniform,\n",
    "    lecun_normal\n",
    "    ]:\n",
    "\n",
    "    # 42, 49, 0, 1, 2, 3, 4\n",
    "    set_seed(49)\n",
    "    cpu_rng_state = torch.get_rng_state()\n",
    "    gpu_rng_state = torch.cuda.get_rng_state()\n",
    "\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Linear)):\n",
    "            init(m.weight)\n",
    "    print(init)\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv1d, nn.Conv2d, nn.Linear)):\n",
    "            hook_handles[name] = module.register_forward_hook(forward_hook(name))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "    act = activation_cache['features.8.0']\n",
    "\n",
    "    model_spectrum = radial_spectrum_2d(act.to(torch.float32), num_bins=16).cpu()\n",
    "    target_spectrum = radial_spectrum_2d(x.to(torch.float32), num_bins=16).cpu()\n",
    "\n",
    "    score = wasserstein_1d(model_spectrum, target_spectrum)\n",
    "    if score < min_score:\n",
    "        min_score = score\n",
    "        cahced_init = init\n",
    "        cached_rng_state = {\n",
    "            'CPU' : cpu_rng_state,\n",
    "            'GPU' : gpu_rng_state\n",
    "        }\n",
    "        print(f\"min score: {min_score}\")\n",
    "\n",
    "\n",
    "    for h in hook_handles.values():\n",
    "        h.remove()\n",
    "    activation_cache.clear()\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc6180",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cahced_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd41f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada04915",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#torch vision default\n",
    "tensor(17.0655, device='cuda:0')\n",
    "\n",
    "# timm's trunc_init\n",
    "tensor(25.9191, device='cuda:0')\n",
    "\n",
    "# fan out\n",
    "tensor(11.3065, device='cuda:0')\n",
    "\n",
    "# init_orthogonal_conv(m, gain=math.sqrt(2))\n",
    "tensor(22.3052, device='cuda:0')\n",
    "\n",
    "# init_orthogonal_conv(m, gain=1.0)\n",
    "tensor(7.9659, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e523df",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "x, y = x.to('cuda'), y.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de857ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with profile(\n",
    "    activities=[\n",
    "        ProfilerActivity.CPU,\n",
    "        ProfilerActivity.CUDA\n",
    "    ],\n",
    "    record_shapes=True,\n",
    "    with_stack=True,\n",
    "    profile_memory=True,\n",
    ") as prof:\n",
    "\n",
    "    for step in range(10):\n",
    "        with record_function(\"train_step\"):\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                output = controller.traced_model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(prof.key_averages().table(\n",
    "    sort_by=\"cuda_time_total\",\n",
    "    row_limit=200\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
