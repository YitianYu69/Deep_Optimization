//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34714021
// Cuda compilation tools, release 12.6, V12.6.68
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_90a
.address_size 64

	// .globl	quant_pack_4bit_sm90a_kernel
// _ZZ16group_minmax_512RfS_E7shm_min has been demoted
// _ZZ16group_minmax_512RfS_E7shm_max has been demoted

.visible .entry quant_pack_4bit_sm90a_kernel(
	.param .u64 quant_pack_4bit_sm90a_kernel_param_0,
	.param .u64 quant_pack_4bit_sm90a_kernel_param_1,
	.param .u32 quant_pack_4bit_sm90a_kernel_param_2,
	.param .u32 quant_pack_4bit_sm90a_kernel_param_3,
	.param .u32 quant_pack_4bit_sm90a_kernel_param_4
)
.maxntid 512, 1, 1
{
	.reg .pred 	%p<38>;
	.reg .f32 	%f<64>;
	.reg .b32 	%r<122>;
	.reg .b64 	%rd<10>;
	// demoted variable
	.shared .align 4 .b8 _ZZ16group_minmax_512RfS_E7shm_min[64];
	// demoted variable
	.shared .align 4 .b8 _ZZ16group_minmax_512RfS_E7shm_max[64];

	ld.param.u64 	%rd3, [quant_pack_4bit_sm90a_kernel_param_0];
	ld.param.u64 	%rd1, [quant_pack_4bit_sm90a_kernel_param_1];
	ld.param.u32 	%r10, [quant_pack_4bit_sm90a_kernel_param_4];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mul.lo.s32 	%r11, %r2, -1640531527;
	mul.lo.s32 	%r12, %r1, -2048144789;
	xor.b32  	%r13, %r12, %r11;
	shl.b32 	%r14, %r2, 9;
	add.s32 	%r15, %r14, %r1;
	mul.wide.s32 	%rd4, %r15, 4;
	add.s64 	%rd2, %rd3, %rd4;
	// begin inline asm
	ld.global.nc.L1::no_allocate.f32 %f10, [%rd2];

	// end inline asm
	and.b32  	%r3, %r1, 31;
	mov.u32 	%r16, 31;
	mov.b32 	%r17, %f10;
	mov.u32 	%r18, 16;
	mov.u32 	%r19, -1;
	shfl.sync.bfly.b32 	%r20|%p1, %r17, %r18, %r16, %r19;
	mov.b32 	%f11, %r20;
	min.f32 	%f12, %f10, %f11;
	mov.b32 	%r21, %f12;
	mov.u32 	%r22, 8;
	shfl.sync.bfly.b32 	%r23|%p2, %r21, %r22, %r16, %r19;
	mov.b32 	%f13, %r23;
	min.f32 	%f14, %f12, %f13;
	mov.b32 	%r24, %f14;
	mov.u32 	%r25, 4;
	shfl.sync.bfly.b32 	%r26|%p3, %r24, %r25, %r16, %r19;
	mov.b32 	%f15, %r26;
	min.f32 	%f16, %f14, %f15;
	mov.b32 	%r27, %f16;
	mov.u32 	%r28, 2;
	shfl.sync.bfly.b32 	%r29|%p4, %r27, %r28, %r16, %r19;
	mov.b32 	%f17, %r29;
	min.f32 	%f18, %f16, %f17;
	mov.b32 	%r30, %f18;
	mov.u32 	%r31, 1;
	shfl.sync.bfly.b32 	%r32|%p5, %r30, %r31, %r16, %r19;
	mov.b32 	%f19, %r32;
	min.f32 	%f2, %f18, %f19;
	xor.b32  	%r4, %r13, %r10;
	shr.u32 	%r5, %r1, 5;
	shfl.sync.bfly.b32 	%r33|%p6, %r17, %r18, %r16, %r19;
	mov.b32 	%f20, %r33;
	max.f32 	%f21, %f10, %f20;
	mov.b32 	%r34, %f21;
	shfl.sync.bfly.b32 	%r35|%p7, %r34, %r22, %r16, %r19;
	mov.b32 	%f22, %r35;
	max.f32 	%f23, %f21, %f22;
	mov.b32 	%r36, %f23;
	shfl.sync.bfly.b32 	%r37|%p8, %r36, %r25, %r16, %r19;
	mov.b32 	%f24, %r37;
	max.f32 	%f25, %f23, %f24;
	mov.b32 	%r38, %f25;
	shfl.sync.bfly.b32 	%r39|%p9, %r38, %r28, %r16, %r19;
	mov.b32 	%f26, %r39;
	max.f32 	%f27, %f25, %f26;
	mov.b32 	%r40, %f27;
	shfl.sync.bfly.b32 	%r41|%p10, %r40, %r31, %r16, %r19;
	mov.b32 	%f28, %r41;
	max.f32 	%f3, %f27, %f28;
	setp.ne.s32 	%p11, %r3, 0;
	@%p11 bra 	$L__BB0_2;

	shl.b32 	%r42, %r5, 2;
	mov.u32 	%r43, _ZZ16group_minmax_512RfS_E7shm_min;
	add.s32 	%r44, %r43, %r42;
	st.shared.f32 	[%r44], %f2;
	mov.u32 	%r45, _ZZ16group_minmax_512RfS_E7shm_max;
	add.s32 	%r46, %r45, %r42;
	st.shared.f32 	[%r46], %f3;

$L__BB0_2:
	bar.sync 	0;
	setp.ne.s32 	%p12, %r5, 0;
	@%p12 bra 	$L__BB0_7;

	setp.gt.u32 	%p13, %r3, 15;
	mov.f32 	%f63, 0fF149F2CA;
	mov.f32 	%f62, 0f7149F2CA;
	@%p13 bra 	$L__BB0_5;

	shl.b32 	%r47, %r3, 2;
	mov.u32 	%r48, _ZZ16group_minmax_512RfS_E7shm_min;
	add.s32 	%r49, %r48, %r47;
	ld.shared.f32 	%f62, [%r49];
	mov.u32 	%r50, _ZZ16group_minmax_512RfS_E7shm_max;
	add.s32 	%r51, %r50, %r47;
	ld.shared.f32 	%f63, [%r51];

$L__BB0_5:
	mov.b32 	%r52, %f62;
	mov.u32 	%r53, 31;
	mov.u32 	%r54, 16;
	mov.u32 	%r55, -1;
	shfl.sync.bfly.b32 	%r56|%p14, %r52, %r54, %r53, %r55;
	mov.b32 	%f31, %r56;
	min.f32 	%f32, %f62, %f31;
	mov.b32 	%r57, %f32;
	mov.u32 	%r58, 8;
	shfl.sync.bfly.b32 	%r59|%p15, %r57, %r58, %r53, %r55;
	mov.b32 	%f33, %r59;
	min.f32 	%f34, %f32, %f33;
	mov.b32 	%r60, %f34;
	mov.u32 	%r61, 4;
	shfl.sync.bfly.b32 	%r62|%p16, %r60, %r61, %r53, %r55;
	mov.b32 	%f35, %r62;
	min.f32 	%f36, %f34, %f35;
	mov.b32 	%r63, %f36;
	mov.u32 	%r64, 2;
	shfl.sync.bfly.b32 	%r65|%p17, %r63, %r64, %r53, %r55;
	mov.b32 	%f37, %r65;
	min.f32 	%f38, %f36, %f37;
	mov.b32 	%r66, %f38;
	mov.u32 	%r67, 1;
	shfl.sync.bfly.b32 	%r68|%p18, %r66, %r67, %r53, %r55;
	mov.b32 	%f39, %r68;
	min.f32 	%f8, %f38, %f39;
	mov.b32 	%r69, %f63;
	shfl.sync.bfly.b32 	%r70|%p19, %r69, %r54, %r53, %r55;
	mov.b32 	%f40, %r70;
	max.f32 	%f41, %f63, %f40;
	mov.b32 	%r71, %f41;
	shfl.sync.bfly.b32 	%r72|%p20, %r71, %r58, %r53, %r55;
	mov.b32 	%f42, %r72;
	max.f32 	%f43, %f41, %f42;
	mov.b32 	%r73, %f43;
	shfl.sync.bfly.b32 	%r74|%p21, %r73, %r61, %r53, %r55;
	mov.b32 	%f44, %r74;
	max.f32 	%f45, %f43, %f44;
	mov.b32 	%r75, %f45;
	shfl.sync.bfly.b32 	%r76|%p22, %r75, %r64, %r53, %r55;
	mov.b32 	%f46, %r76;
	max.f32 	%f47, %f45, %f46;
	mov.b32 	%r77, %f47;
	shfl.sync.bfly.b32 	%r78|%p23, %r77, %r67, %r53, %r55;
	mov.b32 	%f48, %r78;
	max.f32 	%f9, %f47, %f48;
	@%p11 bra 	$L__BB0_7;

	st.shared.f32 	[_ZZ16group_minmax_512RfS_E7shm_min], %f8;
	st.shared.f32 	[_ZZ16group_minmax_512RfS_E7shm_max], %f9;

$L__BB0_7:
	bar.sync 	0;
	ld.shared.f32 	%f49, [_ZZ16group_minmax_512RfS_E7shm_max];
	ld.shared.f32 	%f50, [_ZZ16group_minmax_512RfS_E7shm_min];
	sub.f32 	%f51, %f49, %f50;
	add.f32 	%f52, %f51, 0f358637BD;
	mov.f32 	%f53, 0f41700000;
	div.rn.f32 	%f54, %f53, %f52;
	shl.b32 	%r87, %r4, 13;
	xor.b32  	%r88, %r87, %r4;
	shr.u32 	%r89, %r88, 17;
	xor.b32  	%r90, %r89, %r88;
	shl.b32 	%r91, %r90, 5;
	xor.b32  	%r92, %r91, %r90;
	and.b32  	%r93, %r92, 16777215;
	cvt.rn.f32.u32 	%f55, %r93;
	sub.f32 	%f56, %f10, %f50;
	mul.f32 	%f57, %f56, %f54;
	fma.rn.f32 	%f58, %f55, 0f33800000, %f57;
	add.f32 	%f59, %f58, 0fBF000000;
	mov.f32 	%f60, 0f00000000;
	max.f32 	%f61, %f59, %f60;
	cvt.rni.s32.f32 	%r94, %f61;
	and.b32  	%r95, %r94, 8;
	and.b32  	%r80, %r94, 1;
	// begin inline asm
	{ .reg .pred p; setp.ne.b32 p, %r80, 0;     
  vote.ballot.sync.b32 %r79, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r96, %r94, 1;
	and.b32  	%r82, %r96, 1;
	// begin inline asm
	{ .reg .pred p; setp.ne.b32 p, %r82, 0;     
  vote.ballot.sync.b32 %r81, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r97, %r94, 2;
	and.b32  	%r84, %r97, 1;
	// begin inline asm
	{ .reg .pred p; setp.ne.b32 p, %r84, 0;     
  vote.ballot.sync.b32 %r83, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r86, %r95, 3;
	// begin inline asm
	{ .reg .pred p; setp.ne.b32 p, %r86, 0;     
  vote.ballot.sync.b32 %r85, p, 0xffffffff; 
}
	// end inline asm
	and.b32  	%r98, %r1, 127;
	setp.ne.s32 	%p25, %r98, 0;
	@%p25 bra 	$L__BB0_9;

	shr.s32 	%r115, %r1, 5;
	shl.b32 	%r116, %r115, 2;
	shl.b32 	%r117, %r2, 6;
	add.s32 	%r118, %r116, %r117;
	mov.u32 	%r119, 31;
	mov.u32 	%r120, 0;
	mov.u32 	%r121, -1;
	shfl.sync.idx.b32 	%r103|%p26, %r79, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r104|%p27, %r81, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r105|%p28, %r83, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r106|%p29, %r85, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r107|%p30, %r79, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r108|%p31, %r81, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r109|%p32, %r83, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r110|%p33, %r85, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r111|%p34, %r79, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r112|%p35, %r81, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r113|%p36, %r83, %r120, %r119, %r121;
	shfl.sync.idx.b32 	%r114|%p37, %r85, %r120, %r119, %r121;
	mul.wide.s32 	%rd9, %r118, 4;
	add.s64 	%rd5, %rd1, %rd9;
	// begin inline asm
	st.global.v4.u32 [%rd5], {%r79,%r81,%r83,%r85};

	// end inline asm
	add.s64 	%rd6, %rd5, 16;
	// begin inline asm
	st.global.v4.u32 [%rd6], {%r103,%r104,%r105,%r106};

	// end inline asm
	add.s64 	%rd7, %rd5, 32;
	// begin inline asm
	st.global.v4.u32 [%rd7], {%r107,%r108,%r109,%r110};

	// end inline asm
	add.s64 	%rd8, %rd5, 48;
	// begin inline asm
	st.global.v4.u32 [%rd8], {%r111,%r112,%r113,%r114};

	// end inline asm

$L__BB0_9:
	ret;

}

