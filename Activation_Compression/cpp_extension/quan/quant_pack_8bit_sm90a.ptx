//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34714021
// Cuda compilation tools, release 12.6, V12.6.68
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_90a
.address_size 64

	// .globl	quant_pack_8bit_sm90a_kernel
// _ZZ16group_minmax_512RfS_E7shm_min has been demoted
// _ZZ16group_minmax_512RfS_E7shm_max has been demoted

.visible .entry quant_pack_8bit_sm90a_kernel(
	.param .u64 quant_pack_8bit_sm90a_kernel_param_0,
	.param .u64 quant_pack_8bit_sm90a_kernel_param_1,
	.param .u32 quant_pack_8bit_sm90a_kernel_param_2,
	.param .u32 quant_pack_8bit_sm90a_kernel_param_3,
	.param .u32 quant_pack_8bit_sm90a_kernel_param_4
)
.maxntid 512, 1, 1
{
	.reg .pred 	%p<26>;
	.reg .f32 	%f<64>;
	.reg .b32 	%r<126>;
	.reg .b64 	%rd<8>;
	// demoted variable
	.shared .align 4 .b8 _ZZ16group_minmax_512RfS_E7shm_min[64];
	// demoted variable
	.shared .align 4 .b8 _ZZ16group_minmax_512RfS_E7shm_max[64];

	ld.param.u64 	%rd3, [quant_pack_8bit_sm90a_kernel_param_0];
	ld.param.u64 	%rd1, [quant_pack_8bit_sm90a_kernel_param_1];
	ld.param.u32 	%r14, [quant_pack_8bit_sm90a_kernel_param_4];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mul.lo.s32 	%r15, %r2, -1640531527;
	mul.lo.s32 	%r16, %r1, -1849467071;
	xor.b32  	%r17, %r16, %r15;
	shl.b32 	%r18, %r2, 9;
	add.s32 	%r19, %r18, %r1;
	mul.wide.s32 	%rd4, %r19, 4;
	add.s64 	%rd2, %rd3, %rd4;
	// begin inline asm
	ld.global.nt.f32 %f10, [%rd2];

	// end inline asm
	mov.b32 	%r20, %f10;
	mov.u32 	%r21, 31;
	mov.u32 	%r22, 16;
	mov.u32 	%r23, -1;
	shfl.sync.bfly.b32 	%r24|%p1, %r20, %r22, %r21, %r23;
	mov.b32 	%f11, %r24;
	min.f32 	%f12, %f10, %f11;
	mov.b32 	%r25, %f12;
	mov.u32 	%r26, 8;
	shfl.sync.bfly.b32 	%r27|%p2, %r25, %r26, %r21, %r23;
	mov.b32 	%f13, %r27;
	min.f32 	%f14, %f12, %f13;
	mov.b32 	%r28, %f14;
	mov.u32 	%r29, 4;
	shfl.sync.bfly.b32 	%r30|%p3, %r28, %r29, %r21, %r23;
	mov.b32 	%f15, %r30;
	min.f32 	%f16, %f14, %f15;
	mov.b32 	%r31, %f16;
	mov.u32 	%r32, 2;
	shfl.sync.bfly.b32 	%r33|%p4, %r31, %r32, %r21, %r23;
	mov.b32 	%f17, %r33;
	min.f32 	%f18, %f16, %f17;
	mov.b32 	%r34, %f18;
	mov.u32 	%r35, 1;
	shfl.sync.bfly.b32 	%r36|%p5, %r34, %r35, %r21, %r23;
	mov.b32 	%f19, %r36;
	min.f32 	%f2, %f18, %f19;
	and.b32  	%r3, %r1, 31;
	xor.b32  	%r4, %r17, %r14;
	shr.u32 	%r5, %r1, 5;
	shfl.sync.bfly.b32 	%r37|%p6, %r20, %r22, %r21, %r23;
	mov.b32 	%f20, %r37;
	max.f32 	%f21, %f10, %f20;
	mov.b32 	%r38, %f21;
	shfl.sync.bfly.b32 	%r39|%p7, %r38, %r26, %r21, %r23;
	mov.b32 	%f22, %r39;
	max.f32 	%f23, %f21, %f22;
	mov.b32 	%r40, %f23;
	shfl.sync.bfly.b32 	%r41|%p8, %r40, %r29, %r21, %r23;
	mov.b32 	%f24, %r41;
	max.f32 	%f25, %f23, %f24;
	mov.b32 	%r42, %f25;
	shfl.sync.bfly.b32 	%r43|%p9, %r42, %r32, %r21, %r23;
	mov.b32 	%f26, %r43;
	max.f32 	%f27, %f25, %f26;
	mov.b32 	%r44, %f27;
	shfl.sync.bfly.b32 	%r45|%p10, %r44, %r35, %r21, %r23;
	mov.b32 	%f28, %r45;
	max.f32 	%f3, %f27, %f28;
	setp.ne.s32 	%p11, %r3, 0;
	@%p11 bra 	$L__BB0_2;

	shl.b32 	%r46, %r5, 2;
	mov.u32 	%r47, _ZZ16group_minmax_512RfS_E7shm_min;
	add.s32 	%r48, %r47, %r46;
	st.shared.f32 	[%r48], %f2;
	mov.u32 	%r49, _ZZ16group_minmax_512RfS_E7shm_max;
	add.s32 	%r50, %r49, %r46;
	st.shared.f32 	[%r50], %f3;

$L__BB0_2:
	bar.sync 	0;
	setp.ne.s32 	%p12, %r5, 0;
	@%p12 bra 	$L__BB0_7;

	setp.gt.u32 	%p13, %r3, 15;
	mov.f32 	%f63, 0fF149F2CA;
	mov.f32 	%f62, 0f7149F2CA;
	@%p13 bra 	$L__BB0_5;

	shl.b32 	%r51, %r3, 2;
	mov.u32 	%r52, _ZZ16group_minmax_512RfS_E7shm_min;
	add.s32 	%r53, %r52, %r51;
	ld.shared.f32 	%f62, [%r53];
	mov.u32 	%r54, _ZZ16group_minmax_512RfS_E7shm_max;
	add.s32 	%r55, %r54, %r51;
	ld.shared.f32 	%f63, [%r55];

$L__BB0_5:
	mov.b32 	%r56, %f62;
	mov.u32 	%r57, 31;
	mov.u32 	%r58, 16;
	mov.u32 	%r59, -1;
	shfl.sync.bfly.b32 	%r60|%p14, %r56, %r58, %r57, %r59;
	mov.b32 	%f31, %r60;
	min.f32 	%f32, %f62, %f31;
	mov.b32 	%r61, %f32;
	mov.u32 	%r62, 8;
	shfl.sync.bfly.b32 	%r63|%p15, %r61, %r62, %r57, %r59;
	mov.b32 	%f33, %r63;
	min.f32 	%f34, %f32, %f33;
	mov.b32 	%r64, %f34;
	mov.u32 	%r65, 4;
	shfl.sync.bfly.b32 	%r66|%p16, %r64, %r65, %r57, %r59;
	mov.b32 	%f35, %r66;
	min.f32 	%f36, %f34, %f35;
	mov.b32 	%r67, %f36;
	mov.u32 	%r68, 2;
	shfl.sync.bfly.b32 	%r69|%p17, %r67, %r68, %r57, %r59;
	mov.b32 	%f37, %r69;
	min.f32 	%f38, %f36, %f37;
	mov.b32 	%r70, %f38;
	mov.u32 	%r71, 1;
	shfl.sync.bfly.b32 	%r72|%p18, %r70, %r71, %r57, %r59;
	mov.b32 	%f39, %r72;
	min.f32 	%f8, %f38, %f39;
	mov.b32 	%r73, %f63;
	shfl.sync.bfly.b32 	%r74|%p19, %r73, %r58, %r57, %r59;
	mov.b32 	%f40, %r74;
	max.f32 	%f41, %f63, %f40;
	mov.b32 	%r75, %f41;
	shfl.sync.bfly.b32 	%r76|%p20, %r75, %r62, %r57, %r59;
	mov.b32 	%f42, %r76;
	max.f32 	%f43, %f41, %f42;
	mov.b32 	%r77, %f43;
	shfl.sync.bfly.b32 	%r78|%p21, %r77, %r65, %r57, %r59;
	mov.b32 	%f44, %r78;
	max.f32 	%f45, %f43, %f44;
	mov.b32 	%r79, %f45;
	shfl.sync.bfly.b32 	%r80|%p22, %r79, %r68, %r57, %r59;
	mov.b32 	%f46, %r80;
	max.f32 	%f47, %f45, %f46;
	mov.b32 	%r81, %f47;
	shfl.sync.bfly.b32 	%r82|%p23, %r81, %r71, %r57, %r59;
	mov.b32 	%f48, %r82;
	max.f32 	%f9, %f47, %f48;
	@%p11 bra 	$L__BB0_7;

	st.shared.f32 	[_ZZ16group_minmax_512RfS_E7shm_min], %f8;
	st.shared.f32 	[_ZZ16group_minmax_512RfS_E7shm_max], %f9;

$L__BB0_7:
	bar.sync 	0;
	ld.shared.f32 	%f49, [_ZZ16group_minmax_512RfS_E7shm_max];
	ld.shared.f32 	%f50, [_ZZ16group_minmax_512RfS_E7shm_min];
	sub.f32 	%f51, %f49, %f50;
	add.f32 	%f52, %f51, 0f358637BD;
	mov.f32 	%f53, 0f437F0000;
	div.rn.f32 	%f54, %f53, %f52;
	shl.b32 	%r99, %r4, 13;
	xor.b32  	%r100, %r99, %r4;
	shr.u32 	%r101, %r100, 17;
	xor.b32  	%r102, %r101, %r100;
	shl.b32 	%r103, %r102, 5;
	xor.b32  	%r104, %r103, %r102;
	and.b32  	%r105, %r104, 16777215;
	cvt.rn.f32.u32 	%f55, %r105;
	sub.f32 	%f56, %f10, %f50;
	mul.f32 	%f57, %f56, %f54;
	fma.rn.f32 	%f58, %f55, 0f33800000, %f57;
	add.f32 	%f59, %f58, 0fBF000000;
	mov.f32 	%f60, 0f00000000;
	max.f32 	%f61, %f59, %f60;
	cvt.rni.s32.f32 	%r106, %f61;
	and.b32  	%r107, %r106, 128;
	and.b32  	%r84, %r106, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r84, 0;  
vote.ballot.sync.b32 %r83, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r108, %r106, 1;
	and.b32  	%r86, %r108, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r86, 0;  
vote.ballot.sync.b32 %r85, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r109, %r106, 2;
	and.b32  	%r88, %r109, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r88, 0;  
vote.ballot.sync.b32 %r87, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r110, %r106, 3;
	and.b32  	%r90, %r110, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r90, 0;  
vote.ballot.sync.b32 %r89, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r111, %r106, 4;
	and.b32  	%r92, %r111, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r92, 0;  
vote.ballot.sync.b32 %r91, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r112, %r106, 5;
	and.b32  	%r94, %r112, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r94, 0;  
vote.ballot.sync.b32 %r93, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r113, %r106, 6;
	and.b32  	%r96, %r113, 1;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r96, 0;  
vote.ballot.sync.b32 %r95, p, 0xffffffff; 
}
	// end inline asm
	shr.u32 	%r98, %r107, 7;
	// begin inline asm
	{ .reg .pred p;        
setp.ne.b32 p, %r98, 0;  
vote.ballot.sync.b32 %r97, p, 0xffffffff; 
}
	// end inline asm
	@%p11 bra 	$L__BB0_9;

	shr.s32 	%r122, %r1, 5;
	shl.b32 	%r123, %r122, 3;
	shl.b32 	%r124, %r2, 7;
	add.s32 	%r125, %r123, %r124;
	mul.wide.s32 	%rd7, %r125, 4;
	add.s64 	%rd5, %rd1, %rd7;
	// begin inline asm
	st.global.volatile.v4.u32 [%rd5], {%r83,%r85,%r87,%r89};

	// end inline asm
	add.s64 	%rd6, %rd5, 16;
	// begin inline asm
	st.global.volatile.v4.u32 [%rd6], {%r91,%r93,%r95,%r97};

	// end inline asm

$L__BB0_9:
	ret;

}

